[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Thomas Alexander Gerds. Author, maintainer. Paul Blanche. Contributor. Rikke Mortensen. Contributor. Marvin Wright. Contributor. Nikolaj Tollenaar. Contributor. John Muschelli. Contributor. Ulla Brasch Mogensen. Contributor. Brice Ozenne. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thomas . Gerds Michael W. Kattan (2021). Medical Risk Prediction Models: Ties Machine Learning (1st ed.) Chapman Hall/CRC https://doi.org/10.1201/9781138384484","code":"@Book{,   title = {Medical Risk Prediction Models: With Ties to Machine Learning (1st ed.)},   author = {Thomas A. Gerds and Michael W. Kattan},   publisher = {Chapman and Hall/CRC},   year = {2021},   url = {https://doi.org/10.1201/9781138384484}, }"},{"path":"/index.html","id":"install","dir":"","previous_headings":"","what":"Risk Regression Models and Prediction Scores for Survival Analysis with\n    Competing Risks","title":"Risk Regression Models and Prediction Scores for Survival Analysis with\n    Competing Risks","text":"","code":"library(devtools) install_github(\"tagteam/riskRegression\")"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Risk Regression Models and Prediction Scores for Survival Analysis with\n    Competing Risks","text":"following references provide methodological framework features riskRegression. T.. Gerds M.W. Kattan (2021). Medical Risk Prediction Models: Ties Machine Learning (1st ed.) Chapman Hall/CRC https://doi.org/10.1201/9781138384484 T.. Gerds M. Schumacher. Consistent estimation expected Brier score general survival models right-censored event times. Biometrical Journal, 48(6):1029–1040, 2006. T.. Gerds M. Schumacher. Efron-type measures prediction error survival analysis. Biometrics, 63(4):1283–1287, 2007. T.. Gerds, T. Cai, M. Schumacher. performance risk prediction models. Biometrical Journal, 50(4):457–479, 2008. U B Mogensen, H. Ishwaran, T Gerds. Evaluating random forests survival analysis using prediction error curves. Journal Statistical Software, 50(11), 2012. P. Blanche, J-F Dartigues, H. Jacqmin-Gadda. Estimating comparing time-dependent areas receiver operating characteristic curves censored event times competing risks. Statistics Medicine, 32(30): 5381–5397, 2013. Paul Blanche, Ce'cile Proust-Lima, Lucie Loube`re, Claudine Berr, Jean- Franc,ois Dartigues, 'le`ne Jacqmin-Gadda. Quantifying comparing dynamic predictive accuracy joint models longitudinal marker time--event presence censoring competing risks. Biometrics, 71 (1):102–113, 2015. Functions predict.CauseSpecificCox, predictCox iidCox: Brice Ozenne, Anne Lyngholm Sorensen, Thomas Scheike, Christian Torp-Pedersen Thomas Alexander Gerds. riskRegression: Predicting Risk Event using Cox Regression Models. R Journal (2017) 9:2, pages 440-460.","code":""},{"path":"/reference/CSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Cause-specific Cox proportional hazard regression — CSC","title":"Cause-specific Cox proportional hazard regression — CSC","text":"Interface fitting cause-specific Cox proportional hazard regression models competing risk.","code":""},{"path":"/reference/CSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cause-specific Cox proportional hazard regression — CSC","text":"","code":"CSC(formula, data, cause, surv.type = \"hazard\", fitter = \"coxph\", ...)"},{"path":"/reference/CSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cause-specific Cox proportional hazard regression — CSC","text":"formula Either single Hist formula list formulas. list must contain many Hist formulas causes surv.type=\"hazard\" exactly two formulas surv.type=\"survival\". list first formula used cause interest specific Cox regression formula(s) either cause specific Cox regression(s) Cox regression combined event cause counts event. Note one formula given covariates enter exactly way Cox regression analyses. data data fit models. cause cause interest. Defaults first cause (see Details). surv.type Either \"hazard\" (default) \"survival\".  \"hazard\" fit cause-specific Cox regression models causes.  \"survival\" fit one cause-specific Cox regression model cause interest also Cox regression model event-free survival. fitter Routine fit Cox regression models. coxph use survival::coxph else use rms::cph. ... Arguments given coxph.","code":""},{"path":"/reference/CSC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cause-specific Cox proportional hazard regression — CSC","text":"models list fitted (cause-specific) Cox regression objects response event history response eventTimes sorted (unique) event times surv.type value surv.type theCause cause interest. see cause causes causes","code":""},{"path":"/reference/CSC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cause-specific Cox proportional hazard regression — CSC","text":"causes order determined prodlim::getStates() applied Hist object.","code":""},{"path":"/reference/CSC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cause-specific Cox proportional hazard regression — CSC","text":"B. Ozenne, . L. Soerensen, T.H. Scheike, C.T. Torp-Pedersen, T.. Gerds. riskregression: Predicting risk event using Cox regression models. R Journal, 9(2):440--460, 2017. J Benichou Mitchell H Gail. Estimates absolute cause-specific risk cohort studies. Biometrics, pages 813--826, 1990. T.. Gerds, T.H. Scheike, P.K. Andersen. Absolute risk regression competing risks: Interpretation, link functions, prediction. Statistics Medicine, 31(29):3921--3930, 2012.","code":""},{"path":[]},{"path":"/reference/CSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cause-specific Cox proportional hazard regression — CSC","text":"Thomas . Gerds tag@biostat.ku.dk Ulla B. Mogensen","code":""},{"path":"/reference/CSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cause-specific Cox proportional hazard regression — CSC","text":"","code":"library(prodlim) library(survival) data(Melanoma) ## fit two cause-specific Cox models ## different formula for the two causes fit1 <- CSC(list(Hist(time,status)~sex+age,Hist(time,status)~invasion+epicel+log(thick)),             data=Melanoma) print(fit1) #> CSC(formula = list(Hist(time, status) ~ sex + age, Hist(time,  #>     status) ~ invasion + epicel + log(thick)), data = Melanoma) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ sex + age, x = TRUE,  #>     y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>             coef exp(coef) se(coef)     z Pr(>|z|)   #> sexMale 0.598259  1.818949 0.267639 2.235   0.0254 * #> age     0.016542  1.016679 0.008663 1.910   0.0562 . #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>         exp(coef) exp(-coef) lower .95 upper .95 #> sexMale     1.819     0.5498    1.0765     3.074 #> age         1.017     0.9836    0.9996     1.034 #>  #> Concordance= 0.631  (se = 0.037 ) #> Likelihood ratio test= 9.94  on 2 df,   p=0.007 #> Wald test            = 10  on 2 df,   p=0.007 #> Score (logrank) test = 10.26  on 2 df,   p=0.006 #>  #>  #>  #> ----------> Cause:  2  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     log(thick), x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 14  #>  #>                    coef exp(coef) se(coef)      z Pr(>|z|)   #> invasionlevel.1 -0.7315    0.4812   0.6492 -1.127   0.2599   #> invasionlevel.2 -2.2593    0.1044   1.2478 -1.811   0.0702 . #> epicelpresent    1.0840    2.9564   0.5738  1.889   0.0589 . #> log(thick)       0.8954    2.4484   0.3959  2.262   0.0237 * #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    0.4812     2.0781  0.134806     1.718 #> invasionlevel.2    0.1044     9.5768  0.009051     1.205 #> epicelpresent      2.9564     0.3383  0.960134     9.103 #> log(thick)         2.4484     0.4084  1.126881     5.320 #>  #> Concordance= 0.648  (se = 0.1 ) #> Likelihood ratio test= 7.41  on 4 df,   p=0.1 #> Wald test            = 7.72  on 4 df,   p=0.1 #> Score (logrank) test = 7.44  on 4 df,   p=0.1 #>  if (FALSE) { library(Publish) publish(fit1) }  ## model hazard of all cause mortality instead of hazard of type 2 fit1a <- CSC(list(Hist(time,status)~sex+age,Hist(time,status)~invasion+epicel+log(thick)),              data=Melanoma,              surv.type=\"surv\")  ## the predicted probabilities are similar plot(predictRisk(fit1,times=500,cause=1,newdata=Melanoma),      predictRisk(fit1a,times=500,cause=1,newdata=Melanoma))   ## special case where cause 2 has no covariates fit1b <- CSC(list(Hist(time,status)~sex+age,Hist(time,status)~1),              data=Melanoma) print(fit1b) #> CSC(formula = list(Hist(time, status) ~ sex + age, Hist(time,  #>     status) ~ 1), data = Melanoma) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ sex + age, x = TRUE,  #>     y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>             coef exp(coef) se(coef)     z Pr(>|z|)   #> sexMale 0.598259  1.818949 0.267639 2.235   0.0254 * #> age     0.016542  1.016679 0.008663 1.910   0.0562 . #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>         exp(coef) exp(-coef) lower .95 upper .95 #> sexMale     1.819     0.5498    1.0765     3.074 #> age         1.017     0.9836    0.9996     1.034 #>  #> Concordance= 0.631  (se = 0.037 ) #> Likelihood ratio test= 9.94  on 2 df,   p=0.007 #> Wald test            = 10  on 2 df,   p=0.007 #> Score (logrank) test = 10.26  on 2 df,   p=0.006 #>  #>  #>  #> ----------> Cause:  2  #>  #> Call:  coxph(formula = survival::Surv(time, status) ~ 1, x = TRUE, y = TRUE) #>  #> Null model #>   log likelihood= -67.29348  #>   n= 205  predict(fit1b,cause=1,times=100,newdata=Melanoma) #>      observation    sex age times absRisk #>   1:           1   Male  76   100       0 #>   2:           2   Male  56   100       0 #>   3:           3   Male  41   100       0 #>   4:           4 Female  71   100       0 #>   5:           5   Male  52   100       0 #>  ---                                      #> 201:         201   Male  29   100       0 #> 202:         202 Female  40   100       0 #> 203:         203 Female  42   100       0 #> 204:         204 Female  50   100       0 #> 205:         205 Female  41   100       0   ## same formula for both causes fit2 <- CSC(Hist(time,status)~invasion+epicel+age,             data=Melanoma) print(fit2) #> CSC(formula = Hist(time, status) ~ invasion + epicel + age, data = Melanoma) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)     #> invasionlevel.1  0.935415  2.548270  0.326212  2.868  0.00414 **  #> invasionlevel.2  1.268866  3.556818  0.384273  3.302  0.00096 *** #> epicelpresent   -0.824665  0.438382  0.301977 -2.731  0.00632 **  #> age              0.017170  1.017318  0.008795  1.952  0.05092 .   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    2.5483     0.3924    1.3445    4.8297 #> invasionlevel.2    3.5568     0.2812    1.6748    7.5536 #> epicelpresent      0.4384     2.2811    0.2426    0.7923 #> age                1.0173     0.9830    0.9999    1.0350 #>  #> Concordance= 0.696  (se = 0.036 ) #> Likelihood ratio test= 28.72  on 4 df,   p=9e-06 #> Wald test            = 25.85  on 4 df,   p=3e-05 #> Score (logrank) test = 28.07  on 4 df,   p=1e-05 #>  #>  #>  #> ----------> Cause:  2  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 14  #>  #>                     coef exp(coef) se(coef)      z Pr(>|z|)     #> invasionlevel.1 -0.91300   0.40132  0.64105 -1.424 0.154381     #> invasionlevel.2 -1.27662   0.27898  1.11701 -1.143 0.253086     #> epicelpresent    0.32241   1.38045  0.57013  0.566 0.571730     #> age              0.09323   1.09772  0.02605  3.579 0.000346 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    0.4013     2.4918   0.11424     1.410 #> invasionlevel.2    0.2790     3.5845   0.03124     2.491 #> epicelpresent      1.3804     0.7244   0.45157     4.220 #> age                1.0977     0.9110   1.04307     1.155 #>  #> Concordance= 0.83  (se = 0.046 ) #> Likelihood ratio test= 18.99  on 4 df,   p=8e-04 #> Wald test            = 14  on 4 df,   p=0.007 #> Score (logrank) test = 15.03  on 4 df,   p=0.005 #>   ## combine a cause-specific Cox regression model for cause 2 ## and a Cox regression model for the event-free survival: ## different formula for cause 2 and event-free survival fit3 <- CSC(list(Hist(time,status)~sex+invasion+epicel+age,                  Hist(time,status)~invasion+epicel+age),             surv.type=\"surv\",             data=Melanoma) print(fit3) #> CSC(formula = list(Hist(time, status) ~ sex + invasion + epicel +  #>     age, Hist(time, status) ~ invasion + epicel + age), data = Melanoma,  #>     surv.type = \"surv\") #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ sex + invasion +  #>     epicel + age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>                     coef exp(coef) se(coef)      z Pr(>|z|)     #> sexMale          0.81455   2.25817  0.27080  3.008 0.002630 **  #> invasionlevel.1  0.95491   2.59842  0.32593  2.930 0.003392 **  #> invasionlevel.2  1.37028   3.93647  0.38333  3.575 0.000351 *** #> epicelpresent   -0.96361   0.38151  0.30587 -3.150 0.001630 **  #> age              0.01624   1.01637  0.00844  1.924 0.054392 .   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> sexMale            2.2582     0.4428    1.3282    3.8394 #> invasionlevel.1    2.5984     0.3848    1.3718    4.9220 #> invasionlevel.2    3.9365     0.2540    1.8570    8.3445 #> epicelpresent      0.3815     2.6211    0.2095    0.6948 #> age                1.0164     0.9839    0.9997    1.0333 #>  #> Concordance= 0.731  (se = 0.036 ) #> Likelihood ratio test= 37.59  on 5 df,   p=5e-07 #> Wald test            = 33.68  on 5 df,   p=3e-06 #> Score (logrank) test = 35.94  on 5 df,   p=1e-06 #>  #>  #>  #> ----------> Event-free survival: #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 71  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)    #> invasionlevel.1  0.598823  1.819976  0.280176  2.137  0.03257 *  #> invasionlevel.2  0.846287  2.330977  0.345425  2.450  0.01429 *  #> epicelpresent   -0.573750  0.563408  0.254760 -2.252  0.02431 *  #> age              0.027346  1.027723  0.008348  3.276  0.00105 ** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    1.8200     0.5495     1.051    3.1517 #> invasionlevel.2    2.3310     0.4290     1.184    4.5874 #> epicelpresent      0.5634     1.7749     0.342    0.9283 #> age                1.0277     0.9730     1.011    1.0447 #>  #> Concordance= 0.682  (se = 0.032 ) #> Likelihood ratio test= 27.56  on 4 df,   p=2e-05 #> Wald test            = 26.15  on 4 df,   p=3e-05 #> Score (logrank) test = 27.02  on 4 df,   p=2e-05 #>   ## same formula for both causes fit4 <- CSC(Hist(time,status)~invasion+epicel+age,             data=Melanoma,             surv.type=\"surv\") print(fit4) #> CSC(formula = Hist(time, status) ~ invasion + epicel + age, data = Melanoma,  #>     surv.type = \"surv\") #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)     #> invasionlevel.1  0.935415  2.548270  0.326212  2.868  0.00414 **  #> invasionlevel.2  1.268866  3.556818  0.384273  3.302  0.00096 *** #> epicelpresent   -0.824665  0.438382  0.301977 -2.731  0.00632 **  #> age              0.017170  1.017318  0.008795  1.952  0.05092 .   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    2.5483     0.3924    1.3445    4.8297 #> invasionlevel.2    3.5568     0.2812    1.6748    7.5536 #> epicelpresent      0.4384     2.2811    0.2426    0.7923 #> age                1.0173     0.9830    0.9999    1.0350 #>  #> Concordance= 0.696  (se = 0.036 ) #> Likelihood ratio test= 28.72  on 4 df,   p=9e-06 #> Wald test            = 25.85  on 4 df,   p=3e-05 #> Score (logrank) test = 28.07  on 4 df,   p=1e-05 #>  #>  #>  #> ----------> Event-free survival: #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age, x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 71  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)    #> invasionlevel.1  0.598823  1.819976  0.280176  2.137  0.03257 *  #> invasionlevel.2  0.846287  2.330977  0.345425  2.450  0.01429 *  #> epicelpresent   -0.573750  0.563408  0.254760 -2.252  0.02431 *  #> age              0.027346  1.027723  0.008348  3.276  0.00105 ** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    1.8200     0.5495     1.051    3.1517 #> invasionlevel.2    2.3310     0.4290     1.184    4.5874 #> epicelpresent      0.5634     1.7749     0.342    0.9283 #> age                1.0277     0.9730     1.011    1.0447 #>  #> Concordance= 0.682  (se = 0.032 ) #> Likelihood ratio test= 27.56  on 4 df,   p=2e-05 #> Wald test            = 26.15  on 4 df,   p=3e-05 #> Score (logrank) test = 27.02  on 4 df,   p=2e-05 #>   ## strata fit5 <- CSC(Hist(time,status)~invasion+epicel+age+strata(sex),             data=Melanoma,             surv.type=\"surv\") print(fit5) #> CSC(formula = Hist(time, status) ~ invasion + epicel + age +  #>     strata(sex), data = Melanoma, surv.type = \"surv\") #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 205  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          57              0 #>   2          14              0 #>   unknown     0            134 #>  #>  #> ----------> Cause:  1  #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age + strata(sex), x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 57  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)     #> invasionlevel.1  0.962644  2.618612  0.326103  2.952 0.003158 **  #> invasionlevel.2  1.341972  3.826581  0.385085  3.485 0.000492 *** #> epicelpresent   -0.966928  0.380249  0.307215 -3.147 0.001647 **  #> age              0.016206  1.016338  0.008442  1.920 0.054916 .   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    2.6186     0.3819    1.3819    4.9619 #> invasionlevel.2    3.8266     0.2613    1.7990    8.1395 #> epicelpresent      0.3802     2.6299    0.2082    0.6943 #> age                1.0163     0.9839    0.9997    1.0333 #>  #> Concordance= 0.716  (se = 0.036 ) #> Likelihood ratio test= 31.18  on 4 df,   p=3e-06 #> Wald test            = 27.78  on 4 df,   p=1e-05 #> Score (logrank) test = 30.19  on 4 df,   p=4e-06 #>  #>  #>  #> ----------> Event-free survival: #>  #> Call: #> coxph(formula = survival::Surv(time, status) ~ invasion + epicel +  #>     age + strata(sex), x = TRUE, y = TRUE) #>  #>   n= 205, number of events= 71  #>  #>                      coef exp(coef)  se(coef)      z Pr(>|z|)    #> invasionlevel.1  0.638422  1.893491  0.280113  2.279  0.02266 *  #> invasionlevel.2  0.921428  2.512877  0.347222  2.654  0.00796 ** #> epicelpresent   -0.699726  0.496721  0.259302 -2.698  0.00697 ** #> age              0.025606  1.025937  0.008091  3.165  0.00155 ** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>                 exp(coef) exp(-coef) lower .95 upper .95 #> invasionlevel.1    1.8935     0.5281    1.0935    3.2787 #> invasionlevel.2    2.5129     0.3980    1.2724    4.9628 #> epicelpresent      0.4967     2.0132    0.2988    0.8257 #> age                1.0259     0.9747    1.0098    1.0423 #>  #> Concordance= 0.702  (se = 0.031 ) #> Likelihood ratio test= 28.77  on 4 df,   p=9e-06 #> Wald test            = 27.35  on 4 df,   p=2e-05 #> Score (logrank) test = 28.17  on 4 df,   p=1e-05 #>   ## sanity checks  cox1 <- coxph(Surv(time,status==1)~invasion+epicel+age+strata(sex),data=Melanoma) cox2 <- coxph(Surv(time,status!=0)~invasion+epicel+age+strata(sex),data=Melanoma) all.equal(coef(cox1),coef(fit5$models[[1]])) #> [1] TRUE all.equal(coef(cox2),coef(fit5$models[[2]])) #> [1] TRUE  ## predictions ## ## surv.type = \"hazard\": predictions for both causes can be extracted ## from the same fit fit2 <- CSC(Hist(time,status)~invasion+epicel+age, data=Melanoma) predict(fit2,cause=1,newdata=Melanoma[c(17,99,108),],times=c(100,1000,10000)) #>    observation invasion      epicel age times absRisk #> 1:           1  level.1 not present  46   100  0.0000 #> 2:           2  level.1 not present  34   100  0.0000 #> 3:           3  level.0     present  58   100  0.0000 #> 4:           1  level.1 not present  46  1000  0.1928 #> 5:           2  level.1 not present  34  1000  0.1603 #> 6:           3  level.0     present  58  1000  0.0427 #> 7:           1  level.1 not present  46 10000      NA #> 8:           2  level.1 not present  34 10000      NA #> 9:           3  level.0     present  58 10000      NA predictRisk(fit2,cause=1,newdata=Melanoma[c(17,99,108),],times=c(100,1000,10000)) #>      [,1]       [,2] [,3] #> [1,]    0 0.19283566   NA #> [2,]    0 0.16026171   NA #> [3,]    0 0.04268555   NA predictRisk(fit2,cause=2,newdata=Melanoma[c(17,99,108),],times=c(100,1000,10000)) #>              [,1]        [,2] [,3] #> [1,] 0.0018172532 0.004281110   NA #> [2,] 0.0005938955 0.001411264   NA #> [3,] 0.0190247785 0.045781785   NA predict(fit2,cause=1,newdata=Melanoma[c(17,99,108),],times=c(100,1000,10000)) #>    observation invasion      epicel age times absRisk #> 1:           1  level.1 not present  46   100  0.0000 #> 2:           2  level.1 not present  34   100  0.0000 #> 3:           3  level.0     present  58   100  0.0000 #> 4:           1  level.1 not present  46  1000  0.1928 #> 5:           2  level.1 not present  34  1000  0.1603 #> 6:           3  level.0     present  58  1000  0.0427 #> 7:           1  level.1 not present  46 10000      NA #> 8:           2  level.1 not present  34 10000      NA #> 9:           3  level.0     present  58 10000      NA predict(fit2,cause=2,newdata=Melanoma[c(17,99,108),],times=c(100,1000,10000)) #>    observation invasion      epicel age times  absRisk #> 1:           1  level.1 not present  46   100 0.001817 #> 2:           2  level.1 not present  34   100 0.000594 #> 3:           3  level.0     present  58   100 0.019025 #> 4:           1  level.1 not present  46  1000 0.004281 #> 5:           2  level.1 not present  34  1000 0.001411 #> 6:           3  level.0     present  58  1000 0.045782 #> 7:           1  level.1 not present  46 10000       NA #> 8:           2  level.1 not present  34 10000       NA #> 9:           3  level.0     present  58 10000       NA  ## surv.type = \"surv\" we need to change the cause of interest library(survival) fit5.2 <- CSC(Hist(time,status)~invasion+epicel+age+strata(sex),             data=Melanoma,             surv.type=\"surv\",cause=2) ## now this does not work try(predictRisk(fit5.2,cause=1,newdata=Melanoma,times=4)) #> Error in predict.CauseSpecificCox(object = object, newdata = newdata,  :  #>   Object can be used to predict cause 2 but not 1. #> Note: the cause can be specified in CSC(...,cause=).  ## but this does predictRisk(fit5.2,cause=2,newdata=Melanoma,times=100) #>                [,1] #>   [1,] 6.024245e-02 #>   [2,] 1.673423e-02 #>   [3,] 1.835066e-03 #>   [4,] 2.895922e-02 #>   [5,] 4.164144e-03 #>   [6,] 3.517575e-04 #>   [7,] 4.226097e-02 #>   [8,] 2.463623e-03 #>   [9,] 4.611868e-03 #>  [10,] 2.191509e-02 #>  [11,] 2.406810e-03 #>  [12,] 1.511304e-02 #>  [13,] 2.191509e-02 #>  [14,] 1.154850e-02 #>  [15,] 6.425035e-05 #>  [16,] 2.659387e-02 #>  [17,] 2.917383e-03 #>  [18,] 2.068914e-02 #>  [19,] 1.724844e-01 #>  [20,] 3.914382e-03 #>  [21,] 6.822831e-02 #>  [22,] 1.200253e-03 #>  [23,] 1.266319e-03 #>  [24,] 2.208993e-03 #>  [25,] 2.239422e-02 #>  [26,] 2.541578e-02 #>  [27,] 6.570964e-02 #>  [28,] 3.180427e-03 #>  [29,] 7.736975e-05 #>  [30,] 1.102360e-03 #>  [31,] 2.110609e-02 #>  [32,] 5.087808e-03 #>  [33,] 2.014573e-02 #>  [34,] 2.956986e-03 #>  [35,] 1.835710e-02 #>  [36,] 1.858209e-02 #>  [37,] 2.383689e-04 #>  [38,] 1.860938e-02 #>  [39,] 3.180427e-03 #>  [40,] 8.437599e-03 #>  [41,] 3.829844e-03 #>  [42,] 1.693350e-02 #>  [43,] 4.705314e-03 #>  [44,] 4.487192e-02 #>  [45,] 6.388287e-04 #>  [46,] 1.034547e-01 #>  [47,] 2.135234e-02 #>  [48,] 1.154850e-02 #>  [49,] 1.354302e-02 #>  [50,] 6.435496e-02 #>  [51,] 1.980824e-01 #>  [52,] 2.595079e-02 #>  [53,] 2.110609e-02 #>  [54,] 5.060864e-03 #>  [55,] 5.634319e-04 #>  [56,] 3.490063e-03 #>  [57,] 3.291931e-03 #>  [58,] 1.644268e-03 #>  [59,] 4.960533e-04 #>  [60,] 1.256050e-03 #>  [61,] 9.505245e-04 #>  [62,] 1.234149e-02 #>  [63,] 1.836095e-02 #>  [64,] 7.887092e-03 #>  [65,] 6.549697e-03 #>  [66,] 3.829844e-03 #>  [67,] 7.543867e-04 #>  [68,] 2.541578e-02 #>  [69,] 6.687805e-04 #>  [70,] 5.348562e-03 #>  [71,] 7.730730e-04 #>  [72,] 1.152500e-01 #>  [73,] 2.898261e-03 #>  [74,] 3.722244e-04 #>  [75,] 8.654954e-03 #>  [76,] 1.754134e-03 #>  [77,] 5.968612e-03 #>  [78,] 8.591512e-03 #>  [79,] 3.149017e-03 #>  [80,] 1.783821e-03 #>  [81,] 3.180427e-03 #>  [82,] 1.924911e-03 #>  [83,] 2.423611e-03 #>  [84,] 1.486153e-02 #>  [85,] 2.068766e-03 #>  [86,] 1.616160e-02 #>  [87,] 9.339511e-03 #>  [88,] 1.390024e-02 #>  [89,] 3.789563e-02 #>  [90,] 3.750888e-03 #>  [91,] 8.335454e-03 #>  [92,] 6.823073e-03 #>  [93,] 1.152500e-01 #>  [94,] 2.425237e-02 #>  [95,] 1.070093e-03 #>  [96,] 1.434706e-02 #>  [97,] 1.300086e-03 #>  [98,] 8.053401e-04 #>  [99,] 4.119387e-04 #> [100,] 6.823073e-03 #> [101,] 1.042223e-02 #> [102,] 1.264383e-01 #> [103,] 1.819900e-02 #> [104,] 9.426792e-03 #> [105,] 1.858209e-02 #> [106,] 4.960533e-04 #> [107,] 1.154605e-02 #> [108,] 1.101470e-02 #> [109,] 1.885227e-03 #> [110,] 2.869300e-02 #> [111,] 3.789563e-02 #> [112,] 2.193280e-03 #> [113,] 1.525157e-02 #> [114,] 2.316091e-02 #> [115,] 2.383616e-03 #> [116,] 5.495746e-03 #> [117,] 3.177860e-02 #> [118,] 8.654954e-03 #> [119,] 3.361226e-03 #> [120,] 8.483369e-04 #> [121,] 3.291931e-03 #> [122,] 1.284933e-02 #> [123,] 1.147444e-02 #> [124,] 5.748279e-03 #> [125,] 5.149310e-02 #> [126,] 9.505245e-04 #> [127,] 5.988205e-03 #> [128,] 7.755833e-03 #> [129,] 3.095398e-02 #> [130,] 1.821370e-03 #> [131,] 3.791371e-03 #> [132,] 5.666101e-03 #> [133,] 1.064161e-02 #> [134,] 2.155038e-02 #> [135,] 4.773557e-03 #> [136,] 3.964116e-03 #> [137,] 1.957488e-03 #> [138,] 5.968612e-03 #> [139,] 3.242623e-02 #> [140,] 2.586680e-03 #> [141,] 2.041436e-02 #> [142,] 3.418111e-03 #> [143,] 9.587239e-04 #> [144,] 2.357191e-03 #> [145,] 8.965628e-04 #> [146,] 8.661945e-04 #> [147,] 4.678921e-04 #> [148,] 1.101470e-02 #> [149,] 7.251235e-02 #> [150,] 3.726896e-02 #> [151,] 7.831306e-02 #> [152,] 1.021560e-03 #> [153,] 1.143690e-02 #> [154,] 2.641130e-03 #> [155,] 7.445348e-04 #> [156,] 3.514603e-02 #> [157,] 2.618734e-03 #> [158,] 3.726896e-02 #> [159,] 7.730730e-04 #> [160,] 8.740575e-03 #> [161,] 4.034461e-04 #> [162,] 1.114791e-02 #> [163,] 1.511304e-02 #> [164,] 1.426658e-03 #> [165,] 3.829844e-03 #> [166,] 1.230155e-03 #> [167,] 7.830219e-03 #> [168,] 5.060864e-03 #> [169,] 2.095445e-03 #> [170,] 3.396506e-02 #> [171,] 5.869281e-03 #> [172,] 2.733726e-03 #> [173,] 1.234149e-02 #> [174,] 2.537447e-05 #> [175,] 2.425237e-02 #> [176,] 1.223256e-02 #> [177,] 3.226668e-04 #> [178,] 7.595938e-03 #> [179,] 5.850284e-04 #> [180,] 2.135234e-02 #> [181,] 1.042223e-02 #> [182,] 8.053401e-04 #> [183,] 8.661945e-04 #> [184,] 1.184743e-03 #> [185,] 9.146967e-03 #> [186,] 7.972720e-05 #> [187,] 1.231149e-04 #> [188,] 6.616609e-03 #> [189,] 3.750888e-03 #> [190,] 2.898364e-04 #> [191,] 2.013372e-03 #> [192,] 3.964116e-03 #> [193,] 1.354302e-02 #> [194,] 1.789676e-03 #> [195,] 1.472864e-02 #> [196,] 6.419849e-04 #> [197,] 9.083777e-04 #> [198,] 8.591512e-03 #> [199,] 4.427243e-04 #> [200,] 2.310460e-04 #> [201,] 4.927806e-04 #> [202,] 5.869489e-04 #> [203,] 2.491192e-03 #> [204,] 4.116062e-03 #> [205,] 7.893463e-04 predict(fit5.2,cause=2,newdata=Melanoma,times=100) #>      observation invasion      epicel age    sex times     strata  absRisk #>   1:           1  level.1     present  76   Male   100   sex=Male 0.060242 #>   2:           2  level.0 not present  56   Male   100   sex=Male 0.016734 #>   3:           3  level.1 not present  41   Male   100   sex=Male 0.001835 #>   4:           4  level.0 not present  71 Female   100 sex=Female 0.028959 #>   5:           5  level.2     present  52   Male   100   sex=Male 0.004164 #>  ---                                                                       #> 201:         201  level.2     present  29   Male   100   sex=Male 0.000493 #> 202:         202  level.2     present  40 Female   100 sex=Female 0.000587 #> 203:         203  level.0     present  42 Female   100 sex=Female 0.002491 #> 204:         204  level.0 not present  50 Female   100 sex=Female 0.004116 #> 205:         205  level.1 not present  41 Female   100 sex=Female 0.000789 predict(fit5.2,cause=2,newdata=Melanoma[4,],times=100) #>    observation invasion      epicel age    sex times     strata absRisk #> 1:           1  level.0 not present  71 Female   100 sex=Female   0.029"},{"path":"/reference/Cforest.html","id":null,"dir":"Reference","previous_headings":"","what":"S3-wrapper function for cforest from the party package — Cforest","title":"S3-wrapper function for cforest from the party package — Cforest","text":"S3-wrapper function cforest party package","code":""},{"path":"/reference/Cforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3-wrapper function for cforest from the party package — Cforest","text":"","code":"Cforest(formula, data, ...)"},{"path":"/reference/Cforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3-wrapper function for cforest from the party package — Cforest","text":"formula Passed . See cforest party package data Passed . See cforest party package ... Passed . See cforest party package","code":""},{"path":"/reference/Cforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3-wrapper function for cforest from the party package — Cforest","text":"list two elements: cforest call","code":""},{"path":"/reference/Cforest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"S3-wrapper function for cforest from the party package — Cforest","text":"See cforest party package.","code":""},{"path":"/reference/Cforest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"S3-wrapper function for cforest from the party package — Cforest","text":"Ulla B. Mogensen, Hemant Ishwaran, Thomas . Gerds (2012). Evaluating Random Forests Survival Analysis Using Prediction Error Curves. Journal Statistical Software, 50(11), 1-23. URL http://www.jstatsoft.org/v50/i11/.","code":""},{"path":"/reference/Ctree.html","id":null,"dir":"Reference","previous_headings":"","what":"S3-Wrapper for ctree. — Ctree","title":"S3-Wrapper for ctree. — Ctree","text":"call added ctree object","code":""},{"path":"/reference/Ctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3-Wrapper for ctree. — Ctree","text":"","code":"Ctree(...)"},{"path":"/reference/Ctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3-Wrapper for ctree. — Ctree","text":"... passed ctree","code":""},{"path":"/reference/Ctree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3-Wrapper for ctree. — Ctree","text":"list two elements: ctree call","code":""},{"path":[]},{"path":"/reference/Ctree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"S3-Wrapper for ctree. — Ctree","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/Ctree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S3-Wrapper for ctree. — Ctree","text":"","code":"if (requireNamespace(\"party\",quietly=TRUE)){ library(prodlim) library(party) library(survival) set.seed(50) d <- SimSurv(50) nd <- data.frame(X1=c(0,1,0),X2=c(-1,0,1)) f <- Ctree(Surv(time,status)~X1+X2,data=d) predictRisk(f,newdata=nd,times=c(3,8)) } #> Registered S3 method overwritten by 'coin': #>   method   from    #>   print.ci Publish #> Loading required package: grid #> Loading required package: mvtnorm #> Loading required package: modeltools #> Loading required package: stats4 #> Loading required package: strucchange #> Loading required package: zoo #>  #> Attaching package: ‘zoo’ #> The following objects are masked from ‘package:base’: #>  #>     as.Date, as.Date.numeric #> Loading required package: sandwich #>            [,1]      [,2] #> [1,] 0.09090909 0.2975207 #> [2,] 0.00000000 0.7460317 #> [3,] 0.33333333 0.7777778"},{"path":"/reference/FGR.html","id":null,"dir":"Reference","previous_headings":"","what":"Formula wrapper for crr from cmprsk — FGR","title":"Formula wrapper for crr from cmprsk — FGR","text":"Formula interface Fine-Gray regression competing risk models.","code":""},{"path":"/reference/FGR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Formula wrapper for crr from cmprsk — FGR","text":"","code":"FGR(formula, data, cause = 1, y = TRUE, ...)"},{"path":"/reference/FGR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Formula wrapper for crr from cmprsk — FGR","text":"formula formula whose left hand side Hist object -- see Hist.  right hand side specifies (linear combination ) covariates. See examples . data data.frame variables formula can interpreted. cause failure type interest. Defaults 1. y logical value: TRUE, response vector returned component response. ... ...","code":""},{"path":"/reference/FGR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Formula wrapper for crr from cmprsk — FGR","text":"See crr.","code":""},{"path":"/reference/FGR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Formula wrapper for crr from cmprsk — FGR","text":"Formula interface function crr cmprsk package. function crr allows multiply covariates time enter linear predictor. can achieved formula interface, however, code becomes little cumbersome. See examples. Note FGR allow delayed entry (left-truncation).","code":""},{"path":"/reference/FGR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Formula wrapper for crr from cmprsk — FGR","text":"Gerds, TA Scheike, T Andersen, PK (2011) Absolute risk regression competing risks: interpretation, link functions prediction Research report 11/7. Department Biostatistics, University Copenhagen","code":""},{"path":[]},{"path":"/reference/FGR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Formula wrapper for crr from cmprsk — FGR","text":"Thomas Alexander Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/FGR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Formula wrapper for crr from cmprsk — FGR","text":"","code":"library(prodlim) library(survival) library(cmprsk) library(lava) #>  #> Attaching package: ‘lava’ #> The following objects are masked from ‘package:zoo’: #>  #>     index, index<- d <- prodlim::SimCompRisk(100) f1 <- FGR(Hist(time,cause)~X1+X2,data=d) #> Argument cause missing. Analyse cause: 1 print(f1) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ X1 + X2, data = d, cause = \"1\") #>  #>     coef exp(coef) se(coef)    z p-value #> X1 0.834      2.30    0.309 2.70 6.9e-03 #> X2 0.723      2.06    0.137 5.28 1.3e-07 #>  #>    exp(coef) exp(-coef) 2.5% 97.5% #> X1      2.30      0.434 1.26  4.22 #> X2      2.06      0.485 1.58  2.69 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -190  #> Pseudo likelihood ratio test = 28.3  on 2 df, #>  #> Convergence: TRUE  #>   ## crr allows that some covariates are multiplied by ## a function of time (see argument tf of crr) ## by FGR uses the identity matrix f2 <- FGR(Hist(time,cause)~cov2(X1)+X2,data=d) #> Argument cause missing. Analyse cause: 1 print(f2) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ cov2(X1) + X2, data = d, cause = \"1\") #>  #>         coef exp(coef) se(coef)    z p-value #> X2     0.740      2.10   0.1368 5.41 6.4e-08 #> X1*tf1 0.135      1.14   0.0613 2.21 2.7e-02 #>  #>        exp(coef) exp(-coef) 2.5% 97.5% #> X2          2.10      0.477 1.60  2.74 #> X1*tf1      1.14      0.873 1.02  1.29 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -191  #> Pseudo likelihood ratio test = 25.8  on 2 df, #>  #> Convergence: TRUE  #>   ## same thing, but more explicit: f3 <- FGR(Hist(time,cause)~cov2(X1)+cov1(X2),data=d) #> Argument cause missing. Analyse cause: 1 print(f3) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ cov2(X1) + cov1(X2), data = d,  #>     cause = \"1\") #>  #>         coef exp(coef) se(coef)    z p-value #> X2     0.740      2.10   0.1368 5.41 6.4e-08 #> X1*tf1 0.135      1.14   0.0613 2.21 2.7e-02 #>  #>        exp(coef) exp(-coef) 2.5% 97.5% #> X2          2.10      0.477 1.60  2.74 #> X1*tf1      1.14      0.873 1.02  1.29 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -191  #> Pseudo likelihood ratio test = 25.8  on 2 df, #>  #> Convergence: TRUE  #>   ## both variables can enter cov2: f4 <- FGR(Hist(time,cause)~cov2(X1)+cov2(X2),data=d) #> Argument cause missing. Analyse cause: 1 print(f4) #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ cov2(X1) + cov2(X2), data = d,  #>     cause = \"1\") #>  #>          coef exp(coef) se(coef)    z p-value #> X1*tf1 0.1361      1.15   0.0611 2.23   0.026 #> X2*tf2 0.0985      1.10   0.0434 2.27   0.023 #>  #>        exp(coef) exp(-coef) 2.5% 97.5% #> X1*tf1      1.15      0.873 1.02  1.29 #> X2*tf2      1.10      0.906 1.01  1.20 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -198  #> Pseudo likelihood ratio test = 12.1  on 2 df, #>  #> Convergence: TRUE  #>   ## change the function of time qFun <- function(x){x^2} noFun <- function(x){x} sqFun <- function(x){x^0.5}  ## multiply X1 by time^2 and X2 by time: f5 <- FGR(Hist(time,cause)~cov2(X1,tf=qFun)+cov2(X2),data=d) #> Argument cause missing. Analyse cause: 1 #> Error in qFun(c(0.223312599010185, 0.844653052602936, 0.86743957909998, 0.869654848917858, 1.4718454380646, 1.47986846377743, 1.56788544286003, 1.57284176822651, 1.71280654079967, 1.7446175554818, 2.08017045127398, 2.11900022748555, 2.34027091945108, 2.44735526652256, 2.47481572672078, 2.69072148768644, 2.69930631257876, 2.82681955875637, 2.86986677073091, 3.28835303045329, 3.38016548882937, 3.42930837661085, 3.57927210122299, 3.61310741873331, 3.71589696889436, 3.82638651755888, 4.13125614409393, 4.22817648821086, 4.69740197012358, 4.75934581546958, 4.7989296471193, 5.09144457759695, 5.20599159981632, 5.27409575450788, 5.37841476839829, 5.45365210472182, 5.47792252614271, 5.8344164585106, 6.03541407396753, 6.63251816105419, 6.92722896832721, 7.2931295159595, 7.59440495376659, 7.82755206098875, 8.10614220085668, 8.1127149986577, 8.83868607919211, 9.05983471886304, 9.33426459771812, 10.6845775000325)): could not find function \"qFun\" print(f5) #> Error in print(f5): object 'f5' not found print(f5$crrFit) #> Error in print(f5$crrFit): object 'f5' not found ## same results as crr with(d,crr(ftime=time,            fstatus=cause,            cov2=d[,c(\"X1\",\"X2\")],            tf=function(time){cbind(qFun(time),time)})) #> convergence:  TRUE  #> coefficients: #>  X1*tf1 X2*time  #> 0.01259 0.09674  #> standard errors: #> [1] 0.00853 0.04345 #> two-sided p-values: #>  X1*tf1 X2*time  #>   0.140   0.026   ## still same result, but more explicit f5a <- FGR(Hist(time,cause)~cov2(X1,tf=qFun)+cov2(X2,tf=noFun),data=d) #> Argument cause missing. Analyse cause: 1 #> Error in qFun(c(0.223312599010185, 0.844653052602936, 0.86743957909998, 0.869654848917858, 1.4718454380646, 1.47986846377743, 1.56788544286003, 1.57284176822651, 1.71280654079967, 1.7446175554818, 2.08017045127398, 2.11900022748555, 2.34027091945108, 2.44735526652256, 2.47481572672078, 2.69072148768644, 2.69930631257876, 2.82681955875637, 2.86986677073091, 3.28835303045329, 3.38016548882937, 3.42930837661085, 3.57927210122299, 3.61310741873331, 3.71589696889436, 3.82638651755888, 4.13125614409393, 4.22817648821086, 4.69740197012358, 4.75934581546958, 4.7989296471193, 5.09144457759695, 5.20599159981632, 5.27409575450788, 5.37841476839829, 5.45365210472182, 5.47792252614271, 5.8344164585106, 6.03541407396753, 6.63251816105419, 6.92722896832721, 7.2931295159595, 7.59440495376659, 7.82755206098875, 8.10614220085668, 8.1127149986577, 8.83868607919211, 9.05983471886304, 9.33426459771812, 10.6845775000325)): could not find function \"qFun\" f5a$crrFit #> Error in eval(expr, envir, enclos): object 'f5a' not found  ## multiply X1 by time^2 and X2 by sqrt(time) f5b <- FGR(Hist(time,cause)~cov2(X1,tf=qFun)+cov2(X2,tf=sqFun),data=d,cause=1) #> Error in qFun(c(0.223312599010185, 0.844653052602936, 0.86743957909998, 0.869654848917858, 1.4718454380646, 1.47986846377743, 1.56788544286003, 1.57284176822651, 1.71280654079967, 1.7446175554818, 2.08017045127398, 2.11900022748555, 2.34027091945108, 2.44735526652256, 2.47481572672078, 2.69072148768644, 2.69930631257876, 2.82681955875637, 2.86986677073091, 3.28835303045329, 3.38016548882937, 3.42930837661085, 3.57927210122299, 3.61310741873331, 3.71589696889436, 3.82638651755888, 4.13125614409393, 4.22817648821086, 4.69740197012358, 4.75934581546958, 4.7989296471193, 5.09144457759695, 5.20599159981632, 5.27409575450788, 5.37841476839829, 5.45365210472182, 5.47792252614271, 5.8344164585106, 6.03541407396753, 6.63251816105419, 6.92722896832721, 7.2931295159595, 7.59440495376659, 7.82755206098875, 8.10614220085668, 8.1127149986577, 8.83868607919211, 9.05983471886304, 9.33426459771812, 10.6845775000325)): could not find function \"qFun\"  ## additional arguments for crr f6<- FGR(Hist(time,cause)~X1+X2,data=d, cause=1,gtol=1e-5) f6 #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ X1 + X2, data = d, cause = 1,  #>     gtol = 1e-05) #>  #>     coef exp(coef) se(coef)    z p-value #> X1 0.834      2.30    0.309 2.70 6.9e-03 #> X2 0.723      2.06    0.137 5.28 1.3e-07 #>  #>    exp(coef) exp(-coef) 2.5% 97.5% #> X1      2.30      0.434 1.26  4.22 #> X2      2.06      0.485 1.58  2.69 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -190  #> Pseudo likelihood ratio test = 28.3  on 2 df, #>  #> Convergence: TRUE  #>  f6a<- FGR(Hist(time,cause)~X1+X2,data=d, cause=1,gtol=0.1) f6a #>  #> Right-censored response of a competing.risks model #>  #> No.Observations: 100  #>  #> Pattern: #>           #> Cause     event right.censored #>   1          50              0 #>   2          29              0 #>   unknown     0             21 #>  #>  #> Fine-Gray model: analysis of cause 1  #>  #> Competing Risks Regression #>  #> Call: #> FGR(formula = Hist(time, cause) ~ X1 + X2, data = d, cause = 1,  #>     gtol = 0.1) #>  #>     coef exp(coef) se(coef)    z p-value #> X1 0.895      2.45    0.316 2.83 4.7e-03 #> X2 0.774      2.17    0.141 5.48 4.1e-08 #>  #>    exp(coef) exp(-coef) 2.5% 97.5% #> X1      2.45      0.409 1.32  4.55 #> X2      2.17      0.461 1.64  2.86 #>  #> Num. cases = 100 #> Pseudo Log-likelihood = -190  #> Pseudo likelihood ratio test = 28.1  on 2 df, #>  #> Convergence: TRUE  #>"},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"Fast computation influence function Nelson-Aalen estimator censoring times","code":""},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"","code":"IC_Nelson_Aalen_cens_time(time, status)"},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"time sorted vector event times. Sorted according time -status events come first tied times. status sorted vector 0 = censored 1 = event (cause). Sorted according time -status events come first tied times.","code":""},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"square matrix column corresponds subject row time point.","code":""},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/IC_Nelson_Aalen_cens_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Influence function for Nelson-Aalen estimator. — IC_Nelson_Aalen_cens_time","text":"","code":"time = c(1,3,3,4) status = c(1,0,1,1) IC_Nelson_Aalen_cens_time(time,status) #>      [,1]      [,2]       [,3]       [,4] #> [1,]    0 0.0000000  0.0000000  0.0000000 #> [2,]    0 0.8888889 -0.4444444 -0.4444444 #> [3,]    0 0.8888889 -0.4444444 -0.4444444"},{"path":"/reference/IPA.html","id":null,"dir":"Reference","previous_headings":"","what":"Explained variation for settings with binary, survival and competing risk outcome — IPA","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"Index Prediction Accuracy: General R^2 binary outcome right censored time event (survival) outcome also competing risks","code":""},{"path":"/reference/IPA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"","code":"rsquared(object,...) IPA(object,...) # S3 method for default rsquared(object,formula,newdata,times,cause,...) # S3 method for glm rsquared(object,formula,newdata,...) # S3 method for coxph rsquared(object,formula,newdata,times,...) # S3 method for CauseSpecificCox rsquared(object,formula,newdata,times,cause,...) # S3 method for default IPA(object,formula,newdata,times,cause,...) # S3 method for glm IPA(object,formula,newdata,...) # S3 method for coxph IPA(object,formula,newdata,times,...) # S3 method for CauseSpecificCox IPA(object,formula,newdata,times,cause,...)"},{"path":"/reference/IPA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"object Model want IPA. ... passed riskRegression::Score newdata Optional validation data set compute IPA formula Formula passed Score. provided, try use formula call object, . cause competing risk models event interest times Vector time points used prediction horizon computation Brier scores.","code":""},{"path":"/reference/IPA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"Data frame explained variation values full model.","code":""},{"path":"/reference/IPA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"IPA (R^2) calculated based model's predicted risks. Brier score model compared Brier score null model.","code":""},{"path":[]},{"path":"/reference/IPA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/IPA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explained variation for settings with binary, survival and competing risk outcome — IPA","text":"","code":"library(prodlim) library(data.table) # binary outcome library(lava) set.seed(18) learndat <- sampleData(48,outcome=\"binary\") lr1 = glm(Y~X1+X2+X7+X9,data=learndat,family=binomial) IPA(lr1) #> Error in eval(object$call$data): object 'learndat' not found  ## validation data valdat=sampleData(94,outcome=\"binary\") IPA(lr1,newdata=valdat) #>      Variable Brier  IPA IPA.drop #> 1: Null model  23.6  0.0     -1.3 #> 2: Full model  23.9 -1.3      0.0 #> 3:         X1  23.9 -0.9     -0.3 #> 4:         X2  23.2  1.9     -3.1 #> 5:         X7  24.0 -1.7      0.4 #> 6:         X9  23.5  0.5     -1.8 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.  ## predicted risks externally given p1=predictRisk(lr1,newdata=valdat) IPA(p1,formula=Y~1,valdat) #>         model Brier  IPA #> 1: Null model  23.6  0.0 #> 2:    numeric  23.9 -1.3 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.  # survival library(survival) data(pbc) pbc=na.omit(pbc) pbctest=(1:NROW(pbc)) %in% sample(1:NROW(pbc),size=.632*NROW(pbc)) pbclearn=pbc[pbctest,] cox1= coxph(Surv(time,status!=0)~age+sex+log(bili)+log(albumin)+log(protime),       data=pbclearn,x=TRUE)  ## same data IPA(cox1,formula=Surv(time,status!=0)~1,times=1000) #> Error in eval(object$call$data): object 'pbclearn' not found  ## validation data pbcval=pbc[!pbctest,] IPA(cox1,formula=Surv(time,status!=0)~1,newdata=pbcval,times=1000) #>        Variable times Brier  IPA IPA.drop #> 1:   Null model  1000  18.5  0.0     25.1 #> 2:   Full model  1000  13.9 25.1      0.0 #> 3:          age  1000  14.0 24.4      0.6 #> 4:          sex  1000  13.9 24.8      0.3 #> 5:    log(bili)  1000  15.2 18.0      7.1 #> 6: log(albumin)  1000  13.7 25.9     -0.8 #> 7: log(protime)  1000  14.2 23.4      1.7 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.  ## predicted risks externally given p2=predictRisk(cox1,newdata=pbcval,times=1000) IPA(cox1,formula=Surv(time,status!=0)~1,newdata=pbcval,times=1000) #>        Variable times Brier  IPA IPA.drop #> 1:   Null model  1000  18.5  0.0     25.1 #> 2:   Full model  1000  13.9 25.1      0.0 #> 3:          age  1000  14.0 24.4      0.6 #> 4:          sex  1000  13.9 24.8      0.3 #> 5:    log(bili)  1000  15.2 18.0      7.1 #> 6: log(albumin)  1000  13.7 25.9     -0.8 #> 7: log(protime)  1000  14.2 23.4      1.7 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.   # competing risks data(Melanoma) Melanomatest=(1:NROW(Melanoma)) %in% sample(1:NROW(Melanoma),size=.632*NROW(Melanoma)) Melanomalearn=Melanoma[Melanomatest,] fit1 <- CSC(list(Hist(time,status)~sex,                  Hist(time,status)~invasion+epicel+age),                  data=Melanoma) IPA(fit1,times=1000,cause=2) #>      Variable times Brier  IPA IPA.drop #> 1: Null model  1000   3.3  0.0      2.9 #> 2: Full model  1000   3.2  2.9      0.0 #> 3:        sex  1000   3.2  2.8      0.1 #> 4:   invasion  1000   3.2  4.0     -1.2 #> 5:     epicel  1000   3.2  3.1     -0.2 #> 6:        age  1000   3.3 -0.8      3.6 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.  ## validation data Melanomaval=Melanoma[!Melanomatest,] IPA(fit1,formula=Hist(time,status)~1,newdata=Melanomaval,times=1000) #>      Variable times Brier  IPA IPA.drop #> 1: Null model  1000  11.6  0.0      4.6 #> 2: Full model  1000  11.0  4.6      0.0 #> 3:        sex  1000  11.6 -0.0      4.6 #> 4:   invasion  1000  11.0  4.4      0.2 #> 5:     epicel  1000  11.0  4.5      0.1 #> 6:        age  1000  11.0  4.6     -0.0 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model.  ## predicted risks externally given p3= predictRisk(fit1,cause=1,newdata=Melanomaval,times=1000) IPA(p3,formula=Hist(time,status)~1,cause=1,newdata=Melanomaval,times=1000) #>         model times Brier IPA #> 1: Null model  1000  11.6 0.0 #> 2:     matrix  1000  11.0 4.6 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher IPA the better. #> NOTE: IPA.drop = IPA(Full model) - IPA. The higher the drop #> the more important is the variable for the full model."},{"path":"/reference/Melanoma.html","id":null,"dir":"Reference","previous_headings":"","what":"Malignant melanoma data — Melanoma","title":"Malignant melanoma data — Melanoma","text":"period 1962-77, 205 patients malignant melanoma (cancer skin) radical operation performed Odense University Hospital, Denmark. patients followed end 1977 time 134 still alive 71 died (57 died cancer 14 causes).","code":""},{"path":"/reference/Melanoma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Malignant melanoma data — Melanoma","text":"data frame 205 observations following 12 variables. time time days operation status numeric values 0=censored 1=death.malignant.melanoma 2=death..causes event factor levels censored death.malignant.melanoma death..causes invasion factor levels level.0, level.1, level.2 ici inflammatory cell infiltration (IFI): 0, 1, 2 3 epicel factor levels present present ulcer factor levels present present thick tumour thickness (1/100 mm) sex factor levels Female Male age age operation (years) logthick tumour thickness log-scale","code":""},{"path":"/reference/Melanoma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Malignant melanoma data — Melanoma","text":"object study assess effect risk factors survival. Among risk factors sex age patients histological variables tumor thickness ulceration (absent vs. present).","code":""},{"path":"/reference/Melanoma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Malignant melanoma data — Melanoma","text":"Regression linear predictors (2010) Andersen, P.K. Skovgaard, L.T. Springer Verlag","code":""},{"path":"/reference/Melanoma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Malignant melanoma data — Melanoma","text":"","code":"data(Melanoma)"},{"path":"/reference/Paquid.html","id":null,"dir":"Reference","previous_headings":"","what":"Paquid sample — Paquid","title":"Paquid sample — Paquid","text":"PAQUID prospective cohort study initiated 1988 South Western France explore functional cerebral ageing. sample includes n=2561 subjects. Data contains time--event, type event two cognitive scores measured baseline.","code":""},{"path":"/reference/Paquid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Paquid sample — Paquid","text":"data frame 2561 observations following 4 variables. time time--event (years). status type event 0 = censored, 1 = dementia onset 2 = death without dementia. DSST score Digit Symbol Substitution Score Test. test explores attention psychomotor speed. MMSE score Mini Mental State Examination. test often used index global cognitive performance.","code":""},{"path":"/reference/Paquid.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Paquid sample — Paquid","text":"data first made publicly available via package timeROC.","code":""},{"path":"/reference/Paquid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Paquid sample — Paquid","text":"Dartigues, J., Gagnon, M., Barberger-Gateau, P., Letenneur, L., Commenges, D., Sauvel, C., Michel, P., Salamon, R. (1992). paquid epidemiological program brain ageing. Neuroepidemiology, 11(1):14--18. Blanche, P., Dartigues, J. F., & Jacqmin-Gadda, H. (2013). Estimating comparing time-dependent areas receiver operating characteristic curves censored event times competing risks. Statistics Medicine, 32(30), 5381-5397.","code":""},{"path":"/reference/Paquid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Paquid sample — Paquid","text":"","code":"data(Paquid)"},{"path":"/reference/Score.html","id":null,"dir":"Reference","previous_headings":"","what":"Score risk predictions — Score","title":"Score risk predictions — Score","text":"Methods score predictive performance risk markers risk prediction models","code":""},{"path":"/reference/Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score risk predictions — Score","text":"","code":"# S3 method for list Score(   object,   formula,   data,   metrics = c(\"auc\", \"brier\"),   summary = NULL,   plots = NULL,   cause,   times,   landmarks,   use.event.times = FALSE,   null.model = TRUE,   se.fit = TRUE,   conservative = FALSE,   multi.split.test = FALSE,   conf.int = 0.95,   contrasts = TRUE,   probs = c(0, 0.25, 0.5, 0.75, 1),   cens.method = \"ipcw\",   cens.model = \"cox\",   split.method,   B,   M,   seed,   trainseeds,   parallel = c(\"no\", \"multicore\", \"snow\", \"as.registered\"),   ncpus = 1,   cl = NULL,   progress.bar = 3,   errorhandling = \"pass\",   keep,   predictRisk.args,   debug = 0L,   useEventTimes,   nullModel,   censMethod,   censModel,   splitMethod,   ... )"},{"path":"/reference/Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score risk predictions — Score","text":"object List risk predictions (see details examples). formula formula identifies outcome (left hand     side). E.g., Y ~ 1 binary Hist(time,status) ~ 1 time--event outcome. right censored data, right hand side     formula used estimate inverse probability censoring weights (IPCW) model. data data.frame data.table formula can interpreted. metrics Character vector specifying metrics apply. Case matter. Choices \"AUC\" \"Brier\". summary Character vector specifying summary statistics apply predicted risks. Choices \"risks\", \"IPA\", \"riskQuantile\" \"ibs\". Can c(\"risks\",\"IPA\",\"riskQuantile\",\"ibs\") subset thereof. \"risks\" adds predicted risks output. \"ipa\" computes index prediction accuracy (AKA R-squared) based Brier scores model vs null model \"riskQuantile\" calculates time-point specific boxplots predicted risks (biomarker values) conditional outcome time-point. \"ibs\" calculates integrated Brier scores across time points Brier score computed. works time--event outcome results depend argument times. Set NULL avoid estimation summary statistics. plots Character vector specifying plots put data result. Currently implemented \"ROC\", \"Calibration\" \"boxplot\". addition, one can plot AUC Brier score function time soon times least two different values. cause Event interest. Used binary outcome Y specify risks risks event Y=event competing risks outcome specify cause interest. times survival competing risks outcome: list prediction horizons. times greater maximal observed time data set automatically removed. Note object returned function may become huge prediction performance estimated many prediction horizons. landmarks yet implemented. use.event.times TRUE merge unique event times vector given argument times. null.model TRUE fit risk prediction model ignores     covariates predicts value subjects. model fitted using data left hand side formula. binary outcome just empirical prevalence. (right censored) time event outcome, null models equal Kaplan-Meier estimator (competing risks) Aalen-Johansen estimator (competing risks). se.fit Logical 0 1. FALSE 0 calculate standard errors. conservative Logical, relevant right censored data. TRUE ignore variability estimate inverse probability censoring weights calculating standard errors prediction performance parameters. can potentially reduce computation time memory usage usually small expense slightly higher standard error. multi.split.test Logical 0 1. FALSE 0 calculate multi-split tests. argument ignored split.method \"none\". conf.int Either logical numeric value 0 1. right censored data, confidence intervals based Blanche et al (see references). Setting FALSE prevents computation confidence intervals. TRUE means compute 95 percent confidence intervals corresponding p-values AUC Brier score. set 0.87, level significance 13 percent. , set 0.87. contrasts Either logical list contrasts. list contrasts defines risk prediction models (markers)  contrasted respect prediction performance. TRUE possible comparisons.   example, object list two risk prediction models   null.model=TRUE setting TRUE equivalent   list(c(0,1,2),c(1,2)) c(0,1,2) codes   two comparisons: 1 vs 0 2 vs 0 (positive integers refer   elements object, 0 refers benchmark null   model ignores covariates).  equivalent   explicitly setting list(c(0,1),c(0,2),c(1,2)).   complex example: Suppose object 7 elements   want following 3 comparisons: 6 vs 3, 2 vs 5 2   vs 3, set contrasts=c(6,3),c(2,5,3). probs Quantiles retrospective summary statistics predicted risks. affects result function boxplot.Score. cens.method Method dealing right censored data. Either \"ipcw\" \"pseudo\". IPCW refers inverse probability censoring weights pseudo jackknife pseudo values. Right now pseudo values  used calibration curves. cens.model Model estimating inverse probability     censored weights. Implemented Kaplan-Meier method (\"km\") Cox regression (\"cox\") applied censored times. right hand side formula specify covariates, Kaplan-Meier method used even argument set \"cox\". split.method Method cross-validation. Right now choice bootcv case bootstrap learning sets drawn without replacement (argument M) data. data included current bootstrap learning set used validation set compute prediction performance. B Number bootstrap sets cross-validation. M Size subsamples bootstrap cross-validation. specified integer smaller size data. seed Super seed setting training data seeds randomly splitting (bootstrapping) data cross-validation. trainseeds Seeds training models cross-validation. parallel type parallel operation used (). missing, default \"\". ncpus integer: number processes used parallel operation. cl optional parallel snow cluster use parallel = \"snow\". supplied, cluster local machine created duration Score call. progress.bar Style txtProgressBar. Can 1,2,3 see help(txtProgressBar) NULL avoid progress bar. errorhandling . flexible approach write new predictRisk S3-method. See Details. keep list characters (case sensitive) determines additional output. \"residuals\" provides Brier score residuals \"splitindex\" provides sampling index used split data training validation sets. \"vcov\" provides variance-covariance matrix estimated parameters. predictRisk.args list argument-lists control risks predicted. names lists S3-classes object. argument-lists passed S3-class specific predictRisk method. example, object contains one several random forest model fitted function randomForestSRC::rfsrc can specify additional arguments function riskRegression::predictRisk.rfsrc pass function randomForestSRC::predict.rfsrc. specific example case list(rfsrc=list(na.action=\"na.impute\")). debug Logical. TRUE indicate landmark progress program. useEventTimes obsolete. nullModel obsolete. censMethod obsolete. censModel obsolete. splitMethod obsolete. ... Named list containging additional arguments passed predictRisk methods corresponding object. See examples.","code":""},{"path":"/reference/Score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Score risk predictions — Score","text":"List scores assessments contrasts, .e.,     tests confidence limits performance difference performance (AUC Brier),     summaries plots. elements indata.table format.","code":""},{"path":"/reference/Score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Score risk predictions — Score","text":"function implements toolbox risk prediction modeller: tools work three outcomes: (1) binary (uncensored), (2) right censored time event without competing risks, (3) right censored time event competing risks Computed (time-dependent) Brier score (time-dependent) area ROC curve list risk prediction models either external validation data learning data using bootstrap cross-validation. function optionally provides results plotting (time-point specific) ROC curves, (time-point specific) calibration curves (time-point specific) retrospective boxplots. uncensored binary outcome Delong-Delong test used contrast AUC rival models. right censored survival data (without competing risks) p-values correspond Wald tests based standard errors obtained estimate influence function described detail appendix Blanche et al. (2015). function works one multiple models predict risk event R(t|X) subject characterized predictors X time t. binary endpoints (outcome 0/1 without time component) risk simply R(X). case survival object without competing risks function still works predicted event probabilities, .e., R(t|X)=1-S(t|X) S(t|X) predicted survival chance subject X time t. already existing predictRisk methods (see methods(predictRisk)) may cover models methods predicting risks. users can quickly extend package explained detail Mogensen et al. (2012) predecessors pec::predictSurvProb pec::predictEventProb unified riskRegression::predictRisk. Bootstrap Crossvalidation (see also Gerds & Schumacher 2007 Mogensen et al. 2012) B=10, M (specified M=NROW(data)) Training models 10 bootstrap data sets (learning data sets). Learning data sets obtained sampling NROW(data) subjects data set replacement. roughly .632*NROW(data) subjects learning data (inbag) .368*NROW(data) subjects validation data sets (--bag). used estimate scores: AUC, Brier, etc. Reported averages across 10 splits. ## Bootstrap replacement  set.seed(13) N=17 data = data.frame(id=1:N, y=rbinom(N,1,.3),x=rnorm(N)) boot.index = sample(1:N,size=N,replace=TRUE) boot.index inbag = 1:N  outofbag = !inbag learn.data = data[inbag] val.data = data[outofbag] riskRegression:::getSplitMethod(\"bootcv\",B=10,N=17)$index  NOTE: number .632 expected probability draw one subject (example subject 1) replacement data, depend sample size: B=10000 N=137 mean(sapply(1:B, function(b){match(1,sample(1:N,size=N,replace=TRUE),nomatch=0)})) N=30 mean(sapply(1:B, function(b){match(1,sample(1:N,size=N,replace=TRUE),nomatch=0)})) N=300 mean(sapply(1:B, function(b){match(1,sample(1:N,size=N,replace=TRUE),nomatch=0)})) ## Bootstrap without replacement (training size set 70 percent data) B=10, M=.7 Training models 10 bootstrap data sets (learning data sets). Learning data sets obtained sampling round(.8*NROW(data)) subjects data set without replacement. NROW(data)-round(.8*NROW(data)) subjects learning data sets. used estimate scores: AUC, Brier, etc. Reported averages across 10 splits.  set.seed(13) N=17 data = data.frame(id=1:N, y=rbinom(N,1,.3),x=rnorm(N)) boot.index = sample(1:N,size=M,replace=FALSE) boot.index inbag = 1:N  outofbag = !inbag learn.data = data[inbag] val.data = data[outofbag] riskRegression:::getSplitMethod(\"bootcv\",B=10,N=17,M=.7)$index","code":""},{"path":"/reference/Score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Score risk predictions — Score","text":"Ulla B. Mogensen, Hemant Ishwaran, Thomas . Gerds (2012). Evaluating Random Forests Survival Analysis Using Prediction Error Curves. Journal Statistical Software, 50(11), 1-23. URL http://www.jstatsoft.org/v50/i11/. Paul Blanche, Cecile Proust-Lima, Lucie Loubere, Claudine Berr, Jean- Francois Dartigues, Helene Jacqmin-Gadda. Quantifying comparing dynamic predictive accuracy joint models longitudinal marker time--event presence censoring competing risks. Biometrics, 71 (1):102--113, 2015. P. Blanche, J-F Dartigues, H. Jacqmin-Gadda. Estimating comparing time-dependent areas receiver operating characteristic curves censored event times competing risks. Statistics Medicine, 32(30):5381--5397, 2013. E. Graf et al.  (1999), Assessment comparison prognostic classification schemes survival data. Statistics Medicine, vol 18, pp= 2529--2545. Efron, Tibshirani (1997) Journal American Statistical Association 92, 548--560 Improvement Cross-Validation: .632+ Bootstrap Method. Gerds, Schumacher (2006), Consistent estimation expected Brier score general survival models right-censored event times. Biometrical Journal, vol 48, 1029--1040. Thomas . Gerds, Martin Schumacher (2007) Efron-Type Measures Prediction Error Survival Analysis Biometrics, 63(4), 1283--1287 doi:10.1111/j.1541-0420.2007.00832.x Martin Schumacher, Harald Binder, Thomas Gerds. Assessment survival prediction models based microarray data. Bioinformatics, 23(14):1768-74, 2007. Mark . van de Wiel, Johannes Berkhof, Wessel N. van Wieringen Testing prediction error difference 2 predictors Biostatistics (2009) 10(3): 550-560 doi:10.1093/biostatistics/kxp011 Michael W Kattan Thomas Gerds. index prediction accuracy: intuitive measure useful evaluating risk prediction models. Diagnostic Prognostic Research, 2(1):7, 2018.","code":""},{"path":"/reference/Score.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Score risk predictions — Score","text":"Thomas Gerds tag@biostat.ku.dk Paul Blanche paul.blanche@univ-ubs.fr","code":""},{"path":"/reference/Score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Score risk predictions — Score","text":"","code":"# binary outcome library(lava) set.seed(18) learndat <- sampleData(48,outcome=\"binary\") testdat <- sampleData(40,outcome=\"binary\")  ## score logistic regression models lr1 = glm(Y~X1+X2+X7+X9,data=learndat,family=binomial) lr2 = glm(Y~X3+X5,data=learndat,family=binomial) Score(list(\"LR(X1+X2+X7+X9)\"=lr1,\"LR(X3+X5)\"=lr2),formula=Y~1,data=testdat) #>  #> Metric AUC: #>  #> Results by model: #>  #>              model  AUC lower upper #> 1: LR(X1+X2+X7+X9) 60.7  42.3  79.1 #> 2:       LR(X3+X5) 44.2  26.9  61.6 #>  #> Results of model comparisons: #>  #>        model       reference delta.AUC lower upper   p #> 1: LR(X3+X5) LR(X1+X2+X7+X9)     -16.4 -38.2   5.3 0.1 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher AUC the better. #>  #> Metric Brier: #>  #> Results by model: #>  #>              model Brier lower upper #> 1:      Null model  24.9  24.2  25.7 #> 2: LR(X1+X2+X7+X9)  27.9  19.0  36.8 #> 3:       LR(X3+X5)  25.4  24.0  26.9 #>  #> Results of model comparisons: #>  #>              model       reference delta.Brier lower upper         p #> 1: LR(X1+X2+X7+X9)      Null model         3.0  -5.9  11.8 0.5124805 #> 2:       LR(X3+X5)      Null model         0.5  -0.4   1.4 0.2747143 #> 3:       LR(X3+X5) LR(X1+X2+X7+X9)        -2.5 -11.1   6.2 0.5778617 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The lower Brier the better.  ## ROC curve and calibration plot xb=Score(list(\"LR(X1+X2+X7+X9)\"=lr1,\"LR(X3+X5+X6)\"=lr2),formula=Y~1,          data=testdat,plots=c(\"calibration\",\"ROC\")) if (FALSE) plotROC(xb) plotCalibration(xb)    ## compute AUC for a list of continuous markers markers = as.list(testdat[,.(X6,X7,X8,X9,X10)]) Score(markers,formula=Y~1,data=testdat,metrics=c(\"auc\")) #>  #> Metric AUC: #>  #> Results by model: #>  #>    model  AUC lower upper #> 1:    X6 86.7  75.3  98.2 #> 2:    X7 38.6  20.7  56.5 #> 3:    X8 46.4  27.7  65.0 #> 4:    X9 35.3  17.9  52.8 #> 5:   X10 46.4  27.8  65.0 #>  #> Results of model comparisons: #>  #>     model reference delta.AUC lower upper     p #>  1:    X7        X6     -48.1 -69.7 -26.6 1e-05 #>  2:    X8        X6     -40.4 -63.6 -17.1 7e-04 #>  3:    X9        X6     -51.4 -73.3 -29.4 4e-06 #>  4:   X10        X6     -40.4 -61.8 -18.9 2e-04 #>  5:    X8        X7       7.8 -17.0  32.6 5e-01 #>  6:    X9        X7      -3.3 -26.6  20.1 8e-01 #>  7:   X10        X7       7.8 -17.4  32.9 5e-01 #>  8:    X9        X8     -11.0 -34.8  12.7 4e-01 #>  9:   X10        X8       0.0 -27.4  27.4 1e+00 #> 10:   X10        X9      11.0 -12.1  34.2 4e-01 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher AUC the better.  # cross-validation if (FALSE) {     learndat=sampleData(400,outcome=\"binary\")     lr1a = glm(Y~X6,data=learndat,family=binomial)     lr2a = glm(Y~X7+X8+X9,data=learndat,family=binomial)     ## bootstrap cross-validation     x1=Score(list(\"LR1\"=lr1a,\"LR2\"=lr2a),formula=Y~1,data=learndat,split.method=\"bootcv\",B=100)     x1     ## leave-one-out and leave-pair-out bootstrap     x2=Score(list(\"LR1\"=lr1a,\"LR2\"=lr2a),formula=Y~1,data=learndat,              split.method=\"loob\",              B=100,plots=\"calibration\")     x2 } # survival outcome  # Score Cox regression models if (FALSE) library(survival) library(rms) #> Loading required package: Hmisc #> Loading required package: lattice #> Loading required package: Formula #> Loading required package: ggplot2 #>  #> Attaching package: ‘ggplot2’ #> The following object is masked from ‘package:lava’: #>  #>     vars #>  #> Attaching package: ‘Hmisc’ #> The following objects are masked from ‘package:base’: #>  #>     format.pval, units #> Loading required package: SparseM #>  #> Attaching package: ‘SparseM’ #> The following object is masked from ‘package:base’: #>  #>     backsolve #>  #> Attaching package: ‘rms’ #> The following object is masked from ‘package:modeltools’: #>  #>     Predict library(prodlim) set.seed(18) trainSurv <- sampleData(100,outcome=\"survival\") testSurv <- sampleData(40,outcome=\"survival\") cox1 = coxph(Surv(time,event)~X1+X2+X7+X9,data=trainSurv, y=TRUE, x = TRUE) cox2 = coxph(Surv(time,event)~X3+X5+X6,data=trainSurv, y=TRUE, x = TRUE) xs=Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),          formula=Surv(time,event)~1,data=testSurv,conf.int=FALSE,times=c(5,8)) xs #>  #> Metric AUC: #>  #> Results by model: #>  #>               model times  AUC #> 1: Cox(X1+X2+X7+X9)     5 65.9 #> 2: Cox(X1+X2+X7+X9)     8 69.3 #> 3:    Cox(X3+X5+X6)     5 74.3 #> 4:    Cox(X3+X5+X6)     8 77.5 #>  #> Results of model comparisons: #>  #>    times         model        reference delta.AUC #> 1:     5 Cox(X3+X5+X6) Cox(X1+X2+X7+X9)       8.4 #> 2:     8 Cox(X3+X5+X6) Cox(X1+X2+X7+X9)       8.2 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher AUC the better. #>  #> Metric Brier: #>  #> Results by model: #>  #>               model times Brier #> 1:       Null model     5  23.2 #> 2:       Null model     8  24.4 #> 3: Cox(X1+X2+X7+X9)     5  22.6 #> 4: Cox(X1+X2+X7+X9)     8  22.7 #> 5:    Cox(X3+X5+X6)     5  22.0 #> 6:    Cox(X3+X5+X6)     8  20.0 #>  #> Results of model comparisons: #>  #>    times            model        reference delta.Brier #> 1:     5 Cox(X1+X2+X7+X9)       Null model        -0.6 #> 2:     5    Cox(X3+X5+X6)       Null model        -1.2 #> 3:     5    Cox(X3+X5+X6) Cox(X1+X2+X7+X9)        -0.6 #> 4:     8 Cox(X1+X2+X7+X9)       Null model        -1.6 #> 5:     8    Cox(X3+X5+X6)       Null model        -4.4 #> 6:     8    Cox(X3+X5+X6) Cox(X1+X2+X7+X9)        -2.8 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The lower Brier the better.   # Integrated Brier score if (FALSE) { xs=Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),          formula=Surv(time,event)~1,data=testSurv,conf.int=FALSE,          summary=\"ibs\",          times=sort(unique(testSurv$time))) }  # time-dependent AUC for list of markers if (FALSE) survmarkers = as.list(testSurv[,.(X6,X7,X8,X9,X10)]) Score(survmarkers,       formula=Surv(time,event)~1,metrics=\"auc\",data=testSurv,       conf.int=TRUE,times=c(5,8)) #> Error in Score(survmarkers, formula = Surv(time, event) ~ 1, metrics = \"auc\",     data = testSurv, conf.int = TRUE, times = c(5, 8)): object 'survmarkers' not found  # compare models on test data Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),       formula=Surv(time,event)~1,data=testSurv,conf.int=TRUE,times=c(5,8)) #>  #> Metric AUC: #>  #> Results by model: #>  #>               model times  AUC lower upper #> 1: Cox(X1+X2+X7+X9)     5 65.9  46.6  85.2 #> 2: Cox(X1+X2+X7+X9)     8 69.3  49.2  89.4 #> 3:    Cox(X3+X5+X6)     5 74.3  57.9  90.7 #> 4:    Cox(X3+X5+X6)     8 77.5  57.9  97.1 #>  #> Results of model comparisons: #>  #>    times         model        reference delta.AUC lower upper   p #> 1:     5 Cox(X3+X5+X6) Cox(X1+X2+X7+X9)       8.4 -20.1  36.9 0.6 #> 2:     8 Cox(X3+X5+X6) Cox(X1+X2+X7+X9)       8.2 -25.9  42.4 0.6 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher AUC the better. #>  #> Metric Brier: #>  #> Results by model: #>  #>               model times Brier lower upper #> 1:       Null model     5  23.2  19.0  27.4 #> 2:       Null model     8  24.4  21.5  27.2 #> 3: Cox(X1+X2+X7+X9)     5  22.6  15.8  29.4 #> 4: Cox(X1+X2+X7+X9)     8  22.7  14.5  31.0 #> 5:    Cox(X3+X5+X6)     5  22.0  13.9  30.1 #> 6:    Cox(X3+X5+X6)     8  20.0   9.8  30.1 #>  #> Results of model comparisons: #>  #>    times            model        reference delta.Brier lower upper         p #> 1:     5 Cox(X1+X2+X7+X9)       Null model        -0.6  -8.3   7.1 0.8822806 #> 2:     5    Cox(X3+X5+X6)       Null model        -1.2 -10.6   8.2 0.8002223 #> 3:     5    Cox(X3+X5+X6) Cox(X1+X2+X7+X9)        -0.6 -12.6  11.4 0.9177163 #> 4:     8 Cox(X1+X2+X7+X9)       Null model        -1.6  -9.4   6.1 0.6798489 #> 5:     8    Cox(X3+X5+X6)       Null model        -4.4 -14.7   5.8 0.3990817 #> 6:     8    Cox(X3+X5+X6) Cox(X1+X2+X7+X9)        -2.8 -18.3  12.7 0.7259326 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The lower Brier the better.  # crossvalidation models in traindata if (FALSE) {     library(survival)     set.seed(18)     trainSurv <- sampleData(400,outcome=\"survival\")     cox1 = coxph(Surv(time,event)~X1+X2+X7+X9,data=trainSurv, y=TRUE, x = TRUE)     cox2 = coxph(Surv(time,event)~X3+X5+X6,data=trainSurv, y=TRUE, x = TRUE)     x1 = Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),                formula=Surv(time,event)~1,data=trainSurv,conf.int=TRUE,times=c(5,8),                split.method=\"loob\",B=100,plots=\"calibration\")      x2= Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),               formula=Surv(time,event)~1,data=trainSurv,conf.int=TRUE,times=c(5,8),               split.method=\"bootcv\",B=100) }  # restrict number of comparisons if (FALSE) {     Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),           formula=Surv(time,event)~1,data=trainSurv,contrasts=TRUE,           null.model=FALSE,conf.int=TRUE,times=c(5,8),split.method=\"bootcv\",B=3)      # competing risks outcome     set.seed(18)     trainCR <- sampleData(40,outcome=\"competing.risks\")     testCR <- sampleData(40,outcome=\"competing.risks\")     library(riskRegression)     library(cmprsk)     # Cause-specific Cox regression     csc1 = CSC(Hist(time,event)~X1+X2+X7+X9,data=trainCR)     csc2 = CSC(Hist(time,event)~X3+X5+X6,data=trainCR)     # Fine-Gray regression     fgr1 = FGR(Hist(time,event)~X1+X2+X7+X9,data=trainCR,cause=1)     fgr2 = FGR(Hist(time,event)~X3+X5+X6,data=trainCR,cause=1)     Score(list(\"CSC(X1+X2+X7+X9)\"=csc1,\"CSC(X3+X5+X6)\"=csc2,                \"FGR(X1+X2+X7+X9)\"=fgr1,\"FGR(X3+X5+X6)\"=fgr2),           formula=Hist(time,event)~1,data=testCR,se.fit=1L,times=c(5,8)) }    if (FALSE) {     # reproduce some results of Table IV of Blanche et al. Stat Med 2013     data(Paquid)     ResPaquid <- Score(list(\"DSST\"=-Paquid$DSST,\"MMSE\"=-Paquid$MMSE),                        formula=Hist(time,status)~1,                        data=Paquid,                        null.model = FALSE,                        conf.int=TRUE,                        metrics=c(\"auc\"),                        times=c(3,5,10),                        plots=\"ROC\")     ResPaquid     plotROC(ResPaquid,time=5) } if (FALSE) { # parallel options # by erikvona: Here is a generic example of using future # and doFuture, works great with the current version: library(riskRegression) library(future) library(foreach) library(doFuture) library(survival) # Register all available cores for parallel operation plan(multiprocess, workers = availableCores()) registerDoFuture() trainSurv <- sampleData(400,outcome=\"survival\") cox1 = coxph(Surv(time,event)~X1+X2+X7+X9,data=trainSurv,              y=TRUE, x = TRUE) # Bootstrapping on multiple cores x1 = Score(list(\"Cox(X1+X2+X7+X9)\"=cox1),      formula=Surv(time,event)~1,data=trainSurv, times=c(5,8),      parallel = \"as.registered\", split.method=\"bootcv\",B=100) }"},{"path":"/reference/SmcFcs.html","id":null,"dir":"Reference","previous_headings":"","what":"SmcFcs — SmcFcs","title":"SmcFcs — SmcFcs","text":"TODO","code":""},{"path":"/reference/SmcFcs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SmcFcs — SmcFcs","text":"","code":"SmcFcs(formula, data, m = 5, method, fitter = \"glm\", fit.formula, ...)"},{"path":"/reference/SmcFcs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SmcFcs — SmcFcs","text":"formula TODO data TODO m TODO method TODO fitter TODO fit.formula TODO ... TODO # @export","code":""},{"path":"/reference/SuperPredictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","title":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","text":"Formula interface SuperLearner::SuperLearner","code":""},{"path":"/reference/SuperPredictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","text":"","code":"SuperPredictor(   formula,   data,   family = \"binomial\",   SL.library = c(\"SL.glm\", \"SL.glm.interaction\", \"SL.ranger\"),   ... )"},{"path":"/reference/SuperPredictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","text":"formula left hand side specifies outcome right hand side predictors data data set formula can evaluated family outcome family. default binomial SL.library SuperLearner libraries ... passed SuperLearner::SuperLearner","code":""},{"path":"/reference/SuperPredictor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","text":"Formula interface SuperLearner::SuperLearner ##' @param formula","code":""},{"path":"/reference/SuperPredictor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Formula interface for SuperLearner::SuperLearner — SuperPredictor","text":"","code":"if (FALSE) { if(requireNamespace(\"SuperLearner\",quietly=TRUE)){ library(SuperLearner) library(data.table) d = sampleData(338, outcome=\"binary\") spfit = SuperPredictor(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,data=d) predictRisk(spfit) x <- Score(list(spfit),data=d,formula=Y~1) } }"},{"path":"/reference/SurvResponseVar.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the time and event variable from a Cox model — SurvResponseVar","title":"Extract the time and event variable from a Cox model — SurvResponseVar","text":"Extract time event variable Cox model","code":""},{"path":"/reference/SurvResponseVar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the time and event variable from a Cox model — SurvResponseVar","text":"","code":"SurvResponseVar(formula)"},{"path":"/reference/SurvResponseVar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the time and event variable from a Cox model — SurvResponseVar","text":"formula formula","code":""},{"path":"/reference/SurvResponseVar.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the time and event variable from a Cox model — SurvResponseVar","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/SurvResponseVar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the time and event variable from a Cox model — SurvResponseVar","text":"","code":"if (FALSE) { SurvResponseVar(Surv(time,event)~X1+X2) SurvResponseVar(Hist(time,event==0)~X1+X2) SurvResponseVar(Surv(start,time, status,type=\"counting\") ~ X3+X5) SurvResponseVar(Surv(start,event=status, time2=time,type=\"counting\") ~ X3+X5)  SurvResponseVar(survival::Surv(start,event=status, time2=time,type=\"counting\") ~ X3+X5) SurvResponseVar(status ~ X3+X5) SurvResponseVar(I(status == 1) ~ X3+X5) SurvResponseVar(list(Hist(time, event) ~ X1+X6,Hist(time, event) ~ X6)) }"},{"path":"/reference/anova.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Risk Comparison Over Time — anova.ate","title":"Risk Comparison Over Time — anova.ate","text":"Comparison risk differences risk ratios timepoints.","code":""},{"path":"/reference/anova.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Risk Comparison Over Time — anova.ate","text":"","code":"# S3 method for ate anova(   object,   allContrast = NULL,   type = \"diff\",   estimator = object$estimator[1],   test = \"CvM\",   transform = NULL,   alternative = \"two.sided\",   n.sim = 10000,   print = TRUE,   ... )"},{"path":"/reference/anova.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Risk Comparison Over Time — anova.ate","text":"object ate object, .e. output ate function. allContrast [matrix] contrast risks compared. Matrix two rows, first sequence reference treatments second sequence alternative treatments. type [character vector] functionnal used compare risks: \"diffRisk\" \"ratioRisk\". estimator [character] type estimator relative comparison performed. test [character] type statistic used compare risks times: \"KM\" (extremum risk), \"CvM\" (sum squares risk), \"sum\" (sum risks). transform [character] transformation used, e.g. test performed log-transformation estimate, standard error, influence function. alternative [character] character string specifying alternative hypothesis, must one \"two.sided\", \"greater\" \"less\". n.sim [integer, >0] number simulations used compute p-values. print [logical] results displayed? ... used.","code":""},{"path":"/reference/anova.ate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Risk Comparison Over Time — anova.ate","text":"Experimental!!!","code":""},{"path":"/reference/anova.ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Risk Comparison Over Time — anova.ate","text":"","code":"library(survival) library(data.table)  if (FALSE) { ## simulate data set.seed(12) n <- 200 dtS <- sampleData(n,outcome=\"survival\") dtS$X12 <- LETTERS[as.numeric(as.factor(paste0(dtS$X1,dtS$X2)))] dtS <- dtS[dtS$X12!=\"D\"]  ## model fit fit <- cph(formula = Surv(time,event)~ X1+X6,data=dtS,y=TRUE,x=TRUE) seqTime <- 1:10 ateFit <- ate(fit, data = dtS, treatment = \"X1\", contrasts = NULL,               times = seqTime, B = 0, iid = TRUE, se = TRUE, verbose = TRUE, band = TRUE)  ## display autoplot(ateFit)  ## inference (two sided) statistic <- ateFit$diffRisk$estimate/ateFit$diffRisk$se confint(ateFit, p.value = TRUE, method.band = \"bonferroni\")$diffRisk confint(ateFit, p.value = TRUE, method.band = \"maxT-simulation\")$diffRisk  anova(ateFit, test = \"KS\") anova(ateFit, test = \"CvM\") anova(ateFit, test = \"sum\")  ## manual calculation (one sided) n.sim <- 1e4 statistic <- ateFit$diffRisk[, estimate/se] iid.norm <- scale(ateFit$iid$GFORMULA[[\"1\"]]-ateFit$iid$GFORMULA[[\"0\"]],                   scale = ateFit$diffRisk$se)  ls.out <- lapply(1:n.sim, function(iSim){ iG <- rnorm(NROW(iid.norm)) iCurve <- t(iid.norm) %*% iG data.table(max = max(iCurve), L2 = sum(iCurve^2), sum = sum(iCurve), maxC = max(iCurve) - max(statistic), L2C = sum(iCurve^2) - sum(statistic^2), sumC = sum(iCurve) - sum(statistic), sim = iSim) })  dt.out <- do.call(rbind,ls.out) dt.out[,.(max = mean(.SD$maxC>=0),           L2 = mean(.SD$L2C>=0),           sum = mean(.SD$sumC>=0))]  ## permutation n.sim <- 250 stats.perm <- vector(mode = \"list\", length = n.sim) pb <- txtProgressBar(max = n.sim, style=3) treatVar <- ateFit$variables[\"treatment\"]  for(iSim in 1:n.sim){ ## iSim <- 1 iData <- copy(dtS) iIndex <- sample.int(NROW(iData), replace = FALSE) iData[, c(treatVar) := .SD[[treatVar]][iIndex]]  iFit <- update(fit, data = iData) iAteSim <- ate(iFit, data = iData, treatment = treatVar,                times = seqTime, verbose = FALSE) iStatistic <- iAteSim$diffRisk[,estimate/se] stats.perm[[iSim]] <- cbind(iAteSim$diffRisk[,.(max = max(iStatistic),                                                 L2 = sum(iStatistic^2),                                                 sum = sum(iStatistic))],                             sim = iSim) stats.perm[[iSim]]$maxC <- stats.perm[[iSim]]$max - max(statistic) stats.perm[[iSim]]$L2C <- stats.perm[[iSim]]$L2 - sum(statistic^2) stats.perm[[iSim]]$sumC <- stats.perm[[iSim]]$sum - sum(statistic) setTxtProgressBar(pb, iSim) }  dtstats.perm <- do.call(rbind,stats.perm) dtstats.perm[,.(max = mean(.SD$maxC>=0),                 L2 = mean(.SD$L2C>=0),                 sum = mean(.SD$sumC>=0))] }"},{"path":"/reference/as.data.table.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn ate Object Into a data.table — as.data.table.ate","title":"Turn ate Object Into a data.table — as.data.table.ate","text":"Turn ate object data.table.","code":""},{"path":"/reference/as.data.table.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn ate Object Into a data.table — as.data.table.ate","text":"","code":"# S3 method for ate as.data.table(   x,   estimator = x$estimator,   type = c(\"meanRisk\", \"diffRisk\", \"ratioRisk\"),   keep.rownames = FALSE,   ... )"},{"path":"/reference/as.data.table.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn ate Object Into a data.table — as.data.table.ate","text":"x object obtained function ate estimator [character] type estimator relative estimates output. type [character vector] type risk export. Can \"meanRisk\" export risks specific treatment group, \"diffRisk\" export difference risks treatment groups, \"ratioRisk\" export ratio risks treatment groups. keep.rownames used. ... used.","code":""},{"path":"/reference/as.data.table.influenceTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn influenceTest Object Into a data.table — as.data.table.influenceTest","title":"Turn influenceTest Object Into a data.table — as.data.table.influenceTest","text":"Turn influenceTest object data.table.","code":""},{"path":"/reference/as.data.table.influenceTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn influenceTest Object Into a data.table — as.data.table.influenceTest","text":"","code":"# S3 method for influenceTest as.data.table(x, keep.rownames = FALSE, se = TRUE, ...)"},{"path":"/reference/as.data.table.influenceTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn influenceTest Object Into a data.table — as.data.table.influenceTest","text":"x object obtained function influenceTest keep.rownames used. se [logical] standard errors/quantile confidence bands displayed? ... used.","code":""},{"path":"/reference/as.data.table.predictCSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn predictCSC Object Into a data.table — as.data.table.predictCSC","title":"Turn predictCSC Object Into a data.table — as.data.table.predictCSC","text":"Turn predictCSC object data.table.","code":""},{"path":"/reference/as.data.table.predictCSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn predictCSC Object Into a data.table — as.data.table.predictCSC","text":"","code":"# S3 method for predictCSC as.data.table(x, keep.rownames = FALSE, se = TRUE, ...)"},{"path":"/reference/as.data.table.predictCSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn predictCSC Object Into a data.table — as.data.table.predictCSC","text":"x object obtained function predictCSC keep.rownames used se standard errors/quantile confidence bands displayed? ... used","code":""},{"path":"/reference/as.data.table.predictCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn predictCox Object Into a data.table — as.data.table.predictCox","title":"Turn predictCox Object Into a data.table — as.data.table.predictCox","text":"Turn predictCox object data.table.","code":""},{"path":"/reference/as.data.table.predictCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn predictCox Object Into a data.table — as.data.table.predictCox","text":"","code":"# S3 method for predictCox as.data.table(x, keep.rownames = FALSE, se = TRUE, ...)"},{"path":"/reference/as.data.table.predictCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn predictCox Object Into a data.table — as.data.table.predictCox","text":"x object obtained function predictCox keep.rownames used. se [logical] standard errors/quantile confidence bands displayed? ... used.","code":""},{"path":"/reference/ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Average Treatment Effects Computation — ate","title":"Average Treatment Effects Computation — ate","text":"Use g-formula IPW double robust estimator estimate average treatment     effect (absolute risk difference ratio) based Cox regression without competing risks.","code":""},{"path":"/reference/ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average Treatment Effects Computation — ate","text":"","code":"ate(   event,   treatment,   censor = NULL,   data,   data.index = NULL,   formula,   estimator = NULL,   strata = NULL,   contrasts = NULL,   allContrasts = NULL,   times,   cause = NA,   landmark,   se = TRUE,   iid = (B == 0) && (se || band),   known.nuisance = FALSE,   band = FALSE,   B = 0,   seed,   handler = \"foreach\",   mc.cores = 1,   cl = NULL,   verbose = TRUE,   ... )"},{"path":"/reference/ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average Treatment Effects Computation — ate","text":"event Outcome model describes probability experiencing terminal event depends treatment covariates. object carry call predictRisk method. See examples. treatment Treatment model describes probability allocated treatment group depends covariates. object must glm object (logistic regression) name treatment variable. See examples. censor Censoring model describes probability censored depends treatment covariates. object must coxph cph object. See examples. data [data.frame data.table] Data set evaluate risk predictions based outcome model data.index [numeric vector] Position observation argument data relative dataset used obtain argument event, treatment, censor. necessary standard errors computing Average Treatment Effects subset data set. formula analyses time-dependent covariates, response formula. See examples. estimator [character] type estimator used compute average treatment effect.  Can \"G-formula\", \"IPTW\", \"AIPTW\". using estimator=\"G-formula\", model outcome provided (argument event). using estimator=\"IPTW\", model treatment provided (argument treatment), well censoring (, argument censor). using estimator=\"AIPTW\" (double robust estimator), model outcome treatment provided (argument event treatment), well censoring (, argument censor). strata [character] Strata variable compute average risk. Incompatible treatment. Experimental. contrasts [character vector] levels treatment variable risks assessed compared. Default consider levels. allContrasts [2-row character matrix] levels treatment variable compared. Default consider pairwise comparisons. times [numeric vector] Time points evaluate average treatment effects. cause [integer/character] cause interest. landmark models time-dependent covariates landmark time(s) evaluation. case, argument time may one value prediction risks assumed covariates change landmark landmark+time. se [logical] TRUE compute add standard errors output. iid [logical] TRUE compute add influence function output. known.nuisance [logical] FALSE uncertainty related estimation nuisance parameters ignored. greatly simplifies computations requires use double robust estimator. resulting standard error known consistent event, treatment, censoring models valid. band [logical] TRUE compute add quantiles confidence bands output. B [integer, >0] number bootstrap replications used compute confidence intervals. equals 0, influence function used compute Wald-type confidence intervals/bands. seed [integer, >0] sed number used generate seeds bootstrap achieve reproducible results. handler [character] Parallel handler bootstrap.  \"foreach\" default option Windows. uses parallel create cluster. operating systems can use \"mclapply\". argument ignored mc.cores=1 cl=NULL. mc.cores [integer, >0] number cores use, .e., upper limit number child processes run simultaneously. Passed parallel::mclapply parallel::makeCluster. option initialized environment variable mc_cores set. cl parallel socket cluster used perform cluster calculation parallel (output parallel::makeCluster). packages necessary run computations (e.g. riskRegression) must already loaded worker. used handler=\"foreach\". verbose [logical] TRUE inform estimated run time. ... passed predictRisk","code":""},{"path":[]},{"path":"/reference/ate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Average Treatment Effects Computation — ate","text":"Brice Ozenne broz@sund.ku.dk Thomas Alexander Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average Treatment Effects Computation — ate","text":"","code":"library(survival) library(rms) library(prodlim) library(data.table) set.seed(10)  #### Survival settings  #### #### ATE with Cox model ####  ## generate data n <- 100 dtS <- sampleData(n, outcome=\"survival\") dtS$time <- round(dtS$time,1) dtS$X1 <- factor(rbinom(n, prob = c(0.3,0.4) , size = 2), labels = paste0(\"T\",0:2))  ## estimate the Cox model fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)  ## compute the ATE at times 5, 6, 7, and 8 using X1 as the treatment variable ## standard error computed using the influence function ## confidence intervals / p-values based on asymptotic results ateFit1a <- ate(fit, data = dtS, treatment = \"X1\", times = 5:8) #>  Input variables  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, censoring: 0) #>  - Time  [min;max]      : time [0.6;15.7] #>  - Eval. time           :  5  6  7  8 #>       number at risk T0   16 13 10  7 #>       number at risk T1   26 21 18 11 #>       number at risk T2    7  3  3  1 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Processing #>  - Prepare influence function: outcome done  #>  - Point estimation: done  #>  - Decomposition iid: done #>  - Confidence intervals: done summary(ateFit1a) #>      Average treatment effect  #>  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, censoring: 0) #>  - Time  [min;max]      : time [0.6;15.7] #>  - Eval. time           :  5  6  7  8 #>       number at risk T0   16 13 10  7 #>       number at risk T1   26 21 18 11 #>       number at risk T2    7  3  3  1 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Testing procedure #>  - Null hypothesis     : given two treatments (A,B) and a specific timepoint, equal risks  #>  - Confidence level    : 0.95 #>  #>  Results:  #>  - Difference in standardized risk (B-A) between time zero and 'time'  #>                 reported on the scale [-1;1] (difference between two probabilities) #>  (difference in average risks when treating all subjects with the experimental treatment (B), #>                                 vs. treating all subjects with the reference treatment (A)) #>  #>  time X1=A risk(X1=A) X1=B risk(X1=B) difference           ci p.value #>     5   T0      0.472   T1      0.389    -0.0825 [-0.25;0.09]   0.341 #>     6   T0      0.550   T1      0.461    -0.0896 [-0.27;0.09]   0.341 #>     7   T0      0.609   T1      0.516    -0.0930 [-0.28;0.10]   0.339 #>     8   T0      0.641   T1      0.547    -0.0941 [-0.29;0.10]   0.338 #>     5   T0      0.472   T2      0.448    -0.0239 [-0.26;0.21]   0.841 #>     6   T0      0.550   T2      0.525    -0.0256 [-0.28;0.22]   0.841 #>     7   T0      0.609   T2      0.583    -0.0263 [-0.28;0.23]   0.841 #>     8   T0      0.641   T2      0.615    -0.0264 [-0.29;0.23]   0.841 #>     5   T1      0.389   T2      0.448     0.0586 [-0.17;0.29]   0.612 #>     6   T1      0.461   T2      0.525     0.0639 [-0.18;0.31]   0.611 #>     7   T1      0.516   T2      0.583     0.0667 [-0.19;0.32]   0.609 #>     8   T1      0.547   T2      0.615     0.0677 [-0.19;0.33]   0.608 #>  #>  difference      : estimated difference in standardized risks  #>  ci              : pointwise confidence intervals  #>  p.value         : (unadjusted) p-value  summary(ateFit1a, short = TRUE, type = \"meanRisk\") #>  - Standardized risk between time zero and 'time' #>  #>  time X1  risk          ci #>     5 T0 0.472 [0.33;0.62] #>     6 T0 0.550 [0.40;0.70] #>     7 T0 0.609 [0.46;0.76] #>     8 T0 0.641 [0.49;0.79] #>     5 T1 0.389 [0.26;0.52] #>     6 T1 0.461 [0.33;0.59] #>     7 T1 0.516 [0.38;0.66] #>     8 T1 0.547 [0.41;0.69] #>     5 T2 0.448 [0.25;0.65] #>     6 T2 0.525 [0.31;0.74] #>     7 T2 0.583 [0.36;0.80] #>     8 T2 0.615 [0.39;0.84] #>  summary(ateFit1a, short = TRUE, type = \"diffRisk\") #>  - Difference in standardized risk (B-A) between time zero and 'time'  #>  #>  time X1=A X1=B difference           ci p.value #>     5   T0   T1    -0.0825 [-0.25;0.09]   0.341 #>     6   T0   T1    -0.0896 [-0.27;0.09]   0.341 #>     7   T0   T1    -0.0930 [-0.28;0.10]   0.339 #>     8   T0   T1    -0.0941 [-0.29;0.10]   0.338 #>     5   T0   T2    -0.0239 [-0.26;0.21]   0.841 #>     6   T0   T2    -0.0256 [-0.28;0.22]   0.841 #>     7   T0   T2    -0.0263 [-0.28;0.23]   0.841 #>     8   T0   T2    -0.0264 [-0.29;0.23]   0.841 #>     5   T1   T2     0.0586 [-0.17;0.29]   0.612 #>     6   T1   T2     0.0639 [-0.18;0.31]   0.611 #>     7   T1   T2     0.0667 [-0.19;0.32]   0.609 #>     8   T1   T2     0.0677 [-0.19;0.33]   0.608 #>  summary(ateFit1a, short = TRUE, type = \"ratioRisk\") #>  - Ratio of standardized risks (B/A) between time zero and 'time'  #>  #>  time X1=A X1=B ratio          ci p.value #>     5   T0   T1 0.825 [0.50;1.15]   0.293 #>     6   T0   T1 0.837 [0.53;1.14]   0.295 #>     7   T0   T1 0.847 [0.56;1.14]   0.299 #>     8   T0   T1 0.853 [0.58;1.13]   0.301 #>     5   T0   T2 0.949 [0.46;1.43]   0.838 #>     6   T0   T2 0.953 [0.51;1.40]   0.839 #>     7   T0   T2 0.957 [0.54;1.37]   0.839 #>     8   T0   T2 0.959 [0.56;1.36]   0.839 #>     5   T1   T2 1.150 [0.54;1.76]   0.628 #>     6   T1   T2 1.139 [0.58;1.69]   0.624 #>     7   T1   T2 1.129 [0.62;1.64]   0.622 #>     8   T1   T2 1.124 [0.63;1.61]   0.620 #>   if (FALSE) { ## same as before with in addition the confidence bands / adjusted p-values ## (argument band = TRUE) ateFit1b <- ate(fit, data = dtS, treatment = \"X1\", times = 5:8,                 band = TRUE) summary(ateFit1b)  ## by default bands/adjuste p-values computed separately for each treatment modality summary(ateFit1b, band = 1,          se = FALSE, type = \"diffRisk\", short = TRUE, quantile = TRUE) ## adjustment over treatment and time using the band argument of confint summary(ateFit1b, band = 2,        se = FALSE, type = \"diffRisk\", short = TRUE, quantile = TRUE)  ## confidence intervals / p-values computed using 1000 boostrap samples ## (argument se = TRUE and B = 1000)  ateFit1c <- ate(fit, data = dtS, treatment = \"X1\",                 times = 5:8, se = TRUE, B = 50, handler = \"mclapply\") ## NOTE: for real applications 50 bootstrap samples is not enough   ## same but using 2 cpus for generating and analyzing the boostrap samples ## (parallel computation, argument mc.cores = 2)  ateFit1d <- ate(fit, data = dtS, treatment = \"X1\",                 times = 5:8, se = TRUE, B = 50, mc.cores = 2)  ## manually defining the cluster to be used ## useful when specific packages need to be loaded in each cluster fit <- cph(formula = Surv(time,event)~ X1+X2+rcs(X6),data=dtS,y=TRUE,x=TRUE)  cl <- parallel::makeCluster(2) parallel::clusterEvalQ(cl, library(rms))  ateFit1e <- ate(fit, data = dtS, treatment = \"X1\",                 times = 5:8, se = TRUE, B = 50,                 handler = \"foreach\", cl = cl) }  #### Survival settings without censoring #### #### ATE with glm                        ####  ## generate data n <- 100 dtB <- sampleData(n, outcome=\"binary\") dtB[, X2 := as.numeric(X2)] #>            X6       X7          X8           X9          X10 X1 X2 X3 X4 X5 Y #>   1: 78.01298 63.96298 -0.56839002 -0.210572124  0.502907735  0  2  1  1  1 1 #>   2: 55.52145 54.36513 -0.39144754  0.937064087 -1.374164637  1  1  0  1  1 1 #>   3: 43.13798 62.83007  0.64288621 -0.587024900  0.036800035  0  1  0  1  1 0 #>   4: 49.55549 58.65156  0.27620613  0.496585989  0.586200913  1  1  1  1  0 1 #>   5: 79.22190 60.16542 -0.25813305 -0.260201777  0.683943511  0  1  0  0  1 1 #>   6: 82.94772 62.76167  1.46582983  1.382226397 -0.568756129  0  1  0  0  1 1 #>   7: 38.24775 54.29504 -1.97327590  0.566921974  0.270355642  0  1  1  1  1 0 #>   8: 75.16737 65.93744  0.92010988  0.074845128 -0.541936997  0  1  0  1  1 0 #>   9: 45.05561 61.47713 -0.14907135 -0.910207520  0.402609684  1  1  0  1  1 1 #>  10: 42.73213 56.04234  1.23738748 -0.957253179 -0.186589923  0  1  0  1  1 1 #>  11: 77.12665 53.30601  0.52738054 -1.278404907  0.642750763  0  1  0  1  0 1 #>  12: 58.88072 69.29504  1.49049279  0.007014031  0.671474957  0  1  0  0  1 1 #>  13: 42.79600 66.46572 -0.39243138 -0.180816188 -0.401039690  1  1  0  0  0 1 #>  14: 76.82265 59.70732  0.18796458 -1.139473919  2.165025815  0  1  1  0  0 1 #>  15: 38.35310 65.01524 -0.01127341  0.743817244 -1.395293526  0  1  1  0  1 0 #>  16: 79.90491 66.60928 -1.24592590  0.624441674 -0.170700120  1  1  0  1  0 1 #>  17: 78.05356 68.87915  0.94396826 -1.418233056 -0.169434430  1  2  0  0  1 1 #>  18: 57.61872 64.74185  0.45941533  0.933141193 -0.032983385  0  2  1  0  0 0 #>  19: 66.98958 56.33181 -1.65322897  1.150647382  2.388519770  0  1  1  0  1 0 #>  20: 45.24455 60.60105 -0.77341027  0.470029213 -0.990011932  0  2  0  0  0 0 #>  21: 62.02366 59.91564 -0.68975150  0.879631239 -0.101054172  0  1  0  0  1 1 #>  22: 57.78682 67.08263  1.67183286 -0.923246979 -1.914149078  0  1  0  0  1 1 #>  23: 63.99209 57.24782 -0.09604987  0.251379345 -0.548874372  0  2  1  0  0 1 #>  24: 53.00781 49.67357 -0.79600441 -1.253740771  0.713894914  0  1  0  0  0 1 #>  25: 40.93517 48.01423 -0.22474377 -0.155392632  1.874488735  0  1  1  1  0 0 #>  26: 76.26733 55.95622 -1.26017269  0.517320940  0.794657504  0  1  0  1  1 0 #>  27: 85.67645 65.05618 -1.42640232  0.423064288 -0.094713679  0  1  0  0  1 0 #>  28: 76.45583 53.01383 -2.65363714  1.158858514 -1.347056080  0  2  1  0  0 1 #>  29: 41.69516 68.75821 -1.03865936  1.907944043  0.226424515  0  1  0  1  0 0 #>  30: 68.97958 60.85126  0.57982435  0.122316551  0.024109298  0  1  0  1  1 0 #>  31: 29.92992 56.16979  2.24926361  0.952111614 -1.804701217  0  1  0  0  1 0 #>  32: 55.66421 65.67026 -0.34730097  1.381241504  0.740596491  0  1  0  0  0 1 #>  33: 55.93535 62.49756  0.35892133 -0.688524922 -0.365777394  0  2  1  0  1 0 #>  34: 82.16710 58.59791 -0.56234113 -0.004725565  0.938043750  1  2  0  0  0 1 #>  35: 46.93589 60.39387 -0.96005031  0.706906654 -0.264641308  0  1  0  0  0 0 #>  36: 62.54992 69.20581  0.34253659  0.638144724 -0.166362498  0  1  0  0  1 0 #>  37: 74.74389 59.98933 -1.04648803 -1.787473323 -0.003882510  0  2  0  1  0 1 #>  38: 62.83938 64.19338  0.55333508 -0.205438562  0.435170090  0  1  0  0  1 1 #>  39: 83.37981 69.24409 -0.28051870  0.157280300 -0.620020411  0  1  0  1  0 1 #>  40: 63.87927 56.44113 -0.25400123  0.778093954 -0.245762459  0  2  1  0  0 0 #>  41: 82.95381 63.89724  0.99124934  0.445792808 -0.111607545  0  1  0  1  1 1 #>  42: 76.77325 55.69664 -0.66035357 -0.067550191  0.520877462  1  1  0  1  0 1 #>  43: 40.11926 49.80686  0.69329156 -1.480497207 -0.258175659  0  2  1  1  1 1 #>  44: 62.04355 51.48902  1.52728405 -0.207528914 -0.071121570  0  1  0  1  1 1 #>  45: 38.09094 67.44162  0.23695659 -0.319732621  1.149467397  1  1  1  0  1 1 #>  46: 54.80713 59.21902  1.17387684  1.289086796 -2.430072886  0  1  0  1  1 0 #>  47: 75.85677 61.97361 -2.48614865  0.072783058 -1.710448011  1  1  0  0  0 1 #>  48: 54.50966 70.09970  1.49742470 -0.005325330  0.258522399  0  1  1  1  0 0 #>  49: 74.42121 56.72927  0.97382087  0.818791435  0.498021292  0  1  0  0  1 1 #>  50: 46.25332 62.31992 -0.48411549  0.952465099 -0.049396092  1  1  0  1  0 0 #>  51: 84.39781 61.44562  0.27685067 -1.939096400  1.494676096  0  2  0  0  0 1 #>  52: 66.56635 60.23336 -0.21522285  0.878847068 -2.581771509  0  1  0  0  1 0 #>  53: 47.40846 58.47434  1.70827066 -0.402449468  0.061033497  0  1  0  0  1 1 #>  54: 72.80888 56.05802  1.53843123 -0.882386965  0.327749251  1  1  0  1  1 1 #>  55: 70.58864 60.25092 -0.23621370  0.612407673  0.128658740  0  2  1  0  1 0 #>  56: 66.74386 58.00998 -2.07643183  1.130871707 -0.496879832  0  1  1  0  0 0 #>  57: 68.62644 57.81581 -0.60569297 -1.636657486  0.432174401  0  1  0  0  1 1 #>  58: 87.17309 59.33232  0.95235963  1.083596256  1.412644391  0  1  0  0  0 1 #>  59: 64.16984 59.67586 -1.18769287 -0.085527482 -2.073420227  1  1  0  0  1 1 #>  60: 55.56214 62.99941  3.81258034  0.563125323  0.689403226  0  1  0  0  0 1 #>  61: 80.09402 56.00253  0.64648939  0.372485893  0.653175195  0  1  1  1  1 1 #>  62: 77.64821 51.11732  0.14886884  1.192991625  0.198049842  0  1  1  1  1 0 #>  63: 48.23083 52.25507 -1.07258069  0.734835251  1.399588371  0  1  1  0  1 1 #>  64: 47.79521 66.95377  0.17764396 -1.007523153  0.364184209  0  1  1  0  1 0 #>  65: 79.24335 65.84558 -0.28467953  0.887392638  1.640771446  0  2  1  1  1 1 #>  66: 71.57846 53.46988 -0.70952919  0.418746896  1.135271439  0  1  0  0  1 1 #>  67: 63.67749 67.78430 -0.72730972  0.298064973 -1.216440410  0  1  0  1  1 1 #>  68: 45.57033 64.87571  2.18399129  0.108168399  0.900987013  0  1  1  1  0 1 #>  69: 48.95988 54.12062 -0.42034232  0.040065443 -0.611960104  0  1  0  0  0 1 #>  70: 75.36952 59.78862 -0.13736276  1.471527338  1.131413771  0  2  0  0  1 1 #>  71: 68.28876 59.56319 -0.52263565 -1.755814448 -1.156178361  1  1  0  0  1 1 #>  72: 49.55450 72.63081  1.46846228 -0.092613881 -1.101728513  1  1  0  0  0 1 #>  73: 65.87922 58.28823  1.58985009  1.237809270  0.577847393  0  1  0  1  1 1 #>  74: 74.49191 55.46585 -2.05805583  0.420395072  0.180873659  1  1  0  0  1 1 #>  75: 75.77679 54.73128  1.01236094  0.165181742 -1.987922886  0  1  1  0  1 1 #>  76: 69.50403 51.95586 -1.34335639 -0.827838810  1.360595187  0  1  1  1  0 0 #>  77: 71.86100 61.13832 -1.76114717  0.205799319 -1.174200340  0  1  0  0  1 1 #>  78: 58.22115 57.86385  1.36326293 -0.998953867 -0.937909463  0  1  0  0  0 1 #>  79: 89.64008 61.67966 -0.16707925  0.028508302  1.268314046  0  1  1  1  0 1 #>  80: 57.88654 67.50344 -0.70818084  0.721889354  1.364005221  0  1  0  0  1 0 #>  81: 76.41378 57.91319  0.28394300  0.203508820 -1.842217474  0  1  1  1  0 1 #>  82: 45.59080 63.00873 -0.20854356 -0.249387100 -0.564817488  0  1  0  1  0 0 #>  83: 85.35118 57.55862  0.04651940  2.071403671 -1.659969104  0  1  1  1  1 1 #>  84: 47.72356 63.82289 -1.22547324 -0.982768991  1.252569834  0  2  0  1  0 0 #>  85: 57.45616 55.32343  0.49211534  0.242662434 -1.632399936  0  1  0  0  0 1 #>  86: 57.45603 62.65382  2.22979453  0.003371298  1.053663270  0  1  0  0  1 0 #>  87: 31.38942 60.23798  2.85804162 -1.551135977 -2.768705694  0  1  0  0  0 0 #>  88: 57.83100 60.00459  0.99843840  1.222690877 -1.781053425  0  1  1  1  0 0 #>  89: 65.89807 54.67264 -0.06623606 -0.374327714  0.256339139  0  1  1  0  1 1 #>  90: 49.53415 51.54923 -1.54889847  0.032008937  0.005456635  1  1  1  1  0 1 #>  91: 64.49913 69.79595  0.32266619 -0.230910497  0.741769953  0  1  0  1  1 0 #>  92: 40.62557 62.61934  0.25213485 -0.277975908 -2.685602399  0  1  0  0  0 1 #>  93: 64.88648 59.03623  0.69127232 -1.339535295  1.101621330  0  1  0  1  1 1 #>  94: 66.47275 64.78869  1.18338315 -0.834602773  1.218020447  0  1  0  1  1 1 #>  95: 51.23077 60.85499 -1.53210388  0.331266844  1.501020579  0  1  0  1  0 0 #>  96: 76.13213 51.24694  1.32356115 -0.861312945 -1.185903183  0  1  0  1  0 1 #>  97: 80.60242 65.63773  0.81922078  0.441595794 -1.421862105  0  1  1  0  1 1 #>  98: 67.69269 50.80752  1.80025247  0.730770391 -0.487275186  1  2  0  0  1 1 #>  99: 54.35984 57.30480 -1.61885892  1.378323304  0.589980565  0  1  0  0  1 0 #> 100: 82.50348 56.96561 -0.01577496  0.481238079 -0.454240463  0  1  0  1  0 1 #>            X6       X7          X8           X9          X10 X1 X2 X3 X4 X5 Y  ## estimate a logistic regression model fit <- glm(formula = Y ~ X1+X2, data=dtB, family = \"binomial\")  ## compute the ATE using X1 as the treatment variable ## only point estimate (argument se = FALSE) ateFit1a <- ate(fit, data = dtB, treatment = \"X1\", se = FALSE) #>  Input variables  #>  - Treatment            : X1 (2 levels: \"0\" \"1\") #>  - Event                : Y (cause: 1, competing risk(s): 0) #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  #>  Processing #>  - Point estimation: done  ateFit1a #>      Average treatment effect for cause 1  #>  #>  - Treatment            : X1 (2 levels: \"0\" \"1\") #>  - Event                : Y (cause: 1, competing risk(s): 0) #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  #>  Results  #>  - Standardized risks   :                 #>  X1=A X1=B    risk.A    risk.B difference (B-A) ratio (B/A) #>     0    1 0.5853676 0.9444428        0.3590752    1.613418 #>  #>  - Computation time     : 0.01257181 secs (point estimate) #>   if (FALSE) { ## with confidence intervals ateFit1b <- ate(fit, data = dtB, treatment = \"X1\",                times = 5) ## just for having a nice output not used in computations summary(ateFit1b, short = TRUE)  ## using the lava package library(lava) ateLava <- estimate(fit, function(p, data){ a <- p[\"(Intercept)\"] ; b <- p[\"X11\"] ; c <- p[\"X2\"] ; R.X11 <- expit(a + b + c * data[[\"X2\"]]) R.X10 <- expit(a + c * data[[\"X2\"]]) list(risk0=R.X10,risk1=R.X11,riskdiff=R.X11-R.X10)}, average=TRUE) ateLava }  ## see wglm for handling right-censoring with glm  #### Competing risks settings               #### #### ATE with cause specific Cox regression ####  ## generate data n <- 500 set.seed(10) dt <- sampleData(n, outcome=\"competing.risks\") dt$X1 <- factor(rbinom(n, prob = c(0.2,0.3) , size = 2), labels = paste0(\"T\",0:2))  ## estimate cause specific Cox model fitCR <-  CSC(Hist(time,event)~ X1+X8,data=dt,cause=1)  ## compute the ATE at times 1, 5, 10 using X1 as the treatment variable ateFit2a <- ate(fitCR, data = dt, treatment = \"X1\", times = c(1,5,10),                 cause = 1, se = TRUE, band = TRUE) #>  Input variables  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, competing risk(s): 2, censoring: 0) #>  - Time  [min;max]      : time [0.0839;19.1] #>  - Eval. time           :   1   5 10 #>       number at risk T0   263 106 12 #>       number at risk T1   160  57 11 #>       number at risk T2    26  15  3 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Processing #>  - Prepare influence function: outcome done  #>  - Point estimation: done  #>  - Decomposition iid: done #>  - Confidence intervals / bands: done summary(ateFit2a) #>      Average treatment effect for cause 1  #>  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, competing risk(s): 2, censoring: 0) #>  - Time  [min;max]      : time [0.0839;19.1] #>  - Eval. time           :   1   5 10 #>       number at risk T0   263 106 12 #>       number at risk T1   160  57 11 #>       number at risk T2    26  15  3 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Testing procedure #>  - Null hypothesis     : given two treatments (A,B), equal risks at all timepoints  #>  - Confidence level    : 0.95 #>  - Multiple comparisons: single-step max-T adjustment computed using 10000 simulations #>  #>  Results:  #>  - Difference in standardized risk (B-A) between time zero and 'time'  #>                 reported on the scale [-1;1] (difference between two probabilities) #>  (difference in average risks when treating all subjects with the experimental treatment (B), #>                                 vs. treating all subjects with the reference treatment (A)) #>  #>  time X1=A risk(X1=A) X1=B risk(X1=B) difference           ci p.value #>     1   T0     0.0673   T1     0.0681   8.72e-04 [-0.02;0.02]   0.926 #>     5   T0     0.3744   T1     0.3743  -2.52e-05 [-0.08;0.08]   1.000 #>    10   T0     0.5017   T1     0.4935  -8.21e-03 [-0.10;0.09]   0.867 #>     1   T0     0.0673   T2     0.0523  -1.49e-02 [-0.05;0.02]   0.355 #>     5   T0     0.3744   T2     0.3063  -6.81e-02 [-0.22;0.09]   0.388 #>    10   T0     0.5017   T2     0.4253  -7.64e-02 [-0.27;0.12]   0.434 #>     1   T1     0.0681   T2     0.0523  -1.58e-02 [-0.05;0.02]   0.346 #>     5   T1     0.3743   T2     0.3063  -6.80e-02 [-0.23;0.09]   0.404 #>    10   T1     0.4935   T2     0.4253  -6.82e-02 [-0.27;0.13]   0.498 #>  simultaneous ci adjusted p.value #>     [-0.02;0.02]            0.987 #>     [-0.09;0.09]            1.000 #>     [-0.11;0.09]            0.953 #>     [-0.05;0.02]            0.419 #>     [-0.23;0.10]            0.454 #>     [-0.28;0.13]            0.507 #>     [-0.05;0.02]            0.409 #>     [-0.24;0.10]            0.472 #>     [-0.28;0.14]            0.581 #>  #>  difference      : estimated difference in standardized risks  #>  ci              : pointwise confidence intervals  #>  p.value         : (unadjusted) p-value  #>  simultaneous ci : simulatenous confidence intervals over time #>  adjusted p.value: p-value adjusted for multiple comparisons over time as.data.table(ateFit2a) #>          type estimator time level      estimate          se       lower #>  1:  meanRisk  GFORMULA    1    T0  6.725075e-02 0.012050231  0.04363273 #>  2:  meanRisk  GFORMULA    5    T0  3.743564e-01 0.027863621  0.31974466 #>  3:  meanRisk  GFORMULA   10    T0  5.017158e-01 0.032588024  0.43784440 #>  4:  meanRisk  GFORMULA    1    T1  6.812318e-02 0.012567904  0.04349054 #>  5:  meanRisk  GFORMULA    5    T1  3.743311e-01 0.034694830  0.30633052 #>  6:  meanRisk  GFORMULA   10    T1  4.935039e-01 0.039653201  0.41578504 #>  7:  meanRisk  GFORMULA    1    T2  5.232115e-02 0.018006403  0.01702925 #>  8:  meanRisk  GFORMULA    5    T2  3.062972e-01 0.075452662  0.15841267 #>  9:  meanRisk  GFORMULA   10    T2  4.253305e-01 0.093198889  0.24266407 #> 10:  diffRisk  GFORMULA    1 T0.T1  8.724303e-04 0.009441589 -0.01763274 #> 11:  diffRisk  GFORMULA    5 T0.T1 -2.520916e-05 0.041528106 -0.08141880 #> 12:  diffRisk  GFORMULA   10 T0.T1 -8.211865e-03 0.049084017 -0.10441477 #> 13:  diffRisk  GFORMULA    1 T0.T2 -1.492961e-02 0.016145110 -0.04657344 #> 14:  diffRisk  GFORMULA    5 T0.T2 -6.805918e-02 0.078813390 -0.22253059 #> 15:  diffRisk  GFORMULA   10 T0.T2 -7.638522e-02 0.097706198 -0.26788585 #> 16:  diffRisk  GFORMULA    1 T1.T2 -1.580204e-02 0.016761368 -0.04865371 #> 17:  diffRisk  GFORMULA    5 T1.T2 -6.803397e-02 0.081442901 -0.22765912 #> 18:  diffRisk  GFORMULA   10 T1.T2 -6.817335e-02 0.100625523 -0.26539576 #> 19: ratioRisk  GFORMULA    1 T0.T1  1.012973e+00 0.141191244  0.73624304 #> 20: ratioRisk  GFORMULA    5 T0.T1  9.999327e-01 0.110929211  0.78251540 #> 21: ratioRisk  GFORMULA   10 T0.T1  9.836324e-01 0.097205064  0.79311401 #> 22: ratioRisk  GFORMULA    1 T0.T2  7.780009e-01 0.234968184  0.31747172 #> 23: ratioRisk  GFORMULA    5 T0.T2  8.181968e-01 0.206945429  0.41259122 #> 24: ratioRisk  GFORMULA   10 T0.T2  8.477520e-01 0.191990382  0.47145777 #> 25: ratioRisk  GFORMULA    1 T1.T2  7.680373e-01 0.237987611  0.30159016 #> 26: ratioRisk  GFORMULA    5 T1.T2  8.182519e-01 0.211754010  0.40322167 #> 27: ratioRisk  GFORMULA   10 T1.T2  8.618585e-01 0.199975344  0.46991406 #>          type estimator time level      estimate          se       lower #>          upper quantileBand   lowerBand  upperBand   p.value adj.p.value #>  1: 0.09086877     2.317771  0.03932108 0.09518043        NA          NA #>  2: 0.42896804     2.317771  0.30977486 0.43893784        NA          NA #>  3: 0.56558711     2.317771  0.42618418 0.57724733        NA          NA #>  4: 0.09275582     2.300197  0.03921453 0.09703183        NA          NA #>  5: 0.44233176     2.300197  0.29452621 0.45413608        NA          NA #>  6: 0.57122274     2.300197  0.40229373 0.58471405        NA          NA #>  7: 0.08761305     2.173021  0.01319285 0.09144944        NA          NA #>  8: 0.45418167     2.173021  0.14233695 0.47025739        NA          NA #>  9: 0.60799700     2.173021  0.22280739 0.62785368        NA          NA #> 10: 0.01937760     2.077331 -0.01874087 0.02048573 0.9263779      0.9866 #> 11: 0.08136838     2.077331 -0.08629282 0.08624240 0.9995157      1.0000 #> 12: 0.08799104     2.077331 -0.11017560 0.09375187 0.8671323      0.9528 #> 13: 0.01671423     2.100121 -0.04883630 0.01897708 0.3551148      0.4188 #> 14: 0.08641222     2.100121 -0.23357685 0.09745849 0.3878360      0.4544 #> 15: 0.11511541     2.100121 -0.28158008 0.12880964 0.4343411      0.5071 #> 16: 0.01704964     2.101442 -0.05102508 0.01942101 0.3458009      0.4095 #> 17: 0.09159118     2.101442 -0.23918153 0.10311359 0.4035162      0.4725 #> 18: 0.12904905     2.101442 -0.27963209 0.14328538 0.4980915      0.5807 #> 19: 1.28970255     2.090655  0.71779060 1.30815499 0.9267926      0.9851 #> 20: 1.21734992     2.090655  0.76801794 1.23184738 0.9995156      1.0000 #> 21: 1.17415086     2.090655  0.78041017 1.18685470 0.8662829      0.9563 #> 22: 1.23853008     2.011050  0.30546805 1.25053374 0.3447585      0.3916 #> 23: 1.22380239     2.011050  0.40201913 1.23437448 0.3796681      0.4292 #> 24: 1.22404624     2.011050  0.46164968 1.23385433 0.4277790      0.4786 #> 25: 1.23448445     2.024729  0.28617680 1.24989782 0.3297171      0.3747 #> 26: 1.23328214     2.024729  0.38950734 1.24699647 0.3907278      0.4408 #> 27: 1.25380300     2.024729  0.45696257 1.26675448 0.4896959      0.5518 #>          upper quantileBand   lowerBand  upperBand   p.value adj.p.value  #### Double robust estimator #### if (FALSE) { ## generate data n <- 500 set.seed(10) dt <- sampleData(n, outcome=\"competing.risks\") dt$time <- round(dt$time,1) dt$X1 <- factor(rbinom(n, prob = c(0.4) , size = 1), labels = paste0(\"T\",0:1))  ## working models m.event <-  CSC(Hist(time,event)~ X1+X2+X3+X5+X8,data=dt) m.censor <-  coxph(Surv(time,event==0)~ X1+X2+X3+X5+X8,data=dt, x = TRUE, y = TRUE) m.treatment <-  glm(X1~X2+X3+X5+X8,data=dt,family=binomial(link=\"logit\"))  ## prediction + average ateRobust <- ate(event = m.event,                  treatment = m.treatment,                  censor = m.censor,                  data = dt, times = 5:10,                   cause = 1, band = TRUE)  ## compare various estimators ateRobust3 <- ate(event = m.event,                  treatment = m.treatment,                  censor = m.censor,                  estimator = c(\"GFORMULA\",\"IPTW\",\"AIPTW\"),                  data = dt, times = c(5:10),                   cause = 1, se = TRUE) print(setkeyv(as.data.table(ateRobust3, type = \"meanRisk\"),\"time\")) print(setkeyv(as.data.table(ateRobust3, type = \"diffRisk\"),\"time\")) }  #### time-dependent covariates ### if (FALSE) { library(survival) fit <- coxph(Surv(time, status) ~ celltype+karno + age + trt, veteran) vet2 <- survSplit(Surv(time, status) ~., veteran,                        cut=c(60, 120), episode =\"timegroup\") fitTD <- coxph(Surv(tstart, time, status) ~ celltype +karno + age + trt,                data= vet2,x=1) set.seed(16) resVet <- ate(fitTD,formula=Hist(entry=tstart,time=time,event=status)~1,           data = vet2, treatment = \"celltype\",         times=5,verbose=1,         landmark = c(0,30,60,90), cause = 1, B = 50, se = 1,         band = FALSE, mc.cores=1) summary(resVet) }  if (FALSE) { set.seed(137) d=sampleDataTD(127) library(survival) d[,status:=1*(event==1)] d[,X3:=as.factor(X3)] ## ignore competing risks cox1TD <- coxph(Surv(start,time, status,type=\"counting\") ~ X3+X5+X6+X8,                 data=d, x = TRUE) resTD1 <- ate(cox1TD,formula=Hist(entry=start,time=time,event=status)~1,         data = d, treatment = \"X3\", contrasts = NULL,         times=.5,verbose=1,         landmark = c(0,0.5,1), B = 20, se = 1,         band = FALSE, mc.cores=1) resTD1 ## account for competing risks cscTD <- CSC(Hist(time=time, event=event,entry=start) ~ X3+X5+X6+X8, data=d) set.seed(16) resTD <- ate(cscTD,formula=Hist(entry=start,time=time,event=event)~1,         data = d, treatment = \"X3\", contrasts = NULL,         times=.5,verbose=1,         landmark = c(0,0.5,1), cause = 1, B = 20, se = 1,         band = FALSE, mc.cores=1) resTD }"},{"path":"/reference/autoplot.Score.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot AUC curve — autoplot.Score","title":"ggplot AUC curve — autoplot.Score","text":"ggplot AUC curves","code":""},{"path":"/reference/autoplot.Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot AUC curve — autoplot.Score","text":"","code":"# S3 method for Score autoplot(   object,   models,   type = \"score\",   lwd = 2,   xlim,   ylim,   axes = TRUE,   conf.int = FALSE,   ... )"},{"path":"/reference/autoplot.Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot AUC curve — autoplot.Score","text":"object Object obtained Score.list models Choice models plot type Character. Either \"score\" show AUC \"contrasts\" show differences AUC. lwd Line width xlim Limits x-axis ylim Limits y-axis axes Logical. TRUE draw axes. conf.int Logical. TRUE draw confidence shadows. ... yet used","code":""},{"path":"/reference/autoplot.Score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot AUC curve — autoplot.Score","text":"","code":"library(survival) library(ggplot2) d=sampleData(100,outcome=\"survival\") nd=sampleData(100,outcome=\"survival\") f1=coxph(Surv(time,event)~X1+X6+X8,data=d,x=TRUE,y=TRUE) f2=coxph(Surv(time,event)~X2+X5+X9,data=d,x=TRUE,y=TRUE) xx=Score(list(f1,f2), formula=Surv(time,event)~1, data=nd, metrics=\"auc\", null.model=FALSE, times=seq(3:10)) g <- autoplot(xx) print(g)  aucgraph <- plotAUC(xx)  plotAUC(xx,conf.int=TRUE)  plotAUC(xx,which=\"contrasts\")  plotAUC(xx,which=\"contrasts\",conf.int=TRUE)"},{"path":"/reference/autoplot.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Average Risks — autoplot.ate","title":"Plot Average Risks — autoplot.ate","text":"Plot average risks.","code":""},{"path":"/reference/autoplot.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Average Risks — autoplot.ate","text":"","code":"# S3 method for ate autoplot(   object,   type = \"meanRisk\",   first.derivative = FALSE,   estimator = object$estimator[1],   ci = object$inference$ci,   band = object$inference$band,   plot.type = \"1\",   plot = TRUE,   smooth = FALSE,   digits = 2,   alpha = NA,   ylab = NULL,   ... )"},{"path":"/reference/autoplot.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Average Risks — autoplot.ate","text":"object Object obtained function ate. type [character vector] displayed. Can \"meanRisk\" display risks specific treatment group, \"diffRisk\" display difference risks treatment groups, \"ratioRisk\" display ratio risks treatment groups,. first.derivative [logical] TRUE, display first derivative time risks/risk differences/risk ratios. (confidence intervals obtained via simulation). estimator [character] type estimator relative risks displayed. ci [logical] TRUE display confidence intervals average risks. band [logical] TRUE display confidence bands average risks. plot.type [character] Type plot used. plot.type=\"2\" useful looking simulateneous eventtimes. Otherwise use plot.type=\"1\". plot [logical] graphic plotted. smooth [logical] smooth version risk function plotted instead simple function? digits [integer, >0] Number decimal places. alpha [numeric, 0-1] Transparency confidence bands. Argument passed ggplot2::geom_ribbon. ylab [character] Label y axis. ... Additional parameters cutomize display.","code":""},{"path":"/reference/autoplot.ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Average Risks — autoplot.ate","text":"Invisible. list containing: plot: ggplot object. data: data used create plot.","code":""},{"path":[]},{"path":"/reference/autoplot.ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Average Risks — autoplot.ate","text":"","code":"library(survival) library(rms) library(ggplot2)  #### simulate data #### n <- 1e2 set.seed(10) dtS <- sampleData(n,outcome=\"survival\") seqTimes <- c(0,sort(dtS$time[dtS$event==1]),max(dtS$time))  #### Cox model #### fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)  #### plot.type = 1: for few timepoints #### ateFit <- ate(fit, data = dtS, treatment = \"X1\",               times = c(1,2,5,10), se = TRUE, band = TRUE) #>  Input variables  #>  - Treatment            : X1 (2 levels: \"0\" \"1\") #>  - Event                : event (cause: 1, censoring: 0) #>  - Time  [min;max]      : time [0.64;15.7] #>  - Eval. time          :  1  2  5 10 #>       number at risk 0   83 77 45  7 #>       number at risk 1   12  9  4  3 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Processing #>  - Prepare influence function: outcome done  #>  - Point estimation: done  #>  - Decomposition iid: done #>  - Confidence intervals / bands: done ggplot2::autoplot(ateFit)  if (FALSE) { ggplot2::autoplot(ateFit, band = FALSE) ggplot2::autoplot(ateFit, type = \"diffRisk\") ggplot2::autoplot(ateFit, type = \"ratioRisk\") }  #### plot.type = 2: when looking at all jump times #### if (FALSE) { ateFit <- ate(fit, data = dtS, treatment = \"X1\",               times = seqTimes, se = TRUE, band = TRUE)  ggplot2::autoplot(ateFit, plot.type = \"2\")  ## customize plot outGG <- ggplot2::autoplot(ateFit, plot.type = \"2\", alpha = 0.25) outGG$plot + facet_wrap(~X1, labeller = label_both)   ## Looking at the difference after smoothing outGGS <- ggplot2::autoplot(ateFit, plot.type = \"2\", alpha = NA, smooth = TRUE) outGGS$plot + facet_wrap(~X1, labeller = label_both)  ## first derivative ## (computation of the confidence intervals takes time) ## (based on simulation - n.sim parameter) ggplot2::autoplot(ateFit, plot.type = \"2\", smooth = TRUE,                   band = FALSE, type = \"diffRisk\") ggplot2::autoplot(ateFit, plot.type = \"2\", smooth = TRUE, first.derivative = TRUE,                   band = FALSE, type = \"diffRisk\") }"},{"path":"/reference/autoplot.predictCSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","title":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","text":"Plot predictions Cause-specific Cox proportional hazard regression.","code":""},{"path":"/reference/autoplot.predictCSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","text":"","code":"# S3 method for predictCSC autoplot(   object,   ci = object$se,   band = object$band,   plot = TRUE,   smooth = FALSE,   digits = 2,   alpha = NA,   group.by = \"row\",   reduce.data = FALSE,   ... )"},{"path":"/reference/autoplot.predictCSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","text":"object Object obtained function predictCox. ci [logical] TRUE display confidence intervals predictions. band [logical] TRUE display confidence bands predictions. plot [logical] graphic plotted. smooth [logical] smooth version risk function plotted instead simple function? digits [integer] Number decimal places. alpha [numeric, 0-1] Transparency confidence bands. Argument passed ggplot2::geom_ribbon. group.[character] grouping factor used color prediction curves. Can \"row\", \"strata\", \"covariates\". reduce.data [logical] TRUE covariates take indentical values observations displayed. ... Additional parameters cutomize display.","code":""},{"path":"/reference/autoplot.predictCSC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","text":"Invisible. list containing: plot: ggplot object. data: data used create plot.","code":""},{"path":[]},{"path":"/reference/autoplot.predictCSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Predictions From a Cause-specific Cox Proportional Hazard Regression — autoplot.predictCSC","text":"","code":"library(survival) library(rms) library(ggplot2) library(prodlim)  #### simulate data #### set.seed(10) d <- sampleData(1e2, outcome = \"competing.risks\") seqTau <- c(0,unique(sort(d[d$event==1,time])), max(d$time))  #### CSC model #### m.CSC <- CSC(Hist(time,event)~ X1 + X2 + X6, data = d)  pred.CSC <- predict(m.CSC, newdata = d[1:2,], time = seqTau, cause = 1, band = TRUE) autoplot(pred.CSC, alpha = 0.2)   #### stratified CSC model #### m.SCSC <- CSC(Hist(time,event)~ strata(X1) + strata(X2) + X6,               data = d) pred.SCSC <- predict(m.SCSC, time = seqTau, newdata = d[1:4,],                      cause = 1, keep.newdata = TRUE, keep.strata = TRUE) autoplot(pred.SCSC, group.by = \"strata\")"},{"path":"/reference/autoplot.predictCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Predictions From a Cox Model — autoplot.predictCox","title":"Plot Predictions From a Cox Model — autoplot.predictCox","text":"Plot predictions Cox model.","code":""},{"path":"/reference/autoplot.predictCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Predictions From a Cox Model — autoplot.predictCox","text":"","code":"# S3 method for predictCox autoplot(   object,   type = NULL,   ci = object$se,   band = object$band,   plot = TRUE,   smooth = NULL,   digits = 2,   alpha = NA,   group.by = \"row\",   reduce.data = FALSE,   ylab = NULL,   first.derivative = FALSE,   ... )"},{"path":"/reference/autoplot.predictCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Predictions From a Cox Model — autoplot.predictCox","text":"object Object obtained function predictCox. type [character] type predicted value display. Choices : \"hazard\" hazard function, \"cumhazard\" cumulative hazard function,  \"survival\" survival function. ci [logical] TRUE display confidence intervals predictions. band [logical] TRUE display confidence bands predictions. plot [logical] graphic plotted. smooth [logical] smooth version risk function plotted instead simple function? digits [integer] Number decimal places displaying values covariates caption. alpha [numeric, 0-1] Transparency confidence bands. Argument passed ggplot2::geom_ribbon. group.[character] grouping factor used color prediction curves. Can \"row\", \"strata\", \"covariates\". reduce.data [logical] TRUE covariates take indentical values observations displayed. ylab [character] Label y axis. first.derivative [logical] TRUE, display first derivative time risks/risk differences/risk ratios. (confidence intervals obtained via simulation). ... Additional parameters cutomize display.","code":""},{"path":"/reference/autoplot.predictCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Predictions From a Cox Model — autoplot.predictCox","text":"Invisible. list containing: plot: ggplot object. data: data used create plot.","code":""},{"path":[]},{"path":"/reference/autoplot.predictCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Predictions From a Cox Model — autoplot.predictCox","text":"","code":"library(survival) library(ggplot2)  #### simulate data #### set.seed(10) d <- sampleData(1e2, outcome = \"survival\") seqTau <- c(0,sort(unique(d$time[d$event==1])), max(d$time))  #### Cox model #### m.cox <- coxph(Surv(time,event)~ X1 + X2 + X3,                 data = d, x = TRUE, y = TRUE)  ## display baseline hazard e.basehaz <- predictCox(m.cox) autoplot(e.basehaz, type = \"cumhazard\")  if (FALSE) { autoplot(e.basehaz, type = \"cumhazard\", size.point = 0) ## without points autoplot(e.basehaz, type = \"cumhazard\", smooth = TRUE) autoplot(e.basehaz, type = \"cumhazard\", smooth = TRUE, first.derivative = TRUE) }  ## display baseline hazard with type of event if (FALSE) { e.basehaz <- predictCox(m.cox, keep.newdata = TRUE) autoplot(e.basehaz, type = \"cumhazard\") autoplot(e.basehaz, type = \"cumhazard\", shape.point = c(3,NA)) }  ## display predicted survival if (FALSE) { pred.cox <- predictCox(m.cox, newdata = d[1:2,],   times = seqTau, type = \"survival\", keep.newdata = TRUE) autoplot(pred.cox) autoplot(pred.cox, smooth = TRUE) autoplot(pred.cox, group.by = \"covariates\") autoplot(pred.cox, group.by = \"covariates\", reduce.data = TRUE) autoplot(pred.cox, group.by = \"X1\", reduce.data = TRUE) }  ## predictions with confidence interval/bands if (FALSE) { pred.cox <- predictCox(m.cox, newdata = d[1:2,,drop=FALSE],   times = seqTau, type = \"survival\", band = TRUE, se = TRUE, keep.newdata = TRUE) res <- autoplot(pred.cox, ci = TRUE, band = TRUE, plot = FALSE) res$plot + facet_wrap(~row) res2 <- autoplot(pred.cox, ci = TRUE, band = TRUE, alpha = 0.1, plot = FALSE) res2$plot + facet_wrap(~row) }  #### Stratified Cox model #### if (FALSE) { m.cox.strata <- coxph(Surv(time,event)~ strata(X1) + strata(X2) + X3 + X4,                       data = d, x = TRUE, y = TRUE)  ## baseline hazard pred.baseline <- predictCox(m.cox.strata, keep.newdata = TRUE, type = \"survival\") res <- autoplot(pred.baseline) res$plot + facet_wrap(~strata, labeller = label_both)  ## predictions pred.cox.strata <- predictCox(m.cox.strata, newdata = d[1:3,,drop=FALSE],                               time = seqTau, keep.newdata = TRUE, se = TRUE)  res2 <- autoplot(pred.cox.strata, type = \"survival\", group.by = \"strata\", plot = FALSE) res2$plot + facet_wrap(~strata, labeller = label_both) + theme(legend.position=\"bottom\")  ## smooth version autoplot(pred.cox.strata, type = \"survival\", group.by = \"strata\", smooth = TRUE, ci = FALSE) }  #### Cox model with splines #### if (FALSE) { require(splines) m.cox.spline <- coxph(Surv(time,event)~ X1 + X2 + ns(X6,4),                 data = d, x = TRUE, y = TRUE) grid <- data.frame(X1 = factor(0,0:1), X2 = factor(0,0:1),                    X6 = seq(min(d$X6),max(d$X6), length.out = 100)) pred.spline <- predictCox(m.cox.spline, newdata = grid, keep.newdata = TRUE,                           se = TRUE, band = TRUE, centered = TRUE, type = \"lp\") autoplot(pred.spline, group.by = \"X6\") autoplot(pred.spline, group.by = \"X6\", alpha = 0.5)  grid2 <- data.frame(X1 = factor(1,0:1), X2 = factor(0,0:1),                     X6 = seq(min(d$X6),max(d$X6), length.out = 100)) pred.spline <- predictCox(m.cox.spline, newdata = rbind(grid,grid2), keep.newdata = TRUE,                           se = TRUE, band = TRUE, centered = TRUE, type = \"lp\") autoplot(pred.spline, group.by = c(\"X6\",\"X1\"), alpha = 0.5, plot = FALSE)$plot + facet_wrap(~X1) }"},{"path":"/reference/baseHaz_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"C++ Fast Baseline Hazard Estimation — baseHaz_cpp","title":"C++ Fast Baseline Hazard Estimation — baseHaz_cpp","text":"C++ function estimate baseline hazard Cox Model","code":""},{"path":"/reference/baseHaz_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"C++ Fast Baseline Hazard Estimation — baseHaz_cpp","text":"","code":"baseHaz_cpp(   starttimes,   stoptimes,   status,   eXb,   strata,   predtimes,   emaxtimes,   nPatients,   nStrata,   cause,   Efron )"},{"path":"/reference/baseHaz_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"C++ Fast Baseline Hazard Estimation — baseHaz_cpp","text":"starttimes vector times (begin risk period). stoptimes vector times (end risk period). status vector indicating  censoring event. eXb numeric vector (exponential linear predictor). strata vector integers (index strata observation). predtimes vector times (time evaluate hazard). Must sorted. emaxtimes another vector times, one per strata (last observation time strata). nPatients number observations. nStrata number strata cause status value corresponding event. Efron whether Efron Breslow estimator used presence ties.","code":""},{"path":"/reference/baseHaz_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"C++ Fast Baseline Hazard Estimation — baseHaz_cpp","text":"WARNING stoptimes status eXb strata must sorted strata, stoptimes, status","code":""},{"path":"/reference/boot2pvalue.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the p.value from the distribution under H1 — boot2pvalue","title":"Compute the p.value from the distribution under H1 — boot2pvalue","text":"Compute p.value associated estimated statistic using bootstrap sample distribution H1.","code":""},{"path":"/reference/boot2pvalue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the p.value from the distribution under H1 — boot2pvalue","text":"","code":"boot2pvalue(   x,   null,   estimate = NULL,   alternative = \"two.sided\",   FUN.ci = quantileCI,   tol = .Machine$double.eps^0.5 )"},{"path":"/reference/boot2pvalue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the p.value from the distribution under H1 — boot2pvalue","text":"x [numeric vector] vector bootstrap estimates statistic. null [numeric] value statistic null hypothesis. estimate [numeric] estimated statistic. alternative [character] character string specifying alternative hypothesis, must one \"two.sided\" (default), \"greater\" \"less\". FUN.ci [function] function used compute confidence interval. Must take x, alternative, conf.level sign.estimate arguments return relevant limit (either upper lower) confidence interval. tol [numeric] absolute convergence tolerance.","code":""},{"path":"/reference/boot2pvalue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the p.value from the distribution under H1 — boot2pvalue","text":"test statistic close 0, function returns 1. positive test statistic, function search quantile alpha : quantile(x, probs = alpha)=0 argument alternative set \"greater\". quantile(x, probs = 0.5*alpha)=0 argument alternative set \"two.sided\". argument alternative set \"less\", returns 1. negative test statistic, function search quantile alpha : quantile(x, probs = 1-alpha=0 argument alternative set \"less\". quantile(x, probs = 1-0.5*alpha=0 argument alternative set \"two.sided\". argument alternative set \"greater\", returns 1.","code":""},{"path":"/reference/boot2pvalue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the p.value from the distribution under H1 — boot2pvalue","text":"","code":"set.seed(10)  #### no effect #### x <- rnorm(1e3)  boot2pvalue(x, null = 0, estimate = mean(x), alternative = \"two.sided\") #> Warning: incorrect convergence of the algorithm finding the critical quantile  #> p-value may not be reliable  #> [1] 0.999 ## expected value of 1 boot2pvalue(x, null = 0, estimate = mean(x), alternative = \"greater\") #> [1] 0.5 ## expected value of 0.5 boot2pvalue(x, null = 0, estimate = mean(x), alternative = \"less\") #> [1] 0.5 ## expected value of 0.5  #### positive effect #### x <- rnorm(1e3, mean = 1)  boot2pvalue(x, null = 0, estimate = 1, alternative = \"two.sided\") #> [1] 0.336 ## expected value of 0.32 = 2*pnorm(q = 0, mean = -1) = 2*mean(x<=0) boot2pvalue(x, null = 0, estimate = 1, alternative = \"greater\")   #> [1] 0.168 ## expected value of 0.16 = pnorm(q = 0, mean = 1) = mean(x<=0) boot2pvalue(x, null = 0, estimate = 1, alternative = \"less\") #> [1] 0.832 ## expected value of 0.84 = 1-pnorm(q = 0, mean = 1) = mean(x>=0)  #### negative effect #### x <- rnorm(1e3, mean = -1)  boot2pvalue(x, null = 0, estimate = -1, alternative = \"two.sided\")  #> [1] 0.301 ## expected value of 0.32 = 2*(1-pnorm(q = 0, mean = -1)) = 2*mean(x>=0) boot2pvalue(x, null = 0, estimate = -1, alternative = \"greater\") #> [1] 0.849 ## expected value of 0.84 = pnorm(q = 0, mean = -1) = mean(x<=0) boot2pvalue(x, null = 0, estimate = -1, alternative = \"less\") # pnorm(q = 0, mean = -1) #> [1] 0.151 ## expected value of 0.16 = 1-pnorm(q = 0, mean = -1) = mean(x>=0)"},{"path":"/reference/boxplot.Score.html","id":null,"dir":"Reference","previous_headings":"","what":"Boxplot risk quantiles — boxplot.Score","title":"Boxplot risk quantiles — boxplot.Score","text":"Retrospective boxplots risk quantiles conditional outcome","code":""},{"path":"/reference/boxplot.Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boxplot risk quantiles — boxplot.Score","text":"","code":"# S3 method for Score boxplot(   x,   model,   reference,   type = \"risk\",   timepoint,   overall = 1L,   lwd = 3,   xlim,   xlab = \"\",   main,   outcome.label,   outcome.label.offset = 0,   event.labels,   refline = (type != \"risk\"),   add = FALSE,   ... )"},{"path":"/reference/boxplot.Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boxplot risk quantiles — boxplot.Score","text":"x Score object obtained calling function Score. model Choice risk prediction model reference Choice reference risk prediction model calculation risk differences. type Either \"risk\" predicted risks \"diff\" differences predicted risks. timepoint time point specifying prediction horizon overall Logical. Tag documented. lwd line width xlim x-axis limits xlab x-axis label main title plot outcome.label Title label column shows outcome status outcome.label.offset Vertical offset outcome.label event.labels Labels different events (causes). refline Logical, type=\"diff\" . TRUE draw red vertical line 0. add Logical. Tag documented. ... used","code":""},{"path":"/reference/boxplot.Score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boxplot risk quantiles — boxplot.Score","text":"","code":"# binary outcome library(data.table) library(prodlim) db=sampleData(40,outcome=\"binary\") fitconv=glm(Y~X3+X5,data=db,family=binomial) fitnew=glm(Y~X1+X3+X5+X6+X7,data=db,family=binomial) x=Score(list(new=fitnew,conv=fitconv),         formula=Y~1,contrasts=list(c(2,1)),                data=db,plots=\"box\",null.model=FALSE) boxplot(x)   # survival outcome library(survival) ds=sampleData(40,outcome=\"survival\") fit=coxph(Surv(time,event)~X6+X9,data=ds,x=TRUE,y=TRUE) if (FALSE) {  scoreobj=Score(list(\"Cox\"=fit),                 formula=Hist(time,event)~1, data=ds,                 metrics=NULL, plots=\"box\",                 times=c(1,5),null.model=FALSE) boxplot(scoreobj,timepoint=5) boxplot(scoreobj,timepoint=1)  }  # competing risks outcome library(survival) data(Melanoma, package = \"riskRegression\") fit = CSC(Hist(time,event,cens.code=\"censored\")~invasion+age+sex,data=Melanoma) #> Warning: Variables named status in data will be ignored. #> Warning: Variables named status in data will be ignored. scoreobj=Score(list(\"CSC\"=fit),                formula=Hist(time,event,cens.code=\"censored\")~1,                data=Melanoma,plots=\"box\",times=5*365.25,null.model=FALSE) par(mar=c(4,12,4,4)) boxplot(scoreobj,timepoint=5*365.25)   # more than 2 competing risks m=lava::lvm(~X1+X2+X3) lava::distribution(m, \"eventtime1\") <- lava::coxWeibull.lvm(scale = 1/100) lava::distribution(m, \"eventtime2\") <- lava::coxWeibull.lvm(scale = 1/100) lava::distribution(m, \"eventtime3\") <- lava::coxWeibull.lvm(scale = 1/100) lava::distribution(m, \"censtime\") <- lava::coxWeibull.lvm(scale = 1/100) lava::regression(m,eventtime2~X3)=1.3 m <- lava::eventTime(m, time ~ min(eventtime1 = 1, eventtime2 = 2, eventtime3 = 3, censtime = 0), \"event\") set.seed(101) dcr=as.data.table(lava::sim(m,101)) fit = CSC(Hist(time,event)~X1+X2+X3,data=dcr) scoreobj=Score(list(\"my model\"=fit),                formula=Hist(time,event)~1,                data=dcr,plots=\"box\",times=5,null.model=FALSE) boxplot(scoreobj)"},{"path":"/reference/calcSeCSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard error of the absolute risk predicted from cause-specific Cox models — calcSeCSC","title":"Standard error of the absolute risk predicted from cause-specific Cox models — calcSeCSC","text":"Standard error absolute risk predicted cause-specific Cox models using first order von Mises expansion absolute risk functional.","code":""},{"path":"/reference/calcSeCSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard error of the absolute risk predicted from cause-specific Cox models — calcSeCSC","text":"","code":"calcSeCSC(   object,   cif,   hazard,   cumhazard,   survival,   object.time,   object.maxtime,   eXb,   new.LPdata,   new.strata,   times,   surv.type,   ls.infoVar,   new.n,   cause,   nCause,   nVar.lp,   export,   store.iid,   diag )"},{"path":"/reference/calcSeCSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard error of the absolute risk predicted from cause-specific Cox models — calcSeCSC","text":"object fitted cause specific Cox model cif cumulative incidence function prediction time individual. hazard list containing baseline hazard cause matrix form. Columns correspond strata. cumhazard list containing cumulative baseline hazard cause matrix form. Columns correspond strata. survival list containing (cause) survival matrix form t-. Columns correspond event times. object.time vector containing events regardless cause. object.maxtime matrix containing latest event strata observation cause. eXb matrix containing exponential linear predictor evaluated new observations (rows) cause (columns) new.LPdata list design matrices new observations cause. new.strata matrix containing strata indicator observation cause. times time points evaluate predictions. surv.type see surv.type argument CSC. ls.infoVar list containing output coxVariableName Cox model. new.n number new observations. cause cause interest. nCause number causes. nVar.lp number variables form linear predictor Cox model export can \"iid\" return value influence function observation \"se\" return standard error given timepoint store.iid method used compute influence function standard error. Can \"full\" \"minimal\". See details section. diag [logical] FALSE absolute risk/survival observations times computed, otherwise computed -th observation -th time.","code":""},{"path":"/reference/calcSeCSC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard error of the absolute risk predicted from cause-specific Cox models — calcSeCSC","text":"Can also return empirical influence function functionals cumulative hazard survival sum observations empirical influence function. store.iid=\"full\" compute influence function observation time argument times computing standard error / influence functions. store.iid=\"minimal\" recompute subject specific prediction influence function baseline hazard. avoid store influence functions may lead repeated evaluation influence function. solution therefore efficient efficient memory usage may term computation time.","code":""},{"path":"/reference/calcSeCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of standard errors for predictions — calcSeCox","title":"Computation of standard errors for predictions — calcSeCox","text":"Compute standard error associated predictions Cox regression model using first order von Mises expansion functional (cumulative hazard survival).","code":""},{"path":"/reference/calcSeCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of standard errors for predictions — calcSeCox","text":"","code":"calcSeCox(   object,   times,   nTimes,   type,   diag,   Lambda0,   object.n,   object.time,   object.eXb,   object.strata,   nStrata,   new.n,   new.eXb,   new.LPdata,   new.strata,   new.survival,   nVar.lp,   export,   store.iid )"},{"path":"/reference/calcSeCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of standard errors for predictions — calcSeCox","text":"object fitted Cox regression model object either obtained coxph (survival package) cph (rms package). times Vector times return estimated hazard/survival. nTimes length argument times. type One several strings match (either lower upper case mixtures) one several strings \"hazard\",\"cumhazard\", \"survival\". diag [logical] FALSE hazard/cumlative hazard/survival observations times computed, otherwise computed -th observation -th time. Lambda0 baseline hazard estimate returned BaseHazStrata_cpp. object.n number observations dataset used estimate object. object.time time event observations used estimate object. object.eXb exponential linear predictor relative observations used estimate object. object.strata strata index observations used estimate object. nStrata number strata. new.n number observations prediction performed. new.eXb linear predictor evaluated new observations. new.LPdata variables involved linear predictor new observations. new.strata strata indicator new observations. new.survival survival evaluated new observations. nVar.lp number variables form linear predictor. export can \"iid\" return value influence function observation. \"se\" return standard error given timepoint. \"average.iid\" return value average influence function observations prediction performed. store.iid Implementation used estimate influence function standard error. Can \"full\" \"minimal\". See details section.","code":""},{"path":"/reference/calcSeCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computation of standard errors for predictions — calcSeCox","text":"list optionally containing standard error survival, cumulative hazard hazard.","code":""},{"path":"/reference/calcSeCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computation of standard errors for predictions — calcSeCox","text":"store.iid=\"full\" compute influence function observation time argument times computing standard error / influence functions. store.iid=\"minimal\" recompute subject specific prediction influence function baseline hazard. avoid store influence functions may lead repeated evaluation influence function. solution therefore efficient memory usage may terms computation time.","code":""},{"path":"/reference/calcSeCox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computation of standard errors for predictions — calcSeCox","text":"Brice Ozenne broz@sund.ku.dk, Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/coef.CauseSpecificCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract coefficients from a Cause-Specific Cox regression model — coef.CauseSpecificCox","title":"Extract coefficients from a Cause-Specific Cox regression model — coef.CauseSpecificCox","text":"Extract coefficients Cause-Specific Cox regression model","code":""},{"path":"/reference/coef.CauseSpecificCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract coefficients from a Cause-Specific Cox regression model — coef.CauseSpecificCox","text":"","code":"# S3 method for CauseSpecificCox coef(object, ...)"},{"path":"/reference/coef.CauseSpecificCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract coefficients from a Cause-Specific Cox regression model — coef.CauseSpecificCox","text":"object Object obtained CSC ... used","code":""},{"path":"/reference/coef.riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract coefficients from riskRegression model — coef.riskRegression","title":"Extract coefficients from riskRegression model — coef.riskRegression","text":"Extract coefficients riskRegression model","code":""},{"path":"/reference/coef.riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract coefficients from riskRegression model — coef.riskRegression","text":"","code":"# S3 method for riskRegression coef(object, digits = 3, eps = 10^-4, ...)"},{"path":"/reference/coef.riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract coefficients from riskRegression model — coef.riskRegression","text":"object Object obtained ARR LRR riskRegression digits Number digits eps P-values number shown <eps ... used","code":""},{"path":"/reference/colCenter_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply - by column — colCenter_cpp","title":"Apply - by column — colCenter_cpp","text":"Fast computation sweep(X, MARGIN = 1, FUN = \"-\", STATS = center)","code":""},{"path":"/reference/colCenter_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply - by column — colCenter_cpp","text":"","code":"colCenter_cpp(X, center)"},{"path":"/reference/colCenter_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply - by column — colCenter_cpp","text":"X matrix. center numeric vector length equal number rows x","code":""},{"path":"/reference/colCenter_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply - by column — colCenter_cpp","text":"matrix size X.","code":""},{"path":"/reference/colCenter_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply - by column — colCenter_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/colCenter_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply - by column — colCenter_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 1, FUN = \"-\", STATS = 1:6) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    0    0    0    0 #> [2,]   -1   -1   -1   -1   -1 #> [3,]   -2   -2   -2   -2   -2 #> [4,]   -3   -3   -3   -3   -3 #> [5,]   -4   -4   -4   -4   -4 #> [6,]   -5   -5   -5   -5   -5 colCenter_cpp(x, 1:6 ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    0    0    0    0 #> [2,]   -1   -1   -1   -1   -1 #> [3,]   -2   -2   -2   -2   -2 #> [4,]   -3   -3   -3   -3   -3 #> [5,]   -4   -4   -4   -4   -4 #> [6,]   -5   -5   -5   -5   -5"},{"path":"/reference/colCumProd.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply cumprod in each column — colCumProd","title":"Apply cumprod in each column — colCumProd","text":"Fast computation apply(x,2,cumprod)","code":""},{"path":"/reference/colCumProd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply cumprod in each column — colCumProd","text":"","code":"colCumProd(x)"},{"path":"/reference/colCumProd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply cumprod in each column — colCumProd","text":"x matrix.","code":""},{"path":"/reference/colCumProd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply cumprod in each column — colCumProd","text":"matrix size x.","code":""},{"path":"/reference/colCumProd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply cumprod in each column — colCumProd","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/colCumProd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply cumprod in each column — colCumProd","text":"","code":"x <- matrix(1:8,ncol=2) colCumProd(x) #>      [,1] [,2] #> [1,]    1    5 #> [2,]    2   30 #> [3,]    6  210 #> [4,]   24 1680"},{"path":"/reference/colCumSum.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply cumsum in each column — colCumSum","title":"Apply cumsum in each column — colCumSum","text":"Fast computation apply(x,2,cumsum)","code":""},{"path":"/reference/colCumSum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply cumsum in each column — colCumSum","text":"","code":"colCumSum(x)"},{"path":"/reference/colCumSum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply cumsum in each column — colCumSum","text":"x matrix.","code":""},{"path":"/reference/colCumSum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply cumsum in each column — colCumSum","text":"matrix size x.","code":""},{"path":"/reference/colCumSum.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply cumsum in each column — colCumSum","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/colCumSum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply cumsum in each column — colCumSum","text":"","code":"x <- matrix(1:8,ncol=2) colCumSum(x) #>      [,1] [,2] #> [1,]    1    5 #> [2,]    3   11 #> [3,]    6   18 #> [4,]   10   26"},{"path":"/reference/colMultiply_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply * by column — colMultiply_cpp","title":"Apply * by column — colMultiply_cpp","text":"Fast computation sweep(X, MARGIN = 1, FUN = \"*\", STATS = scale)","code":""},{"path":"/reference/colMultiply_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply * by column — colMultiply_cpp","text":"","code":"colMultiply_cpp(X, scale)"},{"path":"/reference/colMultiply_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply * by column — colMultiply_cpp","text":"X matrix. scale numeric vector length equal number rows x","code":""},{"path":"/reference/colMultiply_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply * by column — colMultiply_cpp","text":"matrix size X.","code":""},{"path":"/reference/colMultiply_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply * by column — colMultiply_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/colMultiply_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply * by column — colMultiply_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 1, FUN = \"*\", STATS = 1:6) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    1    1    1    1 #> [2,]    2    2    2    2    2 #> [3,]    3    3    3    3    3 #> [4,]    4    4    4    4    4 #> [5,]    5    5    5    5    5 #> [6,]    6    6    6    6    6 colMultiply_cpp(x, 1:6 ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    1    1    1    1 #> [2,]    2    2    2    2    2 #> [3,]    3    3    3    3    3 #> [4,]    4    4    4    4    4 #> [5,]    5    5    5    5    5 #> [6,]    6    6    6    6    6"},{"path":"/reference/colScale_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply / by column — colScale_cpp","title":"Apply / by column — colScale_cpp","text":"Fast computation sweep(X, MARGIN = 1, FUN = \"/\", STATS = scale)","code":""},{"path":"/reference/colScale_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply / by column — colScale_cpp","text":"","code":"colScale_cpp(X, scale)"},{"path":"/reference/colScale_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply / by column — colScale_cpp","text":"X matrix. scale numeric vector length equal number rows x","code":""},{"path":"/reference/colScale_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply / by column — colScale_cpp","text":"matrix size X.","code":""},{"path":"/reference/colScale_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply / by column — colScale_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/colScale_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply / by column — colScale_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 1, FUN = \"/\", STATS = 1:6) #>           [,1]      [,2]      [,3]      [,4]      [,5] #> [1,] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 #> [2,] 0.5000000 0.5000000 0.5000000 0.5000000 0.5000000 #> [3,] 0.3333333 0.3333333 0.3333333 0.3333333 0.3333333 #> [4,] 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000 #> [5,] 0.2000000 0.2000000 0.2000000 0.2000000 0.2000000 #> [6,] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 colScale_cpp(x, 1:6 ) #>           [,1]      [,2]      [,3]      [,4]      [,5] #> [1,] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 #> [2,] 0.5000000 0.5000000 0.5000000 0.5000000 0.5000000 #> [3,] 0.3333333 0.3333333 0.3333333 0.3333333 0.3333333 #> [4,] 0.2500000 0.2500000 0.2500000 0.2500000 0.2500000 #> [5,] 0.2000000 0.2000000 0.2000000 0.2000000 0.2000000 #> [6,] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667"},{"path":"/reference/colSumsCrossprod.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply crossprod and colSums — colSumsCrossprod","title":"Apply crossprod and colSums — colSumsCrossprod","text":"Fast computation crossprod(colSums(X),Y)","code":""},{"path":"/reference/colSumsCrossprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply crossprod and colSums — colSumsCrossprod","text":"","code":"colSumsCrossprod(X, Y, transposeY)"},{"path":"/reference/colSumsCrossprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply crossprod and colSums — colSumsCrossprod","text":"X matrix dimensions k*n. Hence result colSums(X) length n. Y matrix dimenions n*m. Can matrix dimension m*n transposeY TRUE. transposeY Logical. TRUE transpose Y matrix multiplication.","code":""},{"path":"/reference/colSumsCrossprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply crossprod and colSums — colSumsCrossprod","text":"vector length m.","code":""},{"path":"/reference/colSumsCrossprod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply crossprod and colSums — colSumsCrossprod","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/colSumsCrossprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply crossprod and colSums — colSumsCrossprod","text":"","code":"x <- matrix(1:8,ncol=2) y <- matrix(1:16,ncol=8) colSumsCrossprod(x,y,0) #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,]   62  134  206  278  350  422  494  566  x <- matrix(1:8,ncol=2) y <- matrix(1:16,ncol=2) colSumsCrossprod(x,y,1) #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #> [1,]  244  280  316  352  388  424  460  496"},{"path":"/reference/confint.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"Confidence intervals confidence Bands predicted absolute risk (cumulative incidence function).","code":""},{"path":"/reference/confint.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"","code":"# S3 method for ate confint(   object,   parm = NULL,   level = 0.95,   n.sim = 10000,   estimator = object$estimator,   contrasts = object$contrasts,   allContrasts = object$allContrasts,   meanRisk.transform = \"none\",   diffRisk.transform = \"none\",   ratioRisk.transform = \"none\",   seed = NA,   ci = object$inference$se,   band = object$inference$band,   p.value = TRUE,   method.band = \"maxT-simulation\",   alternative = \"two.sided\",   bootci.method = \"perc\",   ... )"},{"path":"/reference/confint.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"object ate object, .e. output ate function. parm used. compatibility generic method. level [numeric, 0-1] Level confidence. n.sim [integer, >0] number simulations used compute quantiles confidence bands /perform adjustment multiple comparisons. estimator [character] type estimator relative estimates displayed. contrasts [character vector] levels treatment variable risks assessed compared. Default consider levels. allContrasts [2-row character matrix] levels treatment variable compared. Default consider pairwise comparisons. meanRisk.transform [character] transformation used improve coverage confidence intervals mean risk small samples. Can \"none\", \"log\", \"loglog\", \"cloglog\". diffRisk.transform [character] transformation used improve coverage confidence intervals risk difference small samples. Can \"none\", \"atanh\". ratioRisk.transform [character] transformation used improve coverage confidence intervals risk ratio small samples. Can \"none\", \"log\". seed [integer, >0] seed number set performing simulation confidence bands. given NA seed set. ci [logical] confidence intervals computed? band [logical] confidence bands computed? p.value [logical] p-values/adjusted p-values computed? Requires argument ci /band TRUE. method.band [character] method used adjust multiple comparisons. Can element p.adjust.methods (e.g. \"holm\"), \"maxT-integration\", \"maxT-simulation\". alternative [character] character string specifying alternative hypothesis, must one \"two.sided\" (default), \"greater\" \"less\". bootci.method [character] Method constructing bootstrap confidence intervals. Either \"perc\" (default), \"norm\", \"basic\", \"stud\", \"bca\". ... used.","code":""},{"path":"/reference/confint.ate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"Argument ci, band, p.value, method.band, alternative, meanRisk.transform, diffRisk.transform, ratioRisk.transform active ate object contains influence function. Argument bootci.method active ate object contains bootstrap samples. Influence function: confidence bands confidence intervals computed via influence function automatically restricted interval definition parameter (e.g. [0;1] average risk). Single step max adjustment multiple comparisons, .e. accounting correlation test statistics ordering tests, can performed setting arguemnt method.band \"maxT-integration\" \"maxT-simulation\". former uses numerical integration (pmvnorm qmvnorm perform adjustment latter using simulation. assume test statistics jointly normally distributed. Bootstrap: confidence intervals obtained via bootstrap computed using boot.ci function boot package. p-value obtained using test inversion method (finding smallest confidence level interval contain null hypothesis).","code":""},{"path":"/reference/confint.ate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"Brice Ozenne","code":""},{"path":"/reference/confint.ate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.ate","text":"","code":"library(survival) library(data.table)  ## ## generate data #### set.seed(10) d <- sampleData(70,outcome=\"survival\") d[, X1 := paste0(\"T\",rbinom(.N, size = 2, prob = c(0.51)))] #>           X6       X7           X8          X9         X10 X1 X2 X3 X4 X5 #>  1: 73.81825 62.37447 -0.886787966  0.32751014  0.14188028 T2  0  1  1  0 #>  2: 55.03195 66.16529  1.271146001  0.06386348  1.26171505 T2  1  0  0  1 #>  3: 79.30851 57.03436 -1.605085441 -1.13956094 -0.43150033 T1  0  1  0  1 #>  4: 60.85891 63.76131  1.122273383  1.18041020 -1.82271259 T0  1  0  1  1 #>  5: 26.94100 63.06023  2.158438642  0.04138848  0.35254396 T0  0  0  0  0 #>  6: 52.15634 58.85671  0.428246613 -1.21359356 -1.34845144 T1  1  1  1  1 #>  7: 76.21178 56.47580  1.201178690  0.07319578  0.70768832 T1  1  1  0  0 #>  8: 56.35288 66.14758  1.031690116 -0.25732459 -0.41089094 T0  0  0  1  1 #>  9: 46.35830 67.59258  0.653874253  0.26680641 -0.44604518 T0  0  1  0  0 #> 10: 46.97551 66.72547  2.012081773  1.38772433 -1.04115630 T1  1  0  1  0 #> 11: 73.04213 59.38154  1.094629842  0.19307964 -0.32922472 T2  1  0  1  1 #> 12: 49.79986 64.66951  0.726409354  0.59231662 -0.28282162 T1  1  0  0  0 #> 13: 62.59822 60.09748 -1.399657137 -0.82997453  0.43242913 T1  0  1  0  0 #> 14: 57.60843 64.15426 -1.287795163  0.39257328 -0.30760710 T1  1  1  0  1 #> 15: 71.90249 58.47753 -0.968415478  0.38486761 -0.05663631 T2  0  0  0  0 #> 16: 85.41526 59.70359 -1.736685758  1.05104467  0.73351542 T1  0  0  0  0 #> 17: 78.59953 65.03698  0.831697358  1.15579748  0.09731162 T1  1  0  0  1 #> 18: 60.44155 53.11102 -0.758953109 -1.03443796  1.63089174 T2  0  1  0  0 #> 19: 84.85822 54.97899  2.155077001 -0.25446807  0.56061070 T0  0  1  1  0 #> 20: 76.96835 59.88360 -0.423258880  1.27368427  1.32956476 T1  0  0  0  0 #> 21: 38.96384 67.73374 -0.005649937  1.50254464 -0.27882350 T2  0  0  1  0 #> 22: 62.35156 56.20318  0.400361729  0.59040947 -1.26673154 T2  0  0  0  1 #> 23: 73.01263 65.03396 -0.365677802 -0.63068545 -0.24914839 T1  0  1  0  1 #> 24: 59.50147 61.37107 -0.429143835  0.79234954  0.01798841 T2  0  0  0  1 #> 25: 74.31097 59.59809  0.244697127  0.12538457  0.37707273 T2  1  1  1  0 #> 26: 76.95145 55.48224  2.219776249  0.32275497  0.79600856 T2  0  0  0  1 #> 27: 65.90546 62.36573  0.314269808 -0.44558321 -0.84067742 T1  0  1  1  0 #> 28: 65.65212 66.94244 -0.563785075  0.76684393 -2.20547175 T0  0  0  1  1 #> 29: 56.22386 60.17373 -1.485696158 -1.40350302 -1.12805599 T1  0  1  1  1 #> 30: 67.56142 53.53707  0.415298593 -1.17604678 -1.34130996 T2  1  1  0  0 #> 31: 40.05295 65.81984 -0.528063683  0.51159647  1.60511404 T2  0  0  0  0 #> 32: 58.22551 52.38308 -0.350470617  1.31676526  0.74442373 T2  0  0  1  0 #> 33: 50.50127 47.40832  0.730621937  2.39291295  0.86208221 T0  0  0  1  0 #> 34: 70.16537 56.46235 -0.556624165 -0.06776941  0.39515582 T1  0  0  1  0 #> 35: 55.53177 58.56284 -1.449760536 -0.20378507  0.50911870 T1  1  0  1  1 #> 36: 69.41883 57.82346 -1.051996428  1.99643445 -0.12255013 T2  0  1  0  1 #> 37: 85.17646 58.28461 -0.682838619  1.54321779  0.09258465 T2  0  0  0  1 #> 38: 23.99996 59.80345 -0.612941179 -1.22833763 -0.35787991 T2  0  1  0  0 #> 39: 39.75236 64.43483  1.890780035  2.64448799 -0.35965522 T2  0  1  0  1 #> 40: 78.03012 58.20026 -0.145410534  0.75701371  1.02857072 T2  0  1  0  0 #> 41: 79.40764 56.35523 -0.639423721  1.05534519  1.07789259 T2  0  0  0  1 #> 42: 59.10608 68.75873 -0.411176045  0.95794490  0.93178122 T0  0  1  0  1 #> 43: 49.72406 59.56981  0.342791878  0.83387906 -1.46079387 T1  0  0  0  0 #> 44: 38.19841 65.53182 -1.133246755 -0.16927557 -0.90607558 T1  1  0  0  1 #> 45: 79.41190 59.90411  0.066070303 -0.40443364 -0.68034783 T2  0  0  0  1 #> 46: 77.64254 52.53270  0.037999766  0.29560157  1.06316604 T0  0  1  1  1 #> 47: 72.96068 73.50318  0.921064748 -0.23187451 -0.69241315 T0  0  0  1  0 #> 48: 25.54901 56.28153  2.134965638 -0.44807823 -1.13362827 T1  0  0  1  1 #> 49: 39.12285 65.32597 -0.599826932  0.02231080 -1.09461543 T1  0  0  1  1 #> 50: 39.21185 59.83959  1.244446459  0.04446730 -1.01290362 T2  1  1  0  1 #> 51: 43.90430 57.30020 -0.079457017  0.48072117  0.41027733 T1  0  1  0  0 #> 52: 45.87862 50.37178  1.181751550  0.63561986  0.47774044 T1  0  0  0  0 #> 53: 51.20349 65.03916  2.186144063 -2.00074239 -2.32987955 T1  1  1  0  0 #> 54: 75.52082 58.60383  0.406174931 -0.69065550  0.01625547 T2  0  0  0  1 #> 55: 66.88443 53.75217 -0.738359105 -0.13064519  0.98035352 T2  0  0  1  0 #> 56: 42.09832 66.24246 -1.956486703 -0.34425178  0.80634826 T2  0  0  0  0 #> 57: 71.87834 59.03893 -1.950045702 -0.05241282  0.11960089 T1  0  0  0  1 #> 58: 33.41543 64.55988 -0.940997816  0.09612392 -2.43661560 T2  0  0  0  0 #> 59: 51.18416 49.20865  1.197786769  0.26640705  0.03102248 T1  0  0  1  1 #> 60: 40.76445 66.44805 -0.624239390  0.55479348 -0.33574670 T1  1  1  1  1 #> 61: 55.31798 57.85945 -0.132869655  1.23544588 -0.26377616 T0  0  0  0  1 #> 62: 49.51837 58.72499 -0.017220922  0.28513338 -0.35585246 T1  0  1  0  0 #> 63: 20.34225 66.63579 -0.459629282 -0.45879293 -0.48115480 T1  0  0  1  1 #> 64: 72.37534 64.19345  1.472936791  0.62347802  0.22273547 T2  0  0  1  0 #> 65: 64.60389 52.67500  2.169319613 -0.72399509  2.42991032 T2  0  1  0  0 #> 66: 59.12941 56.91874 -3.001431306  1.61941870  1.49629812 T0  0  1  1  0 #> 67: 73.89854 60.53053 -1.771985583 -0.61667341 -0.71720820 T1  1  1  1  1 #> 68: 56.71962 50.77992 -0.364839223  0.38454106 -0.46705390 T1  1  1  1  1 #> 69: 74.89700 51.91789  0.374533781  2.11452131  0.66292345 T1  0  1  0  0 #> 70: 31.14998 61.13838 -1.234077927 -1.02856737  2.30017689 T2  1  0  1  1 #>           X6       X7           X8          X9         X10 X1 X2 X3 X4 X5 #>      eventtime  censtime       time event #>  1:  9.4184480  8.235906  8.2359063     0 #>  2:  5.4761627 10.870427  5.4761627     1 #>  3:  1.0323078  9.225982  1.0323078     1 #>  4: 19.4574401  6.054568  6.0545684     0 #>  5:  0.5112391 15.695559  0.5112391     1 #>  6:  3.3054768 12.205393  3.3054768     1 #>  7:  1.2161130 11.369665  1.2161130     1 #>  8:  8.9251320 11.405403  8.9251320     1 #>  9: 21.4591920  6.962654  6.9626536     0 #> 10: 23.4557337  9.190943  9.1909426     0 #> 11:  3.2179073  6.543997  3.2179073     1 #> 12: 25.1049438  7.523933  7.5239329     0 #> 13:  1.9147684 14.750842  1.9147684     1 #> 14: 30.2969350  7.194720  7.1947199     0 #> 15:  8.3233198 10.134509  8.3233198     1 #> 16:  6.2367495  9.201862  6.2367495     1 #> 17:  4.9619976 17.199920  4.9619976     1 #> 18:  4.0581326 11.537476  4.0581326     1 #> 19:  0.4985251  9.588110  0.4985251     1 #> 20:  1.7957700  4.230440  1.7957700     1 #> 21: 14.4476473  3.812455  3.8124547     0 #> 22:  3.7826564  6.968215  3.7826564     1 #> 23:  1.1642427  5.047281  1.1642427     1 #> 24:  1.3077129 10.168760  1.3077129     1 #> 25:  1.4479584  9.496166  1.4479584     1 #> 26:  2.7435111  5.892573  2.7435111     1 #> 27:  3.6877980  4.199928  3.6877980     1 #> 28:  8.5142430 11.953367  8.5142430     1 #> 29: 10.9359909  5.102580  5.1025805     0 #> 30:  1.1212223 10.164211  1.1212223     1 #> 31: 46.1189084  7.901729  7.9017289     0 #> 32:  8.6184778 15.408467  8.6184778     1 #> 33:  9.8688062 13.315841  9.8688062     1 #> 34:  7.3795769  3.248795  3.2487951     0 #> 35: 20.8801838  9.280303  9.2803027     0 #> 36: 20.5985926  5.391580  5.3915796     0 #> 37:  8.1520810  4.418386  4.4183855     0 #> 38: 27.5982200  2.154221  2.1542209     0 #> 39: 13.3874120  6.145630  6.1456304     0 #> 40:  4.5201609  8.319503  4.5201609     1 #> 41:  9.1908871 11.354410  9.1908871     1 #> 42: 31.0394522 12.142705 12.1427049     0 #> 43: 23.7193811 20.586829 20.5868289     0 #> 44: 51.2726204  5.622545  5.6225453     0 #> 45:  5.1087674 11.776131  5.1087674     1 #> 46:  4.8693016 13.510045  4.8693016     1 #> 47:  7.0570522 20.179287  7.0570522     1 #> 48:  5.1575500  8.493175  5.1575500     1 #> 49: 49.1905410 15.079774 15.0797744     0 #> 50:  7.2212702  4.703314  4.7033144     0 #> 51: 11.2465692 10.185932 10.1859318     0 #> 52: 26.2233288  2.562768  2.5627679     0 #> 53:  4.0968780 11.844691  4.0968780     1 #> 54:  2.0576730  8.650785  2.0576730     1 #> 55:  2.3751796 12.855153  2.3751796     1 #> 56:  8.8761931  7.342938  7.3429383     0 #> 57:  3.6109236  8.818587  3.6109236     1 #> 58: 35.8238897  8.720648  8.7206480     0 #> 59:  6.7798993  9.574494  6.7798993     1 #> 60: 56.7600799  8.262151  8.2621515     0 #> 61: 22.1808138 18.562114 18.5621136     0 #> 62: 16.7422707 14.722308 14.7223081     0 #> 63: 82.9200663  8.702242  8.7022417     0 #> 64:  7.2858216  9.611724  7.2858216     1 #> 65:  1.2857034  4.265895  1.2857034     1 #> 66: 41.9847051  5.224576  5.2245761     0 #> 67:  3.5260250  7.458201  3.5260250     1 #> 68:  6.7892548  8.966944  6.7892548     1 #> 69:  0.9575123 15.745788  0.9575123     1 #> 70: 15.9073575 12.320922 12.3209217     0 #>      eventtime  censtime       time event ## table(d$X1)  #### stratified Cox model #### fit <- coxph(Surv(time,event)~X1 + strata(X2) + X6,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  #### average treatment effect #### fit.ate <- ate(fit, treatment = \"X1\", times = 1:3, data = d,                se = TRUE, iid = TRUE, band = TRUE) #>  Input variables  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, censoring: 0) #>  - Time  [min;max]      : time [0.499;20.6] #>  - Eval. time           :  1  2  3 #>       number at risk T0   10 10 10 #>       number at risk T1   29 24 23 #>       number at risk T2   28 24 20 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Processing #>  - Prepare influence function: outcome done  #>  - Point estimation: done  #>  - Decomposition iid: done #>  - Confidence intervals / bands: done summary(fit.ate) #>      Average treatment effect  #>  #>  - Treatment            : X1 (3 levels: \"T0\" \"T1\" \"T2\") #>  - Event                : event (cause: 1, censoring: 0) #>  - Time  [min;max]      : time [0.499;20.6] #>  - Eval. time           :  1  2  3 #>       number at risk T0   10 10 10 #>       number at risk T1   29 24 23 #>       number at risk T2   28 24 20 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Testing procedure #>  - Null hypothesis     : given two treatments (A,B), equal risks at all timepoints  #>  - Confidence level    : 0.95 #>  - Multiple comparisons: single-step max-T adjustment computed using 10000 simulations #>  #>  Results:  #>  - Difference in standardized risk (B-A) between time zero and 'time'  #>                 reported on the scale [-1;1] (difference between two probabilities) #>  (difference in average risks when treating all subjects with the experimental treatment (B), #>                                 vs. treating all subjects with the reference treatment (A)) #>  #>  time X1=A risk(X1=A) X1=B risk(X1=B) difference           ci p.value #>     1   T0     0.0339   T1     0.0472    0.01332 [-0.02;0.05]   0.411 #>     2   T0     0.1352   T1     0.1826    0.04739 [-0.07;0.17]   0.431 #>     3   T0     0.1703   T1     0.2267    0.05642 [-0.08;0.20]   0.432 #>     1   T0     0.0339   T2     0.0420    0.00815 [-0.02;0.03]   0.506 #>     2   T0     0.1352   T2     0.1645    0.02933 [-0.07;0.12]   0.545 #>     3   T0     0.1703   T2     0.2054    0.03511 [-0.08;0.15]   0.551 #>     1   T1     0.0472   T2     0.0420   -0.00518 [-0.04;0.03]   0.764 #>     2   T1     0.1826   T2     0.1645   -0.01806 [-0.13;0.10]   0.759 #>     3   T1     0.2267   T2     0.2054   -0.02131 [-0.16;0.11]   0.758 #>  simultaneous ci adjusted p.value #>     [-0.02;0.05]            0.504 #>     [-0.08;0.18]            0.525 #>     [-0.10;0.21]            0.526 #>     [-0.02;0.03]            0.590 #>     [-0.07;0.13]            0.630 #>     [-0.09;0.16]            0.636 #>     [-0.04;0.03]            0.811 #>     [-0.14;0.10]            0.806 #>     [-0.16;0.12]            0.805 #>  #>  difference      : estimated difference in standardized risks  #>  ci              : pointwise confidence intervals  #>  p.value         : (unadjusted) p-value  #>  simultaneous ci : simulatenous confidence intervals over time #>  adjusted p.value: p-value adjusted for multiple comparisons over time dt.ate <- as.data.table(fit.ate)  ## manual calculation of se dd <- copy(d) dd$X1 <- rep(factor(\"T0\", levels = paste0(\"T\",0:2)), NROW(dd)) out <- predictCox(fit, newdata = dd, se = TRUE, times = 1:3, average.iid = TRUE) term1 <- -out$survival.average.iid term2 <- sweep(1-out$survival, MARGIN = 2, FUN = \"-\", STATS = colMeans(1-out$survival)) sqrt(colSums((term1 + term2/NROW(d))^2))  #> [1] 0.02557002 0.05576405 0.06256730 ## fit.ate$meanRisk[treatment==\"T0\",se]  ## note out2 <- predictCox(fit, newdata = dd, se = TRUE, times = 1:3, iid = TRUE) mean(out2$survival.iid[1,1,]) #> [1] -0.0003529296 out$survival.average.iid[1,1] #> [1] -0.0003529296  ## check confidence intervals (no transformation) dt.ate[,.(lower = pmax(0,estimate + qnorm(0.025) * se),           lower2 = lower,           upper = estimate + qnorm(0.975) * se,           upper2 = upper)] #>          lower      lower2      upper     upper2 #>  1: 0.00000000  0.00000000 0.08401352 0.08401352 #>  2: 0.02590437  0.02590437 0.24449544 0.24449544 #>  3: 0.04767637  0.04767637 0.29293567 0.29293567 #>  4: 0.00000000  0.00000000 0.10199266 0.10199266 #>  5: 0.06587254  0.06587254 0.29931345 0.29931345 #>  6: 0.09787653  0.09787653 0.35557496 0.35557496 #>  7: 0.00000000  0.00000000 0.08763162 0.08763162 #>  8: 0.07373281  0.07373281 0.25532659 0.25532659 #>  9: 0.10169224  0.10169224 0.30914481 0.30914481 #> 10: 0.00000000 -0.01843023 0.04508014 0.04508014 #> 11: 0.00000000 -0.07044632 0.16523250 0.16523250 #> 12: 0.00000000 -0.08418721 0.19702666 0.19702666 #> 13: 0.00000000 -0.01583434 0.03212551 0.03212551 #> 14: 0.00000000 -0.06563720 0.12429679 0.12429679 #> 15: 0.00000000 -0.08028787 0.15051289 0.15051289 #> 16: 0.00000000 -0.03892565 0.02856692 0.02856692 #> 17: 0.00000000 -0.13355386 0.09742727 0.09742727 #> 18: 0.00000000 -0.15680088 0.11418644 0.11418644 #> 19: 0.21268856  0.21268856 2.57350940 2.57350940 #> 20: 0.31415598  0.31415598 2.38692575 2.38692575 #> 21: 0.35840663  0.35840663 2.30416217 2.30416217 #> 22: 0.32511683  0.32511683 2.15548849 2.15548849 #> 23: 0.39528481  0.39528481 2.03858823 2.03858823 #> 24: 0.42753998  0.42753998 1.98480606 1.98480606 #> 25: 0.23798475  0.23798475 1.54265349 1.54265349 #> 26: 0.31071769  0.31071769 1.49142922 1.49142922 #> 27: 0.34410983  0.34410983 1.46793427 1.46793427 #>          lower      lower2      upper     upper2  ## add confidence intervals computed on the log-log scale ## and backtransformed outCI <- confint(fit.ate,                  meanRisk.transform = \"loglog\", diffRisk.transform = \"atanh\",                  ratioRisk.transform = \"log\") summary(outCI, type = \"risk\", short = TRUE) #>                        Length Class      Mode      #> meanRisk               10     data.table list      #> diffRisk               15     data.table list      #> ratioRisk              15     data.table list      #> inference              12     data.frame list      #> inference.allContrasts  6     -none-     character #> inference.contrasts     3     -none-     character #> transform               3     -none-     character  dt.ate[type == \"meanRisk\", newse := se/(estimate*log(estimate))] #>          type estimator time level     estimate         se       lower #>  1:  meanRisk  GFORMULA    1    T0  0.033897209 0.02557002  0.00000000 #>  2:  meanRisk  GFORMULA    2    T0  0.135199903 0.05576405  0.02590437 #>  3:  meanRisk  GFORMULA    3    T0  0.170306018 0.06256730  0.04767637 #>  4:  meanRisk  GFORMULA    1    T1  0.047222167 0.02794464  0.00000000 #>  5:  meanRisk  GFORMULA    2    T1  0.182592994 0.05955234  0.06587254 #>  6:  meanRisk  GFORMULA    3    T1  0.226725745 0.06574061  0.09787653 #>  7:  meanRisk  GFORMULA    1    T2  0.042042798 0.02326003  0.00000000 #>  8:  meanRisk  GFORMULA    2    T2  0.164529699 0.04632579  0.07373281 #>  9:  meanRisk  GFORMULA    3    T2  0.205418524 0.05292254  0.10169224 #> 10:  diffRisk  GFORMULA    1 T0.T1  0.013324958 0.01620192 -0.01843023 #> 11:  diffRisk  GFORMULA    2 T0.T1  0.047393091 0.06012325 -0.07044632 #> 12:  diffRisk  GFORMULA    3 T0.T1  0.056419727 0.07173955 -0.08418721 #> 13:  diffRisk  GFORMULA    1 T0.T2  0.008145589 0.01223488 -0.01583434 #> 14:  diffRisk  GFORMULA    2 T0.T2  0.029329797 0.04845344 -0.06563720 #> 15:  diffRisk  GFORMULA    3 T0.T2  0.035112506 0.05887883 -0.08028787 #> 16:  diffRisk  GFORMULA    1 T1.T2 -0.005179369 0.01721781 -0.03892565 #> 17:  diffRisk  GFORMULA    2 T1.T2 -0.018063295 0.05892484 -0.13355386 #> 18:  diffRisk  GFORMULA    3 T1.T2 -0.021307221 0.06913069 -0.15680088 #> 19: ratioRisk  GFORMULA    1 T0.T1  1.393098981 0.60226128  0.21268856 #> 20: ratioRisk  GFORMULA    2 T0.T1  1.350540868 0.52877752  0.31415598 #> 21: ratioRisk  GFORMULA    3 T0.T1  1.331284402 0.49637533  0.35840663 #> 22: ratioRisk  GFORMULA    1 T0.T2  1.240302659 0.46694013  0.32511683 #> 23: ratioRisk  GFORMULA    2 T0.T2  1.216936521 0.41921776  0.39528481 #> 24: ratioRisk  GFORMULA    3 T0.T2  1.206173022 0.39726905  0.42753998 #> 25: ratioRisk  GFORMULA    1 T1.T2  0.890319121 0.33282978  0.23798475 #> 26: ratioRisk  GFORMULA    2 T1.T2  0.901073451 0.30120746  0.31071769 #> 27: ratioRisk  GFORMULA    3 T1.T2  0.906022049 0.28669518  0.34410983 #>          type estimator time level     estimate         se       lower #>          upper quantileBand   lowerBand  upperBand   p.value adj.p.value #>  1: 0.08401352     2.200264  0.00000000 0.09015800        NA          NA #>  2: 0.24449544     2.200264  0.01250425 0.25789556        NA          NA #>  3: 0.29293567     2.200264  0.03264143 0.30797061        NA          NA #>  4: 0.10199266     2.273745  0.00000000 0.11076116        NA          NA #>  5: 0.29931345     2.273745  0.04718615 0.31799984        NA          NA #>  6: 0.35557496     2.273745  0.07724837 0.37620312        NA          NA #>  7: 0.08763162     2.314972  0.00000000 0.09588910        NA          NA #>  8: 0.25532659     2.314972  0.05728680 0.27177260        NA          NA #>  9: 0.30914481     2.314972  0.08290433 0.32793271        NA          NA #> 10: 0.04508014     2.134070 -0.02125108 0.04790099 0.4108318      0.5042 #> 11: 0.16523250     2.134070 -0.08091413 0.17570032 0.4305414      0.5251 #> 12: 0.19702666     2.134070 -0.09667749 0.20951695 0.4316026      0.5258 #> 13: 0.03212551     2.089872 -0.01742375 0.03371492 0.5055595      0.5898 #> 14: 0.12429679     2.089872 -0.07193169 0.13059129 0.5449669      0.6296 #> 15: 0.15051289     2.089872 -0.08793671 0.15816172 0.5509401      0.6359 #> 16: 0.02856692     2.039855 -0.04030120 0.02994247 0.7635559      0.8107 #> 17: 0.09742727     2.039855 -0.13826142 0.10213483 0.7591874      0.8062 #> 18: 0.11418644     2.039855 -0.16232380 0.11970936 0.7579176      0.8050 #> 19: 2.57350940     1.989982  0.19460974 2.59158822 0.5139464      0.5270 #> 20: 2.38692575     1.989982  0.29828302 2.40279872 0.5073773      0.5204 #> 21: 2.30416217     1.989982  0.34350632 2.31906248 0.5045122      0.5167 #> 22: 2.15548849     1.986203  0.31286476 2.16774056 0.6068097      0.6111 #> 23: 2.03858823     1.986203  0.38428493 2.04958811 0.6048216      0.6097 #> 24: 1.98480606     1.986203  0.41711602 1.99523003 0.6037776      0.6083 #> 25: 1.54265349     1.928798  0.24835759 1.53228066 0.7417472      0.7423 #> 26: 1.49142922     1.928798  0.32010500 1.48204191 0.7425841      0.7434 #> 27: 1.46793427     1.928798  0.35304486 1.45899924 0.7430648      0.7442 #>          upper quantileBand   lowerBand  upperBand   p.value adj.p.value #>          newse #>  1: -0.2228858 #>  2: -0.2061250 #>  3: -0.2075417 #>  4: -0.1938390 #>  5: -0.1917959 #>  6: -0.1953866 #>  7: -0.1745771 #>  8: -0.1560207 #>  9: -0.1627800 #> 10:         NA #> 11:         NA #> 12:         NA #> 13:         NA #> 14:         NA #> 15:         NA #> 16:         NA #> 17:         NA #> 18:         NA #> 19:         NA #> 20:         NA #> 21:         NA #> 22:         NA #> 23:         NA #> 24:         NA #> 25:         NA #> 26:         NA #> 27:         NA #>          newse dt.ate[type == \"meanRisk\", .(lower = exp(-exp(log(-log(estimate)) - 1.96 * newse)),                         upper = exp(-exp(log(-log(estimate)) + 1.96 * newse)))] #>          lower     upper #> 1: 0.005308092 0.1123030 #> 2: 0.049930563 0.2629084 #> 3: 0.070036723 0.3077237 #> 4: 0.011517821 0.1239456 #> 5: 0.084038215 0.3110947 #> 6: 0.113440244 0.3635412 #> 7: 0.011538684 0.1053196 #> 8: 0.086275187 0.2646901 #> 9: 0.113322713 0.3165183"},{"path":"/reference/confint.influenceTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","title":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","text":"Confidence intervals confidence Bands difference two estimates.","code":""},{"path":"/reference/confint.influenceTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","text":"","code":"# S3 method for influenceTest confint(   object,   parm = NULL,   level = 0.95,   n.sim = 10000,   transform = \"none\",   seed = NA,   ... )"},{"path":"/reference/confint.influenceTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","text":"object influenceTest object, .e. output influenceTest function. parm used. compatibility generic method. level [numeric, 0-1] Level confidence. n.sim [integer, >0] number simulations used compute quantiles confidence bands. transform [character] transformation used improve coverage confidence intervals. Can \"none\" \"atanh\". seed [integer, >0] seed number set performing simulations confidence bands. given NA seed set. ... used.","code":""},{"path":"/reference/confint.influenceTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","text":"Except cumulative hazard, confidence bands confidence intervals automatically restricted interval [-1;1].","code":""},{"path":"/reference/confint.influenceTest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals and Confidence Bands for the Difference Between Two Estimates — confint.influenceTest","text":"Brice Ozenne","code":""},{"path":"/reference/confint.predictCSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"Confidence intervals confidence Bands predicted absolute risk (cumulative incidence function).","code":""},{"path":"/reference/confint.predictCSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"","code":"# S3 method for predictCSC confint(   object,   parm = NULL,   level = 0.95,   n.sim = 10000,   absRisk.transform = \"loglog\",   seed = NA,   ... )"},{"path":"/reference/confint.predictCSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"object predictCSC object, .e. output predictCSC function. parm used. compatibility generic method. level [numeric, 0-1] Level confidence. n.sim [integer, >0] number simulations used compute quantiles confidence bands. absRisk.transform [character] transformation used improve coverage confidence intervals predicted absolute risk small samples. Can \"none\", \"log\", \"loglog\", \"cloglog\". seed [integer, >0] seed number set performing simulations confidence bands. given NA seed set. ... used.","code":""},{"path":"/reference/confint.predictCSC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"confidence bands confidence intervals automatically restricted interval [0;1].","code":""},{"path":"/reference/confint.predictCSC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"Brice Ozenne","code":""},{"path":"/reference/confint.predictCSC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals and Confidence Bands for the Predicted Absolute Risk (Cumulative Incidence Function) — confint.predictCSC","text":"","code":"library(survival) library(prodlim) #### generate data #### set.seed(10) d <- sampleData(100)   #### estimate a stratified CSC model ### fit <- CSC(Hist(time,event)~ X1 + strata(X2) + X6, data=d)  #### compute individual specific risks fit.pred <- predict(fit, newdata=d[1:3], times=c(3,8), cause = 1,                     se = TRUE, iid = TRUE, band = TRUE) fit.pred #>    observation X1   X6 X2 times strata absRisk absRisk.se absRisk.lower #> 1:           1  1 30.8  1     3   X2=1   0.138     0.0785        0.0311 #> 2:           2  0 66.3  1     3   X2=1   0.456     0.1247        0.2114 #> 3:           3  0 77.6  1     3   X2=1   0.799     0.1285        0.4007 #> 4:           1  1 30.8  1     8   X2=1   0.298     0.1365        0.0788 #> 5:           2  0 66.3  1     8   X2=1   0.803     0.0900        0.5503 #> 6:           3  0 77.6  1     8   X2=1   0.954     0.0659        0.4310 #>    absRisk.upper absRisk.quantileBand absRisk.lowerBand absRisk.upperBand #> 1:         0.324                 2.15            0.0255             0.344 #> 2:         0.673                 2.21            0.1832             0.695 #> 3:         0.946                 2.15            0.3498             0.953 #> 4:         0.562                 2.15            0.0649             0.585 #> 5:         0.923                 2.21            0.5067             0.932 #> 6:         0.997                 2.15            0.3266             0.998  ## check confidence intervals newse <- fit.pred$absRisk.se/(-fit.pred$absRisk*log(fit.pred$absRisk)) cbind(lower = as.double(exp(-exp(log(-log(fit.pred$absRisk)) + 1.96 * newse))),       upper = as.double(exp(-exp(log(-log(fit.pred$absRisk)) - 1.96 * newse))) ) #>           lower     upper #> [1,] 0.03106980 0.3237727 #> [2,] 0.21142317 0.6725332 #> [3,] 0.40068902 0.9463311 #> [4,] 0.07874874 0.5616676 #> [5,] 0.55031414 0.9226697 #> [6,] 0.43098190 0.9973992  #### compute confidence intervals without transformation confint(fit.pred, absRisk.transform = \"none\") #>    observation X1   X6 X2 times strata absRisk absRisk.se absRisk.lower #> 1:           1  1 30.8  1     3   X2=1   0.138     0.0785        0.0000 #> 2:           2  0 66.3  1     3   X2=1   0.456     0.1247        0.2116 #> 3:           3  0 77.6  1     3   X2=1   0.799     0.1285        0.5469 #> 4:           1  1 30.8  1     8   X2=1   0.298     0.1365        0.0305 #> 5:           2  0 66.3  1     8   X2=1   0.803     0.0900        0.6267 #> 6:           3  0 77.6  1     8   X2=1   0.954     0.0659        0.8252 #>    absRisk.upper absRisk.quantileBand absRisk.lowerBand absRisk.upperBand #> 1:         0.292                 2.14           0.00000             0.306 #> 2:         0.700                 2.23           0.17842             0.734 #> 3:         1.000                 2.17           0.51970             1.000 #> 4:         0.565                 2.14           0.00656             0.589 #> 5:         0.980                 2.23           0.60269             1.000 #> 6:         1.000                 2.17           0.81125             1.000 cbind(lower = as.double(fit.pred$absRisk - 1.96 * fit.pred$absRisk.se),       upper = as.double(fit.pred$absRisk + 1.96 * fit.pred$absRisk.se) ) #>            lower     upper #> [1,] -0.01553676 0.2920606 #> [2,]  0.21161883 0.7004983 #> [3,]  0.54689863 1.0507549 #> [4,]  0.03045984 0.5654551 #> [5,]  0.62665840 0.9795842 #> [6,]  0.82518445 1.0833380"},{"path":"/reference/confint.predictCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"Confidence intervals confidence Bands predicted survival/cumulative Hazard.","code":""},{"path":"/reference/confint.predictCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"","code":"# S3 method for predictCox confint(   object,   parm = NULL,   level = 0.95,   n.sim = 10000,   cumhazard.transform = \"log\",   survival.transform = \"loglog\",   seed = NA,   ... )"},{"path":"/reference/confint.predictCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"object predictCox object, .e. output predictCox function. parm [character] type predicted value confidence intervals output. Can \"survival\" \"cumhazard\". level [numeric, 0-1] Level confidence. n.sim [integer, >0] number simulations used compute quantiles confidence bands. cumhazard.transform [character] transformation used improve coverage confidence intervals cumlative hazard small samples. Can \"none\", \"log\". survival.transform [character] transformation used improve coverage confidence intervals survival small samples. Can \"none\", \"log\", \"loglog\", \"cloglog\". seed [integer, >0] seed number set performing simulations confidence bands. given NA seed set. ... used.","code":""},{"path":"/reference/confint.predictCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"confidence bands confidence intervals automatically restricted interval definition statistic, .e. confidence interval survival [0.5;1.2] become [0.5;1].","code":""},{"path":"/reference/confint.predictCox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"Brice Ozenne","code":""},{"path":"/reference/confint.predictCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence Intervals and Confidence Bands for the predicted Survival/Cumulative Hazard — confint.predictCox","text":"","code":"library(survival)  #### generate data #### set.seed(10) d <- sampleData(40,outcome=\"survival\")   #### estimate a stratified Cox model #### fit <- coxph(Surv(time,event)~X1 + strata(X2) + X6,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  #### compute individual specific survival probabilities   fit.pred <- predictCox(fit, newdata=d[1:3], times=c(3,8), type = \"survival\",                        se = TRUE, iid = TRUE, band = TRUE) fit.pred #>    observation strata times survival survival.se survival.lower survival.upper #> 1:           1      0     3    0.830      0.0598          0.672          0.917 #> 2:           2      0     3    0.878      0.0510          0.732          0.947 #> 3:           3      0     3    0.975      0.0194          0.888          0.995 #> 4:           1      0     8    0.441      0.1062          0.233          0.631 #> 5:           2      0     8    0.564      0.1131          0.320          0.750 #> 6:           3      0     8    0.894      0.0692          0.648          0.972 #>    survival.quantileBand survival.lowerBand survival.upperBand #> 1:                  2.24              0.642              0.925 #> 2:                  2.22              0.704              0.953 #> 3:                  2.13              0.873              0.995 #> 4:                  2.24              0.205              0.654 #> 5:                  2.22              0.287              0.769 #> 6:                  2.13              0.613              0.975  ## check standard error sqrt(rowSums(fit.pred$survival.iid[,,1]^2)) ## se for individual 1 #>  [1] 0.018392578 0.016237776 0.007431816 0.012893439 0.025032667 0.005398069 #>  [7] 0.025666528 0.005026215 0.020439989 0.013954960 0.020245964 0.012961149 #> [13] 0.010320665 0.022387257 0.003809652 0.037842644 0.013409129 0.010237400 #> [19] 0.017079206 0.014556417 0.004868714 0.013372745 0.051035469 0.019664220 #> [25] 0.023187719 0.013702212 0.001694092 0.020826096 0.002277766 0.060597775 #> [31] 0.015962232 0.011798179 0.008106319 0.004469016 0.004496629 0.002184175 #> [37] 0.007678302 0.000496456 0.002440726 0.008088248  ## check confidence interval newse <- fit.pred$survival.se/(-fit.pred$survival*log(fit.pred$survival)) cbind(lower = as.double(exp(-exp(log(-log(fit.pred$survival)) + 1.96 * newse))),       upper = as.double(exp(-exp(log(-log(fit.pred$survival)) - 1.96 * newse))) ) #>          lower     upper #> [1,] 0.6720145 0.9166403 #> [2,] 0.7317857 0.9473215 #> [3,] 0.8882076 0.9945995 #> [4,] 0.2325654 0.6310395 #> [5,] 0.3204751 0.7495790 #> [6,] 0.6477553 0.9717133  #### compute confidence intervals without transformation confint(fit.pred, survival.transform = \"none\") #>    observation strata times survival survival.se survival.lower survival.upper #> 1:           1      0     3    0.830      0.0598          0.713          0.948 #> 2:           2      0     3    0.878      0.0510          0.778          0.978 #> 3:           3      0     3    0.975      0.0194          0.937          1.000 #> 4:           1      0     8    0.441      0.1062          0.232          0.649 #> 5:           2      0     8    0.564      0.1131          0.342          0.786 #> 6:           3      0     8    0.894      0.0692          0.759          1.000 #>    survival.quantileBand survival.lowerBand survival.upperBand #> 1:                  2.24              0.697              0.964 #> 2:                  2.20              0.766              0.991 #> 3:                  2.10              0.934              1.000 #> 4:                  2.24              0.203              0.678 #> 5:                  2.20              0.315              0.813 #> 6:                  2.10              0.749              1.000 cbind(lower = as.double(fit.pred$survival - 1.96 * fit.pred$survival.se),       upper = as.double(fit.pred$survival + 1.96 * fit.pred$survival.se) ) #>          lower     upper #> [1,] 0.7130004 0.9475453 #> [2,] 0.7780635 0.9781347 #> [3,] 0.9368629 1.0130999 #> [4,] 0.2324617 0.6488784 #> [5,] 0.3422163 0.7857635 #> [6,] 0.7587567 1.0300007"},{"path":"/reference/coxBaseEstimator.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the type of estimator for the baseline hazard — coxBaseEstimator","title":"Extract the type of estimator for the baseline hazard — coxBaseEstimator","text":"Extract type estimator baseline hazard","code":""},{"path":"/reference/coxBaseEstimator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the type of estimator for the baseline hazard — coxBaseEstimator","text":"","code":"coxBaseEstimator(object)  # S3 method for coxph coxBaseEstimator(object)  # S3 method for phreg coxBaseEstimator(object)"},{"path":"/reference/coxBaseEstimator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the type of estimator for the baseline hazard — coxBaseEstimator","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxBaseEstimator.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the type of estimator for the baseline hazard — coxBaseEstimator","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxCenter.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the mean value of the covariates — coxCenter","title":"Extract the mean value of the covariates — coxCenter","text":"Extract mean value covariates","code":""},{"path":"/reference/coxCenter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the mean value of the covariates — coxCenter","text":"","code":"coxCenter(object)  # S3 method for cph coxCenter(object)  # S3 method for coxph coxCenter(object)  # S3 method for phreg coxCenter(object)"},{"path":"/reference/coxCenter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the mean value of the covariates — coxCenter","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxCenter.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the mean value of the covariates — coxCenter","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxFormula.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the formula from a Cox model — coxFormula","title":"Extract the formula from a Cox model — coxFormula","text":"Extract formula Cox model","code":""},{"path":"/reference/coxFormula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the formula from a Cox model — coxFormula","text":"","code":"coxFormula(object)  # S3 method for cph coxFormula(object)  # S3 method for coxph coxFormula(object)  # S3 method for phreg coxFormula(object)  # S3 method for glm coxFormula(object)"},{"path":"/reference/coxFormula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the formula from a Cox model — coxFormula","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxFormula.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the formula from a Cox model — coxFormula","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxLP.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the linear predictor of a Cox model — coxLP","title":"Compute the linear predictor of a Cox model — coxLP","text":"Compute linear predictor Cox model","code":""},{"path":"/reference/coxLP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the linear predictor of a Cox model — coxLP","text":"","code":"coxLP(object, data, center)  # S3 method for cph coxLP(object, data, center)  # S3 method for coxph coxLP(object, data, center)  # S3 method for phreg coxLP(object, data, center)"},{"path":"/reference/coxLP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the linear predictor of a Cox model — coxLP","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package). data data.frame data.table center linear predictor computed centering covariates","code":""},{"path":"/reference/coxLP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the linear predictor of a Cox model — coxLP","text":"case empty linear predictor returns vector 0 length number rows dataset","code":""},{"path":"/reference/coxLP.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the linear predictor of a Cox model — coxLP","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxModelFrame.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the design matrix used to train a Cox model — coxModelFrame","title":"Extract the design matrix used to train a Cox model — coxModelFrame","text":"Extract design matrix used train Cox model. contain time event, type event,  variable linear predictor, strata variables date entry (case delayed entry).","code":""},{"path":"/reference/coxModelFrame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the design matrix used to train a Cox model — coxModelFrame","text":"","code":"coxModelFrame(object, center)  # S3 method for coxph coxModelFrame(object, center = FALSE)  # S3 method for cph coxModelFrame(object, center = FALSE)  # S3 method for phreg coxModelFrame(object, center = FALSE)"},{"path":"/reference/coxModelFrame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the design matrix used to train a Cox model — coxModelFrame","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package). center [logical] variables linear predictor added ?","code":""},{"path":"/reference/coxModelFrame.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the design matrix used to train a Cox model — coxModelFrame","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxN.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the number of observations from a Cox model — coxN","title":"Extract the number of observations from a Cox model — coxN","text":"Extract number observations Cox model","code":""},{"path":"/reference/coxN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the number of observations from a Cox model — coxN","text":"","code":"coxN(object)  # S3 method for cph coxN(object)  # S3 method for coxph coxN(object)  # S3 method for phreg coxN(object)  # S3 method for CauseSpecificCox coxN(object)  # S3 method for glm coxN(object)"},{"path":"/reference/coxN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the number of observations from a Cox model — coxN","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxN.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the number of observations from a Cox model — coxN","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxSpecial.html","id":null,"dir":"Reference","previous_headings":"","what":"Special characters in Cox model — coxSpecial","title":"Special characters in Cox model — coxSpecial","text":"Return special character(s) Cox model, e.g. used indicate strata variables.","code":""},{"path":"/reference/coxSpecial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Special characters in Cox model — coxSpecial","text":"","code":"coxSpecial(object)  # S3 method for coxph coxSpecial(object)  # S3 method for cph coxSpecial(object)  # S3 method for phreg coxSpecial(object)"},{"path":"/reference/coxSpecial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Special characters in Cox model — coxSpecial","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxSpecial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Special characters in Cox model — coxSpecial","text":"Must return list least one element strata indicating character formula marking variable(s) defining strata.","code":""},{"path":"/reference/coxSpecial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Special characters in Cox model — coxSpecial","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxStrata.html","id":null,"dir":"Reference","previous_headings":"","what":"Define the strata for a new dataset — coxStrata","title":"Define the strata for a new dataset — coxStrata","text":"Define strata dataset match stratified Cox model","code":""},{"path":"/reference/coxStrata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define the strata for a new dataset — coxStrata","text":"","code":"coxStrata(object, data, sterms, strata.vars, strata.levels)  # S3 method for cph coxStrata(object, data, sterms, strata.vars, strata.levels)  # S3 method for coxph coxStrata(object, data, sterms, strata.vars, strata.levels)  # S3 method for phreg coxStrata(object, data, sterms, strata.vars, strata.levels)"},{"path":"/reference/coxStrata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define the strata for a new dataset — coxStrata","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package). data data.frame data.table sterms terms formula corresponding strata variables strata.vars name variables used define strata strata.levels named list containing variable used form strata possible levels levels strata levels used fit Cox model","code":""},{"path":"/reference/coxStrata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define the strata for a new dataset — coxStrata","text":"strata variables returns vector \"1\" (factor).","code":""},{"path":"/reference/coxStrata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define the strata for a new dataset — coxStrata","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxStrataLevel.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the name of the strata in Cox model — coxStrataLevel","title":"Returns the name of the strata in Cox model — coxStrataLevel","text":"Return name strata Cox model","code":""},{"path":"/reference/coxStrataLevel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the name of the strata in Cox model — coxStrataLevel","text":"","code":"coxStrataLevel(object)  # S3 method for coxph coxStrataLevel(object)  # S3 method for cph coxStrataLevel(object)  # S3 method for phreg coxStrataLevel(object)"},{"path":"/reference/coxStrataLevel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the name of the strata in Cox model — coxStrataLevel","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxStrataLevel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Returns the name of the strata in Cox model — coxStrataLevel","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxVarCov.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","title":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","text":"Extract variance covariance matrix beta Cox model","code":""},{"path":"/reference/coxVarCov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","text":"","code":"coxVarCov(object)  # S3 method for cph coxVarCov(object)  # S3 method for coxph coxVarCov(object)  # S3 method for phreg coxVarCov(object)"},{"path":"/reference/coxVarCov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","text":"object fitted Cox regression model object either obtained coxph (survival package), cph (rms package), phreg (mets package).","code":""},{"path":"/reference/coxVarCov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","text":"return NULL Cox model covariate.  rows columns variance covariance matrix must named names used design matrix.","code":""},{"path":"/reference/coxVarCov.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the variance covariance matrix of the beta from a Cox model — coxVarCov","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/coxVariableName.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract variable names from a model — coxVariableName","title":"Extract variable names from a model — coxVariableName","text":"Extract name variables belonging linear predictor used form strata","code":""},{"path":"/reference/coxVariableName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract variable names from a model — coxVariableName","text":"","code":"coxVariableName(object, model.frame)"},{"path":"/reference/coxVariableName.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract variable names from a model — coxVariableName","text":"object fitted Cox regression model object either obtained coxph (survival package) cph (rms package). model.frame [data.frame] dataset containing relevant variables (entry, time event, type event, variables linear predictor, strata). Output coxModelFrame.","code":""},{"path":"/reference/coxVariableName.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract variable names from a model — coxVariableName","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/dicreteRoot.html","id":null,"dir":"Reference","previous_headings":"","what":"Dichotomic search for monotone function — discreteRoot","title":"Dichotomic search for monotone function — discreteRoot","text":"Find root monotone function discrete grid value using dichotomic search","code":""},{"path":"/reference/dicreteRoot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dichotomic search for monotone function — discreteRoot","text":"","code":"discreteRoot(   fn,   grid,   increasing = TRUE,   check = TRUE,   tol = .Machine$double.eps^0.5 )"},{"path":"/reference/dicreteRoot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dichotomic search for monotone function — discreteRoot","text":"fn [function] objective function minimize absolute value. grid [vector] possible minimizers. increasing [logical] function fn increasing? check [logical] program check fn takes different sign first vs. last value grid? tol [numeric] absolute convergence tolerance.","code":""},{"path":"/reference/getSplitMethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Input for data splitting algorithms — getSplitMethod","title":"Input for data splitting algorithms — getSplitMethod","text":"Parse hyperparameters data splitting algorithm","code":""},{"path":"/reference/getSplitMethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Input for data splitting algorithms — getSplitMethod","text":"","code":"getSplitMethod(split.method, B, N, M, seed)"},{"path":"/reference/getSplitMethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Input for data splitting algorithms — getSplitMethod","text":"split.method character string specifying algorithm data splitting: \"loob\" leave one bootstrap \"bootcv\" bootstrap cross validation \"cv5\" 5-fold cross validation \"loocv\" leave one cross validation aka N-1 fold cross validation \"632plus\" Efron's .632+ bootstrap B Number repetitions bootstrap k-fold cross-validation N Sample size M Subsample size. Default N (subsampling). seed Integer passed set.seed. given NA seed set.","code":""},{"path":"/reference/getSplitMethod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Input for data splitting algorithms — getSplitMethod","text":"list following elements: split.methodName: print name algorithm split.method: internal name algorithm index: index data splitting. bootstrap splitting matrix B columns M rows identifying -bag subjects. k-fold cross-validation matrix B columns identifying membership k groups. k: k k-fold cross-validation N: sample size M: subsample size","code":""},{"path":[]},{"path":"/reference/getSplitMethod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Input for data splitting algorithms — getSplitMethod","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/getSplitMethod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Input for data splitting algorithms — getSplitMethod","text":"","code":"# 3-fold crossvalidation getSplitMethod(\"cv3\",B=4,N=37) #> $name #> [1] \"3-fold cross-validation\" #>  #> $internal.name #> [1] \"crossval\" #>  #> $index #>       [,1] [,2] [,3] [,4] #>  [1,]    3    2    3    1 #>  [2,]    3    3    1    1 #>  [3,]    1    3    2    1 #>  [4,]    3    1    2    1 #>  [5,]    2    1    1    2 #>  [6,]    3    2    2    1 #>  [7,]    1    2    3    1 #>  [8,]    2    1    3    3 #>  [9,]    2    3    1    1 #> [10,]    1    1    2    1 #> [11,]    2    2    3    2 #> [12,]    2    1    2    3 #> [13,]    3    2    2    1 #> [14,]    3    1    1    2 #> [15,]    3    1    1    3 #> [16,]    1    1    3    3 #> [17,]    3    1    2    3 #> [18,]    3    3    2    3 #> [19,]    1    3    1    2 #> [20,]    2    1    2    2 #> [21,]    1    1    1    3 #> [22,]    1    3    3    2 #> [23,]    2    2    1    3 #> [24,]    1    3    1    3 #> [25,]    1    3    1    2 #> [26,]    2    2    2    1 #> [27,]    2    1    1    2 #> [28,]    3    3    1    1 #> [29,]    1    2    2    2 #> [30,]    1    2    3    1 #> [31,]    3    1    3    3 #> [32,]    1    2    1    3 #> [33,]    2    2    3    3 #> [34,]    2    2    2    2 #> [35,]    2    3    3    2 #> [36,]    1    3    3    1 #> [37,]    3    3    3    2 #>  #> $k #> [1] 3 #>  #> $B #> [1] 4 #>  #> $M #> [1] 37 #>  #> $N #> [1] 37 #>  #> attr(,\"class\") #> [1] \"split.method\"  # bootstrap with replacement getSplitMethod(\"loob\",B=4,N=37) #> $name #> [1] \"LeaveOneOutBoot\" #>  #> $internal.name #> [1] \"LeaveOneOutBoot\" #>  #> $index #>       [,1] [,2] [,3] [,4] #>  [1,]    1    1    1    1 #>  [2,]    2    3    1    2 #>  [3,]    3    4    3    3 #>  [4,]    4    4    4    4 #>  [5,]    5    5    4    4 #>  [6,]    5    5    4    6 #>  [7,]    5    6    5    6 #>  [8,]    5    7    6    7 #>  [9,]    9    7    7    8 #> [10,]   10    9    8    9 #> [11,]   10   10    8   10 #> [12,]   11   10    8   10 #> [13,]   11   11    9   10 #> [14,]   15   12   12   11 #> [15,]   15   12   12   12 #> [16,]   15   13   14   12 #> [17,]   15   14   16   14 #> [18,]   16   14   16   15 #> [19,]   16   14   17   16 #> [20,]   17   14   19   17 #> [21,]   19   17   20   18 #> [22,]   21   17   20   18 #> [23,]   23   17   24   19 #> [24,]   23   18   24   19 #> [25,]   23   19   25   19 #> [26,]   26   25   25   20 #> [27,]   26   26   26   22 #> [28,]   30   27   28   22 #> [29,]   31   27   29   22 #> [30,]   34   29   30   23 #> [31,]   34   29   30   23 #> [32,]   35   31   31   26 #> [33,]   36   32   31   26 #> [34,]   37   33   31   27 #> [35,]   37   34   32   31 #> [36,]   37   36   33   36 #> [37,]   37   36   36   37 #>  #> $k #> NULL #>  #> $B #> [1] 4 #>  #> $M #> [1] 37 #>  #> $N #> [1] 37 #>  #> attr(,\"class\") #> [1] \"split.method\"  # bootstrap without replacement getSplitMethod(\"loob\",B=4,N=37,M=20) #> $name #> [1] \"LeaveOneOutBoot\" #>  #> $internal.name #> [1] \"LeaveOneOutBoot\" #>  #> $index #>       [,1] [,2] [,3] [,4] #>  [1,]    2    1    2    2 #>  [2,]    4    3    4    3 #>  [3,]    5    4    5    4 #>  [4,]    6    5    6    8 #>  [5,]    7   10    8    9 #>  [6,]    9   12   10   10 #>  [7,]   11   13   14   13 #>  [8,]   12   14   16   14 #>  [9,]   14   15   18   16 #> [10,]   15   17   19   19 #> [11,]   16   19   20   20 #> [12,]   18   22   22   21 #> [13,]   19   23   24   22 #> [14,]   24   25   25   23 #> [15,]   25   29   26   24 #> [16,]   26   30   29   25 #> [17,]   28   31   31   30 #> [18,]   30   34   33   31 #> [19,]   34   35   34   33 #> [20,]   35   37   35   34 #>  #> $k #> NULL #>  #> $B #> [1] 4 #>  #> $M #> [1] 20 #>  #> $N #> [1] 37 #>  #> attr(,\"class\") #> [1] \"split.method\""},{"path":"/reference/iid.wglm.html","id":null,"dir":"Reference","previous_headings":"","what":"IID for IPCW Logistic Regressions — iid.wglm","title":"IID for IPCW Logistic Regressions — iid.wglm","text":"Compute decomposition iid elements ML estimor IPCW logistic regressions.","code":""},{"path":"/reference/iid.wglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IID for IPCW Logistic Regressions — iid.wglm","text":"","code":"# S3 method for wglm iid(x, times = NULL, simplifies = TRUE, ...)"},{"path":"/reference/iid.wglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IID for IPCW Logistic Regressions — iid.wglm","text":"x wglm object. times [numeric vector] time points iid output. simplifies [logical] ouput converted matrix one timepoint requested. Otherwise always return list. ... used.","code":""},{"path":"/reference/iidCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract iid decomposition from a Cox model — iidCox","title":"Extract iid decomposition from a Cox model — iidCox","text":"Compute influence function observation used estimate model","code":""},{"path":"/reference/iidCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract iid decomposition from a Cox model — iidCox","text":"","code":"iidCox(   object,   newdata,   baseline.iid,   tau.hazard,   tau.max,   store.iid,   keep.times,   return.object )  # S3 method for coxph iidCox(   object,   newdata = NULL,   baseline.iid = TRUE,   tau.hazard = NULL,   tau.max = NULL,   store.iid = \"full\",   keep.times = TRUE,   return.object = TRUE )  # S3 method for cph iidCox(   object,   newdata = NULL,   baseline.iid = TRUE,   tau.hazard = NULL,   tau.max = NULL,   store.iid = \"full\",   keep.times = TRUE,   return.object = TRUE )  # S3 method for phreg iidCox(   object,   newdata = NULL,   baseline.iid = TRUE,   tau.hazard = NULL,   tau.max = NULL,   store.iid = \"full\",   keep.times = TRUE,   return.object = TRUE )  # S3 method for CauseSpecificCox iidCox(   object,   newdata = NULL,   baseline.iid = TRUE,   tau.hazard = NULL,   tau.max = NULL,   store.iid = \"full\",   keep.times = TRUE,   return.object = TRUE )"},{"path":"/reference/iidCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract iid decomposition from a Cox model — iidCox","text":"object object fitted Cox regression model object either obtained coxph (survival package) cph (rms package). newdata [data.frame] Optional new data iid decomposition baseline.iid [logical] influence function baseline hazard computed. tau.hazard [numeric vector] vector times ..d decomposition baseline hazard computed tau.max [numeric] latest time ..d decomposition baseline hazard computed. Alternative tau.hazard. store.iid [character] method used compute influence function standard error. Can \"full\" \"minimal\". See details section. keep.times [logical] TRUE add evaluation times output. return.object [logical] TRUE return object iid decomposition added. Otherwise return list (see return section)","code":""},{"path":"/reference/iidCox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract iid decomposition from a Cox model — iidCox","text":"Cox models, returns object additional iid slot (.e. object$iid). list containing: IFbetaInfluence function regression coefficient. IFhazardTime differential influence function hazard. IFcumhazardInfluence function cumulative hazard. calcIFhazardElements used compute influence function given time. timeTimes influence function evaluated. etime1.minTime first event (.e. jump) strata. etime.maxLast observation time (.e. jump censoring) strata. indexObsIndex observation original dataset. Cause-Specific Cox models, returns object additional iid slot model (e.g. object$models[[1]]iid).","code":""},{"path":"/reference/iidCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract iid decomposition from a Cox model — iidCox","text":"function implements first three formula (number,10,11) subsection \"Empirical estimates\" Ozenne et al. (2017). event strata, influence function baseline hazard set 0. Argument store.iid: n denotes sample size, J number jump times, p number coefficients: store.iid=\"full\" exports influence function coefficients baseline hazard event time. store.iid=\"minimal\" exports influence function coefficients. baseline hazard computes quantities necessary compute influence function order save memory. details can found appendix B Ozenne et al. (2017).","code":""},{"path":"/reference/iidCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract iid decomposition from a Cox model — iidCox","text":"Brice Ozenne, Anne Lyngholm Sorensen, Thomas Scheike, Christian Torp-Pedersen Thomas Alexander Gerds. riskRegression: Predicting Risk Event using Cox Regression Models. R Journal (2017) 9:2, pages 440-460.","code":""},{"path":"/reference/iidCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract iid decomposition from a Cox model — iidCox","text":"","code":"library(survival) library(data.table) library(prodlim) set.seed(10) d <- sampleData(100, outcome = \"survival\")[,.(eventtime,event,X1,X6)] setkey(d, eventtime)  m.cox <- coxph(Surv(eventtime, event) ~ X1+X6, data = d, y = TRUE, x = TRUE) system.time(IF.cox <- iidCox(m.cox)) #>    user  system elapsed  #>   0.011   0.000   0.011   IF.cox.all <- iidCox(m.cox, tau.hazard = sort(unique(c(7,d$eventtime)))) IF.cox.beta <- iidCox(m.cox, baseline.iid = FALSE)"},{"path":"/reference/influenceTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Influence test [Experimental!!] — influenceTest","title":"Influence test [Experimental!!] — influenceTest","text":"Compare two estimates using influence function","code":""},{"path":"/reference/influenceTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Influence test [Experimental!!] — influenceTest","text":"","code":"influenceTest(object, ...)  # S3 method for list influenceTest(   object,   newdata,   times,   type,   cause,   keep.newdata = TRUE,   keep.strata = FALSE,   ... )  # S3 method for default influenceTest(object, object2, band = TRUE, ...)"},{"path":"/reference/influenceTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Influence test [Experimental!!] — influenceTest","text":"object either list models object class predictCox predictCSC. ... additional arguments passed lower level functions. newdata [data.frame data.table] Contain values predictor variables defining subject specific predictions. times [numeric vector] Time points return estimated absolute risk. type [character]type predicted value. cause [integer/character] Identifies cause interest among competing events. keep.newdata [logical] TRUE add value covariates used make prediction output. keep.strata [logical] TRUE add value strata used make prediction output. object2 predict1 another model. band [logical] TRUE add influence function output confint able compute confidence bands.","code":""},{"path":"/reference/influenceTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Influence test [Experimental!!] — influenceTest","text":"","code":"library(lava) library(survival) library(prodlim) library(data.table) n <- 100  #### Under H1 set.seed(1) newdata <- data.frame(X1=0:1)  ## simulate non proportional hazard using lava m <- lvm() regression(m) <- y ~ 1 regression(m) <- s ~ exp(-2*X1) distribution(m,~X1) <- binomial.lvm() distribution(m,~cens) <- coxWeibull.lvm(scale=1) distribution(m,~y) <- coxWeibull.lvm(scale=1,shape=~s) eventTime(m) <- eventtime ~ min(y=1,cens=0) d <- as.data.table(sim(m,n)) setkey(d, eventtime)  ## fit cox models m.cox <- coxph(Surv(eventtime, status) ~ X1,                 data = d, y = TRUE, x = TRUE)  mStrata.cox <- coxph(Surv(eventtime, status) ~ strata(X1),                       data = d, y = TRUE, x = TRUE)  ## compare models # one time point outIF <- influenceTest(list(m.cox, mStrata.cox),                type = \"survival\", newdata = newdata, times = 0.5) confint(outIF) #>         Comparison of two estimates of the survival at time 0.5 #>  #> model 1: #> coxph(formula = Surv(eventtime, status) ~ X1, data = d, x = TRUE,  #>     y = TRUE) #> model 2: #> coxph(formula = Surv(eventtime, status) ~ strata(X1), data = d,  #>     x = TRUE, y = TRUE) #>    X1 time difference     se     conf.interval p.value quantileBand #> 1:  0  0.5    -0.0608 0.0270 [-0.114 ; -0.008]  0.0243         1.98 #> 2:  1  0.5     0.0361 0.0241  [-0.011 ; 0.083]  0.1339         1.98 #>            conf.band #> 1: [-0.114 ; -0.007] #> 2:  [-0.012 ; 0.084]                                   # several timepoints outIF <- influenceTest(list(m.cox, mStrata.cox),                type = \"survival\", newdata = newdata, times = c(0.5,1,1.5)) confint(outIF) #>         Comparison of two estimates of the survival at time 0.5 1 1.5 #>  #> model 1: #> coxph(formula = Surv(eventtime, status) ~ X1, data = d, x = TRUE,  #>     y = TRUE) #> model 2: #> coxph(formula = Surv(eventtime, status) ~ strata(X1), data = d,  #>     x = TRUE, y = TRUE) #>    X1 time difference     se     conf.interval p.value quantileBand #> 1:  0  0.5    -0.0608 0.0270 [-0.114 ; -0.008] 0.02435         2.17 #> 2:  0  1.0     0.0539 0.0273       [0 ; 0.107] 0.04814         2.17 #> 3:  0  1.5     0.0539 0.0273       [0 ; 0.107] 0.04814         2.17 #> 4:  1  0.5     0.0361 0.0241  [-0.011 ; 0.083] 0.13388         2.17 #> 5:  1  1.0    -0.0626 0.0234 [-0.109 ; -0.017] 0.00758         2.17 #> 6:  1  1.5    -0.0626 0.0234 [-0.109 ; -0.017] 0.00758         2.17 #>            conf.band #> 1: [-0.119 ; -0.002] #> 2:  [-0.005 ; 0.113] #> 3:  [-0.005 ; 0.113] #> 4:  [-0.016 ; 0.088] #> 5: [-0.113 ; -0.012] #> 6: [-0.113 ; -0.012]  #### Under H0 (Cox) #### set.seed(1) ## simulate proportional hazard using lava m <- lvm() regression(m) <- y ~ 1 distribution(m,~X1) <- binomial.lvm() distribution(m,~cens) <- coxWeibull.lvm() distribution(m,~y) <- coxWeibull.lvm() eventTime(m) <- eventtime ~ min(y=1,cens=0) d <- as.data.table(sim(m,n)) setkey(d, eventtime)  ## fit cox models Utime <- sort(unique(d$eventtime)) m.cox <- coxph(Surv(eventtime, status) ~ X1,                 data = d, y = TRUE, x = TRUE)  mStrata.cox <- coxph(Surv(eventtime, status) ~ strata(X1),                       data = d, y = TRUE, x = TRUE)  p.cox <- predictCox(m.cox, newdata = newdata, time = Utime, type = \"survival\") p.coxStrata <- predictCox(mStrata.cox, newdata = newdata, time = Utime, type = \"survival\")  ## display library(ggplot2) autoplot(p.cox)  autoplot(p.coxStrata)    ## compare models outIF <- influenceTest(list(m.cox, mStrata.cox),                         type = \"survival\", newdata = newdata, times = Utime[1:6]) confint(outIF) #>         Comparison of two estimates of the survival at time 0.901 1.364 1.984 2.004 2.177 2.312 #>  #> model 1: #> coxph(formula = Surv(eventtime, status) ~ X1, data = d, x = TRUE,  #>     y = TRUE) #> model 2: #> coxph(formula = Surv(eventtime, status) ~ strata(X1), data = d,  #>     x = TRUE, y = TRUE) #>     X1  time difference     se    conf.interval p.value quantileBand #>  1:  0 0.901    0.00000 0.0000          [0 ; 0]   1.000         2.34 #>  2:  0 1.364    0.01469 0.0140 [-0.013 ; 0.042]   0.295         2.34 #>  3:  0 1.984    0.00739 0.0155 [-0.023 ; 0.038]   0.633         2.34 #>  4:  0 2.004    0.00739 0.0155 [-0.023 ; 0.038]   0.633         2.34 #>  5:  0 2.177    0.02195 0.0200 [-0.017 ; 0.061]   0.272         2.34 #>  6:  0 2.312    0.03650 0.0232 [-0.009 ; 0.082]   0.115         2.34 #>  7:  1 0.901    0.00000 0.0000          [0 ; 0]   1.000         2.34 #>  8:  1 1.364   -0.01234 0.0120 [-0.036 ; 0.011]   0.303         2.34 #>  9:  1 1.984   -0.00627 0.0130 [-0.032 ; 0.019]   0.630         2.34 #> 10:  1 2.004   -0.00627 0.0130 [-0.032 ; 0.019]   0.630         2.34 #> 11:  1 2.177   -0.01871 0.0171 [-0.052 ; 0.015]   0.273         2.34 #> 12:  1 2.312   -0.03108 0.0200  [-0.07 ; 0.008]   0.120         2.34 #>            conf.band #>  1:          [0 ; 0] #>  2: [-0.018 ; 0.047] #>  3: [-0.029 ; 0.044] #>  4: [-0.029 ; 0.044] #>  5: [-0.025 ; 0.069] #>  6: [-0.018 ; 0.091] #>  7:          [0 ; 0] #>  8:  [-0.04 ; 0.016] #>  9: [-0.037 ; 0.024] #> 10: [-0.037 ; 0.024] #> 11: [-0.059 ; 0.021] #> 12: [-0.078 ; 0.016]  #### Under H0 (CSC) #### set.seed(1) ff <- ~ f(X1,2) + f(X2,-0.033) ff <- update(ff, ~ .+ f(X3,0) + f(X4,0) + f(X5,0)) ff <- update(ff, ~ .+ f(X6,0) + f(X7,0) + f(X8,0) + f(X9,0)) d <- sampleData(n, outcome = \"competing.risk\", formula = ff) d[,X1:=as.numeric(as.character(X1))] #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>   1:  38.17963 60.30461  0.49696095  0.96169663  1.473881181  0  0  0  1  0 #>   2:  47.31519 55.88254 -0.22487472 -0.60442573  0.677268492  1  0  0  0  0 #>   3:  41.24281 69.14865 -1.11714317 -0.75287728  0.379962687  0  0  1  0  1 #>   4:  70.00932 52.85042 -0.39499460 -1.55561159 -0.192798426  0  0  1  0  0 #>   5:  40.63845 61.27069  1.54983034 -1.45389374  1.577891795  1  0  1  0  0 #>   6:  29.47495 45.30113 -0.74351448  0.05633184  0.596234109  1  1  1  1  1 #>   7:  90.32020 60.01208 -2.33171212  0.50936941 -1.173576941  0  0  0  0  1 #>   8:  75.08960 62.54833  0.81224544 -2.09788296 -0.155642535  0  1  1  1  0 #>   9:  72.25685 54.57640 -0.50131066 -1.00436198 -1.918909820  1  0  0  0  0 #>  10:  50.04018 63.52416 -0.51088657  0.53577172 -0.195258846  0  0  1  0  1 #>  11:  59.83078 61.65488 -1.21536404 -0.45303708 -2.592327670  1  1  1  0  1 #>  12:  69.29516 64.88164 -0.02255863  2.16536850  1.314002167  0  0  0  0  0 #>  13:  40.78142 55.78330  0.70123930  1.24574667 -0.635543001  0  0  1  1  1 #>  14:  58.13608 55.14710 -0.58748203  0.59549803 -0.429978839  0  0  1  1  1 #>  15:  62.63612 51.14234 -0.60672794  0.00488445 -0.169318332  0  0  1  0  1 #>  16:  85.39161 58.38765  1.09664022  0.27936078  0.612218174  0  0  0  0  0 #>  17:  69.63199 53.30600 -0.24750968 -0.70590613  0.678340177  0  0  0  0  1 #>  18:  79.23350 63.44078 -0.15990171  0.62801715  0.567951972  0  0  0  0  1 #>  19:  62.10820 60.35640 -0.62577825  1.48021396 -0.572542604  0  0  0  1  1 #>  20:  43.31246 70.94876  0.90043464  1.08342991 -1.363291256  0  0  1  1  0 #>  21:  54.90485 54.21146 -0.99419363 -0.81324426 -0.388722244  0  1  0  1  0 #>  22:  35.02853 65.90844  0.84925039 -1.61887685  0.277914132  0  0  0  0  0 #>  23:  73.93278 57.36316  0.80570229 -0.10965570 -0.823081122  0  0  0  0  0 #>  24:  81.25240 52.71686 -0.46760094  0.44088937 -0.068840934  0  0  0  1  1 #>  25:  59.05919 62.86484  0.84842031  1.35099398 -1.167662326  0  0  0  1  1 #>  26:  45.28646 52.83311  0.98676986 -1.31860948 -0.008309014  0  1  0  1  1 #>  27:  76.30725 54.72407  0.57562029  0.36438459  0.128855402  0  1  0  1  0 #>  28:  62.08991 56.33444  2.02484205  0.23349984 -0.145875628  0  0  1  1  0 #>  29:  54.20592 61.05454 -1.96235319  1.19395526 -0.163910957  0  1  1  0  0 #>  30:  76.85378 55.00540 -1.16492093 -0.02790997  1.763552003  1  1  1  1  1 #>  31:  48.60232 65.38925 -1.37651921 -0.35729885  0.762586512  0  0  1  1  0 #>  32:  77.23439 54.00513  0.16767993 -1.14681414  1.111431081  0  0  0  0  0 #>  33:  47.36286 61.08319  1.58462908 -0.51742048 -0.923206953  0  0  0  0  0 #>  34:  65.87120 60.71544  1.67788895 -0.36212377  0.164341838  0  0  0  1  1 #>  35:  73.37066 54.67125  0.48829670  2.35055433  1.154825187  0  0  0  0  0 #>  36:  39.97112 57.85688  0.87867326  2.44653138 -0.056521425  0  0  1  0  1 #>  37:  65.97185 56.71910 -0.14487487 -0.16670328 -2.129360648  0  0  1  0  1 #>  38:  58.32620 64.79697  0.46897176 -1.04366744  0.344845762  0  0  0  0  1 #>  39:  70.13616 67.78026  0.37623548 -1.97293493 -1.904955446  0  0  0  0  0 #>  40:  48.17103 54.79602 -0.76104028  0.51467163 -0.811170153  0  0  1  1  0 #>  41:  58.69520 64.65286 -0.29329493 -1.09057358  1.324004321  1  0  0  1  0 #>  42:  80.73426 59.62277 -0.13484126  2.28465933  0.615636849  0  1  0  0  1 #>  43:  62.52735 50.16402  1.39384582 -0.88561757  1.091668956  1  0  0  0  1 #>  44:  72.34786 56.22048 -1.03698869  0.11110643  0.306604862  0  0  0  0  0 #>  45:  56.68658 62.30575 -2.11433515  3.81027668 -0.110158762  0  0  0  1  0 #>  46:  44.55913 60.72553  0.76827822 -1.10891000 -0.924312773  0  0  0  0  0 #>  47:  59.83611 47.78844 -0.81616062  0.30756662  1.592913754  0  1  0  0  0 #>  48:  41.62513 62.90159 -0.43610692 -1.10689447  0.045010598  0  0  1  0  0 #>  49:  21.05833 63.27526  0.90470503  0.34765365 -0.715128401  0  0  0  0  0 #>  50:  77.53684 58.47746 -0.76308626 -0.87326454  0.865223100  1  0  0  1  1 #>  51:  43.69637 56.46216 -0.34106698  0.07730312  1.074440958  0  1  1  0  1 #>  52:  32.60875 69.85786  1.50242453 -0.29686864  1.895654774  0  0  0  0  1 #>  53:  74.92923 59.55001  0.52830771 -1.18324224 -0.602997304  0  0  0  1  0 #>  54:  59.82207 59.92991  0.54219136  0.01129269 -0.390867821  0  1  0  0  1 #>  55:  51.00557 54.38272 -0.13667336  0.99160104 -0.416222032  0  0  0  1  0 #>  56:  57.33078 53.27935 -1.13673385  1.59396745 -0.375657423  0  0  0  0  0 #>  57:  53.61028 52.38422 -1.49662715 -1.37271127 -0.366630946  0  0  0  1  0 #>  58:  74.94988 57.89016 -0.22338564 -0.24961093 -0.295677453  0  0  1  0  0 #>  59:  70.91491 66.80462  2.00171923  1.15942453  1.441820410  0  1  0  1  0 #>  60:  34.10054 68.76897  0.22170382 -1.11422235 -0.697538292  0  1  0  0  1 #>  61:  65.30098 67.84182  0.16437291 -2.52850069 -0.388167506  0  0  0  0  1 #>  62:  70.90220 66.48378  0.33262361 -0.93590256  0.652536452  0  0  0  0  0 #>  63:  70.02391 58.81202 -0.38520800 -0.96723946  1.124772447  0  0  0  1  0 #>  64:  23.63524 53.87925 -1.39875403  0.04748859 -0.772110803  0  0  0  0  1 #>  65:  56.46964 58.36094  2.67574080 -0.40373679 -0.508086216  0  1  0  0  1 #>  66:  89.69450 47.93775 -0.42368609  0.23149613  0.523620590  0  0  1  1  0 #>  67:  71.95192 58.43104 -0.29860151 -0.42237241  1.017754227  1  0  1  0  0 #>  68:  34.36086 68.29939 -1.79234173  0.37411839 -0.251164588  0  0  0  1  1 #>  69:  35.04497 60.65477 -0.24800823 -0.36600577 -1.429993447  0  0  0  1  1 #>  70:  67.36664 65.47944 -0.24730392  1.19010145  1.709121032  0  1  0  0  0 #>  71:  57.38917 62.44670 -0.25551038 -0.73732753  1.435069572  0  0  0  0  0 #>  72:  74.41936 56.10545 -1.78693810  0.29066665 -0.710371146  0  0  1  0  0 #>  73:  64.40740 68.71780  1.78466282 -0.88484957 -0.065067574  0  0  1  1  0 #>  74:  61.21499 59.60806  1.76358635  0.20800648 -1.759468735  0  0  0  0  0 #>  75:  62.75493 55.12223  0.68960022 -0.04773017  0.569722972  0  1  0  0  0 #>  76:  62.49383 60.35330 -1.10074064 -1.68452065  1.612346798  0  0  0  0  0 #>  77:  40.95601 52.40700  0.71450936 -0.14422656 -1.637280647  0  0  1  0  0 #>  78:  95.24240 64.31890 -0.24647032  1.18021367 -0.779568513  0  0  0  1  0 #>  79:  38.81992 62.50784 -0.31978617  0.68139992 -0.641176934  0  1  0  0  0 #>  80:  59.74558 58.22609  1.36264429  0.14324763 -0.681131394  0  0  0  0  1 #>  81:  51.83521 57.55786 -1.22788259 -1.19231644 -2.033285596  0  0  1  0  0 #>  82:  87.00169 64.68147 -0.51121923  1.16922865  0.500963559  0  1  0  0  1 #>  83:  75.17160 54.68796 -0.73119500  0.07920171 -1.531798140  0  0  1  1  1 #>  84:  51.54425 55.08090  0.01975201 -0.45177375 -0.024997639  0  0  1  1  0 #>  85:  63.08131 62.12124 -1.57286391  1.64202821  0.592984721  0  0  0  0  0 #>  86:  77.48193 57.74343 -0.70333327 -0.76959232 -0.198195421  0  0  0  0  0 #>  87:  93.54484 64.62542  0.71593209  0.30336096  0.892008392  0  0  0  1  0 #>  88:  64.53398 59.00690  0.46521491  1.28173742 -0.025715071  0  0  0  1  0 #>  89:  44.36240 65.97426 -0.97390231  0.60222280 -0.647660451  0  1  1  0  0 #>  90:  45.24687 62.47772  0.55921773 -0.30702226  0.646359415  1  0  0  1  0 #>  91:  90.08578 48.77424 -2.43263975 -0.41841810 -0.433832740  0  0  0  0  0 #>  92:  28.94143 53.32314 -0.34048493  0.35513553  1.772611185  0  0  1  0  0 #>  93: 105.83614 66.41388  0.71303319  0.51348111 -0.018259711  0  0  0  1  1 #>  94:  56.07974 63.45398 -0.65903739  0.01860740  0.852814994  0  0  0  0  0 #>  95:  53.18410 55.16469 -0.03640262  1.31844897  0.205162903  0  1  0  0  1 #>  96:  62.36341 53.27103 -1.59328630 -0.06583200 -3.008048599  0  0  0  0  1 #>  97:  74.00083 65.16833  0.84779280 -0.70029608 -1.366111931  0  0  0  1  0 #>  98:  64.54242 55.94112 -1.85038885  0.53732613 -0.424102260  0  0  0  0  0 #>  99:  30.65775 69.00863 -0.32365063 -2.20178232  0.236803664  1  0  1  0  0 #> 100:  65.30305 68.85771 -0.25524811  0.39197374 -2.342723120  0  0  0  0  1 #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>      eventtime1 eventtime2   censtime       time event #>   1:  6.2835117  6.5080075 11.5156754  6.2835117     1 #>   2:  2.2341745 10.2016103  9.9424766  2.2341745     1 #>   3:  5.4227648 11.4384015  7.4640840  5.4227648     1 #>   4: 14.4463659  0.8569032  3.1029354  0.8569032     2 #>   5:  5.0566209  6.7565221 12.6533135  5.0566209     1 #>   6:  4.9180272 12.4317594  3.2733982  3.2733982     0 #>   7: 21.7373883 14.3005616  2.3856664  2.3856664     0 #>   8:  6.8654215  8.5900969  6.4366715  6.4366715     0 #>   9:  3.6545169  2.8100287  6.8076628  2.8100287     2 #>  10: 11.3187530  7.1616535 16.6855449  7.1616535     2 #>  11:  4.9578732  1.5529912 12.5698152  1.5529912     2 #>  12: 12.6136920  5.5880073 13.1685721  5.5880073     2 #>  13: 12.2705325 10.1527570  6.1268894  6.1268894     0 #>  14: 11.7160646  9.1681445  9.7818335  9.1681445     2 #>  15: 13.3093289 13.8170712  5.1143986  5.1143986     0 #>  16:  2.8558834 20.8251202  8.3531989  2.8558834     1 #>  17: 10.3116570  5.7851651  5.7603574  5.7603574     0 #>  18: 15.6965602 15.0706310  0.9014898  0.9014898     0 #>  19:  9.8658157  8.9821989  9.8361143  8.9821989     2 #>  20:  7.8103363  6.6792906  5.0173907  5.0173907     0 #>  21:  4.9754291  0.9052550  2.5985392  0.9052550     2 #>  22: 10.6698406  8.3785386 12.4518953  8.3785386     2 #>  23:  4.2034654  8.5143906  6.5437848  4.2034654     1 #>  24:  0.3912398 13.2359741 14.4048971  0.3912398     1 #>  25: 12.4273308  5.3035339 11.4877347  5.3035339     2 #>  26:  9.2460530  8.8875661  9.7551134  8.8875661     2 #>  27: 10.0175198  8.1917854 20.7682985  8.1917854     2 #>  28:  1.8716231 12.5395636  9.8046907  1.8716231     1 #>  29:  6.7783389 12.1471281  3.7365423  3.7365423     0 #>  30:  1.7361957  7.1972075 10.3816363  1.7361957     1 #>  31:  2.9051934  7.4404807  8.5419258  2.9051934     1 #>  32: 16.8423205 16.0097286  7.1522689  7.1522689     0 #>  33:  8.5958827 18.2676768  8.4032656  8.4032656     0 #>  34:  6.0094763  6.6477715 12.9647190  6.0094763     1 #>  35: 17.6307100  2.7214120  4.3531514  2.7214120     2 #>  36:  5.2781104  7.1694490  6.3464056  5.2781104     1 #>  37:  7.2443077  7.6040207  4.7996851  4.7996851     0 #>  38:  8.2040793  8.0149945 14.9202754  8.0149945     2 #>  39:  8.9036096  1.2254374  5.6865034  1.2254374     2 #>  40: 19.1566811  8.2339490  9.4259990  8.2339490     2 #>  41:  0.7256035  6.1771413  4.4418193  0.7256035     1 #>  42:  1.1343471  7.1292371  6.5978478  1.1343471     1 #>  43:  2.4818625 11.9659573  4.9468016  2.4818625     1 #>  44:  9.2433390 11.6368070  7.6963083  7.6963083     0 #>  45: 11.4974289  5.6183353  7.9712452  5.6183353     2 #>  46: 15.8702088  8.9039935  4.8635127  4.8635127     0 #>  47: 10.7024090 13.1994135 19.3854679 10.7024090     1 #>  48:  3.3465424  5.4045730  8.6009103  3.3465424     1 #>  49: 10.8718263 15.0130365  5.5816328  5.5816328     0 #>  50:  3.5098271  3.8151275  6.0589827  3.5098271     1 #>  51:  7.5771125  6.9764637  8.5961656  6.9764637     2 #>  52:  7.1823229  7.6478994  3.8654561  3.8654561     0 #>  53:  7.4972585 10.5469171  9.0846832  7.4972585     1 #>  54: 12.5460292  8.8970390 11.8630723  8.8970390     2 #>  55:  4.4530482  8.3202501 16.2776107  4.4530482     1 #>  56: 18.1829154 13.0766848 15.1918985 13.0766848     2 #>  57:  6.8488799  7.9722989 10.7291826  6.8488799     1 #>  58:  9.1428227 16.0829018  8.1028164  8.1028164     0 #>  59: 10.3188714 11.3181822  6.4224766  6.4224766     0 #>  60:  5.1499748 12.4413617  9.4834562  5.1499748     1 #>  61: 13.2357625 11.2071474  3.0191937  3.0191937     0 #>  62:  8.4072725  3.3290603 11.0703455  3.3290603     2 #>  63:  5.5218756  8.9828104  8.8236154  5.5218756     1 #>  64:  8.1938006  4.9847842 10.4949142  4.9847842     2 #>  65:  8.7705630  3.5655318  6.5532025  3.5655318     2 #>  66:  7.2883367  9.4021645 11.6392897  7.2883367     1 #>  67:  2.7472424 16.5887588  8.5848967  2.7472424     1 #>  68:  6.5057331 10.4506967  5.1591435  5.1591435     0 #>  69:  3.8063188  5.6863212 15.7289648  3.8063188     1 #>  70:  9.7735032 10.4204035  3.6491674  3.6491674     0 #>  71:  2.0174490  6.7924836 10.3997117  2.0174490     1 #>  72:  9.8248568  4.1667978  4.1835375  4.1667978     2 #>  73: 13.3095367  3.9412067 10.2924392  3.9412067     2 #>  74: 12.0943064  9.6857073 10.4751533  9.6857073     2 #>  75:  2.3043659  9.8299805  8.6116188  2.3043659     1 #>  76: 15.7569380  3.3231612  3.3773780  3.3231612     2 #>  77: 12.8251201  6.6299801  3.8182415  3.8182415     0 #>  78: 16.1069493  5.4740161  9.7037897  5.4740161     2 #>  79:  7.2066603  7.0853750  5.0189867  5.0189867     0 #>  80: 12.3822634  3.1928412  2.0044564  2.0044564     0 #>  81:  7.2873177 11.0683954  9.1279371  7.2873177     1 #>  82: 12.3448375 12.8612633  5.8219822  5.8219822     0 #>  83:  9.6914349  3.4717358  9.5723812  3.4717358     2 #>  84: 10.2753258  8.2854717 10.5964482  8.2854717     2 #>  85:  2.9179562  3.6219149  5.2751958  2.9179562     1 #>  86: 14.7949557 12.9034272 12.6335523 12.6335523     0 #>  87: 11.6901039  5.2624704  5.8387701  5.2624704     2 #>  88: 12.9563074  5.6769274 14.5129689  5.6769274     2 #>  89:  5.5090254  2.4066712 11.8511819  2.4066712     2 #>  90:  0.9690222  7.7596721 13.9383800  0.9690222     1 #>  91:  8.3891580  5.8312706 11.9526635  5.8312706     2 #>  92:  6.6220447  9.7181270 16.8265585  6.6220447     1 #>  93: 13.1848154 15.1455991  6.6537063  6.6537063     0 #>  94:  7.1122919  2.7472876  3.6343076  2.7472876     2 #>  95:  3.5078609 11.2315946  4.9985375  3.5078609     1 #>  96:  8.4434745  7.2571465  4.7593402  4.7593402     0 #>  97: 19.9907424 14.8458817  8.8704839  8.8704839     0 #>  98: 13.1079695  4.1683325  9.4413615  4.1683325     2 #>  99:  4.0399870 10.7042893  4.5787251  4.0399870     1 #> 100: 11.3307878  4.9478527  7.0896903  4.9478527     2 #>      eventtime1 eventtime2   censtime       time event d[,X2:=as.numeric(as.character(X2))] #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>   1:  38.17963 60.30461  0.49696095  0.96169663  1.473881181  0  0  0  1  0 #>   2:  47.31519 55.88254 -0.22487472 -0.60442573  0.677268492  1  0  0  0  0 #>   3:  41.24281 69.14865 -1.11714317 -0.75287728  0.379962687  0  0  1  0  1 #>   4:  70.00932 52.85042 -0.39499460 -1.55561159 -0.192798426  0  0  1  0  0 #>   5:  40.63845 61.27069  1.54983034 -1.45389374  1.577891795  1  0  1  0  0 #>   6:  29.47495 45.30113 -0.74351448  0.05633184  0.596234109  1  1  1  1  1 #>   7:  90.32020 60.01208 -2.33171212  0.50936941 -1.173576941  0  0  0  0  1 #>   8:  75.08960 62.54833  0.81224544 -2.09788296 -0.155642535  0  1  1  1  0 #>   9:  72.25685 54.57640 -0.50131066 -1.00436198 -1.918909820  1  0  0  0  0 #>  10:  50.04018 63.52416 -0.51088657  0.53577172 -0.195258846  0  0  1  0  1 #>  11:  59.83078 61.65488 -1.21536404 -0.45303708 -2.592327670  1  1  1  0  1 #>  12:  69.29516 64.88164 -0.02255863  2.16536850  1.314002167  0  0  0  0  0 #>  13:  40.78142 55.78330  0.70123930  1.24574667 -0.635543001  0  0  1  1  1 #>  14:  58.13608 55.14710 -0.58748203  0.59549803 -0.429978839  0  0  1  1  1 #>  15:  62.63612 51.14234 -0.60672794  0.00488445 -0.169318332  0  0  1  0  1 #>  16:  85.39161 58.38765  1.09664022  0.27936078  0.612218174  0  0  0  0  0 #>  17:  69.63199 53.30600 -0.24750968 -0.70590613  0.678340177  0  0  0  0  1 #>  18:  79.23350 63.44078 -0.15990171  0.62801715  0.567951972  0  0  0  0  1 #>  19:  62.10820 60.35640 -0.62577825  1.48021396 -0.572542604  0  0  0  1  1 #>  20:  43.31246 70.94876  0.90043464  1.08342991 -1.363291256  0  0  1  1  0 #>  21:  54.90485 54.21146 -0.99419363 -0.81324426 -0.388722244  0  1  0  1  0 #>  22:  35.02853 65.90844  0.84925039 -1.61887685  0.277914132  0  0  0  0  0 #>  23:  73.93278 57.36316  0.80570229 -0.10965570 -0.823081122  0  0  0  0  0 #>  24:  81.25240 52.71686 -0.46760094  0.44088937 -0.068840934  0  0  0  1  1 #>  25:  59.05919 62.86484  0.84842031  1.35099398 -1.167662326  0  0  0  1  1 #>  26:  45.28646 52.83311  0.98676986 -1.31860948 -0.008309014  0  1  0  1  1 #>  27:  76.30725 54.72407  0.57562029  0.36438459  0.128855402  0  1  0  1  0 #>  28:  62.08991 56.33444  2.02484205  0.23349984 -0.145875628  0  0  1  1  0 #>  29:  54.20592 61.05454 -1.96235319  1.19395526 -0.163910957  0  1  1  0  0 #>  30:  76.85378 55.00540 -1.16492093 -0.02790997  1.763552003  1  1  1  1  1 #>  31:  48.60232 65.38925 -1.37651921 -0.35729885  0.762586512  0  0  1  1  0 #>  32:  77.23439 54.00513  0.16767993 -1.14681414  1.111431081  0  0  0  0  0 #>  33:  47.36286 61.08319  1.58462908 -0.51742048 -0.923206953  0  0  0  0  0 #>  34:  65.87120 60.71544  1.67788895 -0.36212377  0.164341838  0  0  0  1  1 #>  35:  73.37066 54.67125  0.48829670  2.35055433  1.154825187  0  0  0  0  0 #>  36:  39.97112 57.85688  0.87867326  2.44653138 -0.056521425  0  0  1  0  1 #>  37:  65.97185 56.71910 -0.14487487 -0.16670328 -2.129360648  0  0  1  0  1 #>  38:  58.32620 64.79697  0.46897176 -1.04366744  0.344845762  0  0  0  0  1 #>  39:  70.13616 67.78026  0.37623548 -1.97293493 -1.904955446  0  0  0  0  0 #>  40:  48.17103 54.79602 -0.76104028  0.51467163 -0.811170153  0  0  1  1  0 #>  41:  58.69520 64.65286 -0.29329493 -1.09057358  1.324004321  1  0  0  1  0 #>  42:  80.73426 59.62277 -0.13484126  2.28465933  0.615636849  0  1  0  0  1 #>  43:  62.52735 50.16402  1.39384582 -0.88561757  1.091668956  1  0  0  0  1 #>  44:  72.34786 56.22048 -1.03698869  0.11110643  0.306604862  0  0  0  0  0 #>  45:  56.68658 62.30575 -2.11433515  3.81027668 -0.110158762  0  0  0  1  0 #>  46:  44.55913 60.72553  0.76827822 -1.10891000 -0.924312773  0  0  0  0  0 #>  47:  59.83611 47.78844 -0.81616062  0.30756662  1.592913754  0  1  0  0  0 #>  48:  41.62513 62.90159 -0.43610692 -1.10689447  0.045010598  0  0  1  0  0 #>  49:  21.05833 63.27526  0.90470503  0.34765365 -0.715128401  0  0  0  0  0 #>  50:  77.53684 58.47746 -0.76308626 -0.87326454  0.865223100  1  0  0  1  1 #>  51:  43.69637 56.46216 -0.34106698  0.07730312  1.074440958  0  1  1  0  1 #>  52:  32.60875 69.85786  1.50242453 -0.29686864  1.895654774  0  0  0  0  1 #>  53:  74.92923 59.55001  0.52830771 -1.18324224 -0.602997304  0  0  0  1  0 #>  54:  59.82207 59.92991  0.54219136  0.01129269 -0.390867821  0  1  0  0  1 #>  55:  51.00557 54.38272 -0.13667336  0.99160104 -0.416222032  0  0  0  1  0 #>  56:  57.33078 53.27935 -1.13673385  1.59396745 -0.375657423  0  0  0  0  0 #>  57:  53.61028 52.38422 -1.49662715 -1.37271127 -0.366630946  0  0  0  1  0 #>  58:  74.94988 57.89016 -0.22338564 -0.24961093 -0.295677453  0  0  1  0  0 #>  59:  70.91491 66.80462  2.00171923  1.15942453  1.441820410  0  1  0  1  0 #>  60:  34.10054 68.76897  0.22170382 -1.11422235 -0.697538292  0  1  0  0  1 #>  61:  65.30098 67.84182  0.16437291 -2.52850069 -0.388167506  0  0  0  0  1 #>  62:  70.90220 66.48378  0.33262361 -0.93590256  0.652536452  0  0  0  0  0 #>  63:  70.02391 58.81202 -0.38520800 -0.96723946  1.124772447  0  0  0  1  0 #>  64:  23.63524 53.87925 -1.39875403  0.04748859 -0.772110803  0  0  0  0  1 #>  65:  56.46964 58.36094  2.67574080 -0.40373679 -0.508086216  0  1  0  0  1 #>  66:  89.69450 47.93775 -0.42368609  0.23149613  0.523620590  0  0  1  1  0 #>  67:  71.95192 58.43104 -0.29860151 -0.42237241  1.017754227  1  0  1  0  0 #>  68:  34.36086 68.29939 -1.79234173  0.37411839 -0.251164588  0  0  0  1  1 #>  69:  35.04497 60.65477 -0.24800823 -0.36600577 -1.429993447  0  0  0  1  1 #>  70:  67.36664 65.47944 -0.24730392  1.19010145  1.709121032  0  1  0  0  0 #>  71:  57.38917 62.44670 -0.25551038 -0.73732753  1.435069572  0  0  0  0  0 #>  72:  74.41936 56.10545 -1.78693810  0.29066665 -0.710371146  0  0  1  0  0 #>  73:  64.40740 68.71780  1.78466282 -0.88484957 -0.065067574  0  0  1  1  0 #>  74:  61.21499 59.60806  1.76358635  0.20800648 -1.759468735  0  0  0  0  0 #>  75:  62.75493 55.12223  0.68960022 -0.04773017  0.569722972  0  1  0  0  0 #>  76:  62.49383 60.35330 -1.10074064 -1.68452065  1.612346798  0  0  0  0  0 #>  77:  40.95601 52.40700  0.71450936 -0.14422656 -1.637280647  0  0  1  0  0 #>  78:  95.24240 64.31890 -0.24647032  1.18021367 -0.779568513  0  0  0  1  0 #>  79:  38.81992 62.50784 -0.31978617  0.68139992 -0.641176934  0  1  0  0  0 #>  80:  59.74558 58.22609  1.36264429  0.14324763 -0.681131394  0  0  0  0  1 #>  81:  51.83521 57.55786 -1.22788259 -1.19231644 -2.033285596  0  0  1  0  0 #>  82:  87.00169 64.68147 -0.51121923  1.16922865  0.500963559  0  1  0  0  1 #>  83:  75.17160 54.68796 -0.73119500  0.07920171 -1.531798140  0  0  1  1  1 #>  84:  51.54425 55.08090  0.01975201 -0.45177375 -0.024997639  0  0  1  1  0 #>  85:  63.08131 62.12124 -1.57286391  1.64202821  0.592984721  0  0  0  0  0 #>  86:  77.48193 57.74343 -0.70333327 -0.76959232 -0.198195421  0  0  0  0  0 #>  87:  93.54484 64.62542  0.71593209  0.30336096  0.892008392  0  0  0  1  0 #>  88:  64.53398 59.00690  0.46521491  1.28173742 -0.025715071  0  0  0  1  0 #>  89:  44.36240 65.97426 -0.97390231  0.60222280 -0.647660451  0  1  1  0  0 #>  90:  45.24687 62.47772  0.55921773 -0.30702226  0.646359415  1  0  0  1  0 #>  91:  90.08578 48.77424 -2.43263975 -0.41841810 -0.433832740  0  0  0  0  0 #>  92:  28.94143 53.32314 -0.34048493  0.35513553  1.772611185  0  0  1  0  0 #>  93: 105.83614 66.41388  0.71303319  0.51348111 -0.018259711  0  0  0  1  1 #>  94:  56.07974 63.45398 -0.65903739  0.01860740  0.852814994  0  0  0  0  0 #>  95:  53.18410 55.16469 -0.03640262  1.31844897  0.205162903  0  1  0  0  1 #>  96:  62.36341 53.27103 -1.59328630 -0.06583200 -3.008048599  0  0  0  0  1 #>  97:  74.00083 65.16833  0.84779280 -0.70029608 -1.366111931  0  0  0  1  0 #>  98:  64.54242 55.94112 -1.85038885  0.53732613 -0.424102260  0  0  0  0  0 #>  99:  30.65775 69.00863 -0.32365063 -2.20178232  0.236803664  1  0  1  0  0 #> 100:  65.30305 68.85771 -0.25524811  0.39197374 -2.342723120  0  0  0  0  1 #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>      eventtime1 eventtime2   censtime       time event #>   1:  6.2835117  6.5080075 11.5156754  6.2835117     1 #>   2:  2.2341745 10.2016103  9.9424766  2.2341745     1 #>   3:  5.4227648 11.4384015  7.4640840  5.4227648     1 #>   4: 14.4463659  0.8569032  3.1029354  0.8569032     2 #>   5:  5.0566209  6.7565221 12.6533135  5.0566209     1 #>   6:  4.9180272 12.4317594  3.2733982  3.2733982     0 #>   7: 21.7373883 14.3005616  2.3856664  2.3856664     0 #>   8:  6.8654215  8.5900969  6.4366715  6.4366715     0 #>   9:  3.6545169  2.8100287  6.8076628  2.8100287     2 #>  10: 11.3187530  7.1616535 16.6855449  7.1616535     2 #>  11:  4.9578732  1.5529912 12.5698152  1.5529912     2 #>  12: 12.6136920  5.5880073 13.1685721  5.5880073     2 #>  13: 12.2705325 10.1527570  6.1268894  6.1268894     0 #>  14: 11.7160646  9.1681445  9.7818335  9.1681445     2 #>  15: 13.3093289 13.8170712  5.1143986  5.1143986     0 #>  16:  2.8558834 20.8251202  8.3531989  2.8558834     1 #>  17: 10.3116570  5.7851651  5.7603574  5.7603574     0 #>  18: 15.6965602 15.0706310  0.9014898  0.9014898     0 #>  19:  9.8658157  8.9821989  9.8361143  8.9821989     2 #>  20:  7.8103363  6.6792906  5.0173907  5.0173907     0 #>  21:  4.9754291  0.9052550  2.5985392  0.9052550     2 #>  22: 10.6698406  8.3785386 12.4518953  8.3785386     2 #>  23:  4.2034654  8.5143906  6.5437848  4.2034654     1 #>  24:  0.3912398 13.2359741 14.4048971  0.3912398     1 #>  25: 12.4273308  5.3035339 11.4877347  5.3035339     2 #>  26:  9.2460530  8.8875661  9.7551134  8.8875661     2 #>  27: 10.0175198  8.1917854 20.7682985  8.1917854     2 #>  28:  1.8716231 12.5395636  9.8046907  1.8716231     1 #>  29:  6.7783389 12.1471281  3.7365423  3.7365423     0 #>  30:  1.7361957  7.1972075 10.3816363  1.7361957     1 #>  31:  2.9051934  7.4404807  8.5419258  2.9051934     1 #>  32: 16.8423205 16.0097286  7.1522689  7.1522689     0 #>  33:  8.5958827 18.2676768  8.4032656  8.4032656     0 #>  34:  6.0094763  6.6477715 12.9647190  6.0094763     1 #>  35: 17.6307100  2.7214120  4.3531514  2.7214120     2 #>  36:  5.2781104  7.1694490  6.3464056  5.2781104     1 #>  37:  7.2443077  7.6040207  4.7996851  4.7996851     0 #>  38:  8.2040793  8.0149945 14.9202754  8.0149945     2 #>  39:  8.9036096  1.2254374  5.6865034  1.2254374     2 #>  40: 19.1566811  8.2339490  9.4259990  8.2339490     2 #>  41:  0.7256035  6.1771413  4.4418193  0.7256035     1 #>  42:  1.1343471  7.1292371  6.5978478  1.1343471     1 #>  43:  2.4818625 11.9659573  4.9468016  2.4818625     1 #>  44:  9.2433390 11.6368070  7.6963083  7.6963083     0 #>  45: 11.4974289  5.6183353  7.9712452  5.6183353     2 #>  46: 15.8702088  8.9039935  4.8635127  4.8635127     0 #>  47: 10.7024090 13.1994135 19.3854679 10.7024090     1 #>  48:  3.3465424  5.4045730  8.6009103  3.3465424     1 #>  49: 10.8718263 15.0130365  5.5816328  5.5816328     0 #>  50:  3.5098271  3.8151275  6.0589827  3.5098271     1 #>  51:  7.5771125  6.9764637  8.5961656  6.9764637     2 #>  52:  7.1823229  7.6478994  3.8654561  3.8654561     0 #>  53:  7.4972585 10.5469171  9.0846832  7.4972585     1 #>  54: 12.5460292  8.8970390 11.8630723  8.8970390     2 #>  55:  4.4530482  8.3202501 16.2776107  4.4530482     1 #>  56: 18.1829154 13.0766848 15.1918985 13.0766848     2 #>  57:  6.8488799  7.9722989 10.7291826  6.8488799     1 #>  58:  9.1428227 16.0829018  8.1028164  8.1028164     0 #>  59: 10.3188714 11.3181822  6.4224766  6.4224766     0 #>  60:  5.1499748 12.4413617  9.4834562  5.1499748     1 #>  61: 13.2357625 11.2071474  3.0191937  3.0191937     0 #>  62:  8.4072725  3.3290603 11.0703455  3.3290603     2 #>  63:  5.5218756  8.9828104  8.8236154  5.5218756     1 #>  64:  8.1938006  4.9847842 10.4949142  4.9847842     2 #>  65:  8.7705630  3.5655318  6.5532025  3.5655318     2 #>  66:  7.2883367  9.4021645 11.6392897  7.2883367     1 #>  67:  2.7472424 16.5887588  8.5848967  2.7472424     1 #>  68:  6.5057331 10.4506967  5.1591435  5.1591435     0 #>  69:  3.8063188  5.6863212 15.7289648  3.8063188     1 #>  70:  9.7735032 10.4204035  3.6491674  3.6491674     0 #>  71:  2.0174490  6.7924836 10.3997117  2.0174490     1 #>  72:  9.8248568  4.1667978  4.1835375  4.1667978     2 #>  73: 13.3095367  3.9412067 10.2924392  3.9412067     2 #>  74: 12.0943064  9.6857073 10.4751533  9.6857073     2 #>  75:  2.3043659  9.8299805  8.6116188  2.3043659     1 #>  76: 15.7569380  3.3231612  3.3773780  3.3231612     2 #>  77: 12.8251201  6.6299801  3.8182415  3.8182415     0 #>  78: 16.1069493  5.4740161  9.7037897  5.4740161     2 #>  79:  7.2066603  7.0853750  5.0189867  5.0189867     0 #>  80: 12.3822634  3.1928412  2.0044564  2.0044564     0 #>  81:  7.2873177 11.0683954  9.1279371  7.2873177     1 #>  82: 12.3448375 12.8612633  5.8219822  5.8219822     0 #>  83:  9.6914349  3.4717358  9.5723812  3.4717358     2 #>  84: 10.2753258  8.2854717 10.5964482  8.2854717     2 #>  85:  2.9179562  3.6219149  5.2751958  2.9179562     1 #>  86: 14.7949557 12.9034272 12.6335523 12.6335523     0 #>  87: 11.6901039  5.2624704  5.8387701  5.2624704     2 #>  88: 12.9563074  5.6769274 14.5129689  5.6769274     2 #>  89:  5.5090254  2.4066712 11.8511819  2.4066712     2 #>  90:  0.9690222  7.7596721 13.9383800  0.9690222     1 #>  91:  8.3891580  5.8312706 11.9526635  5.8312706     2 #>  92:  6.6220447  9.7181270 16.8265585  6.6220447     1 #>  93: 13.1848154 15.1455991  6.6537063  6.6537063     0 #>  94:  7.1122919  2.7472876  3.6343076  2.7472876     2 #>  95:  3.5078609 11.2315946  4.9985375  3.5078609     1 #>  96:  8.4434745  7.2571465  4.7593402  4.7593402     0 #>  97: 19.9907424 14.8458817  8.8704839  8.8704839     0 #>  98: 13.1079695  4.1683325  9.4413615  4.1683325     2 #>  99:  4.0399870 10.7042893  4.5787251  4.0399870     1 #> 100: 11.3307878  4.9478527  7.0896903  4.9478527     2 #>      eventtime1 eventtime2   censtime       time event d[,X3:=as.numeric(as.character(X3))] #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>   1:  38.17963 60.30461  0.49696095  0.96169663  1.473881181  0  0  0  1  0 #>   2:  47.31519 55.88254 -0.22487472 -0.60442573  0.677268492  1  0  0  0  0 #>   3:  41.24281 69.14865 -1.11714317 -0.75287728  0.379962687  0  0  1  0  1 #>   4:  70.00932 52.85042 -0.39499460 -1.55561159 -0.192798426  0  0  1  0  0 #>   5:  40.63845 61.27069  1.54983034 -1.45389374  1.577891795  1  0  1  0  0 #>   6:  29.47495 45.30113 -0.74351448  0.05633184  0.596234109  1  1  1  1  1 #>   7:  90.32020 60.01208 -2.33171212  0.50936941 -1.173576941  0  0  0  0  1 #>   8:  75.08960 62.54833  0.81224544 -2.09788296 -0.155642535  0  1  1  1  0 #>   9:  72.25685 54.57640 -0.50131066 -1.00436198 -1.918909820  1  0  0  0  0 #>  10:  50.04018 63.52416 -0.51088657  0.53577172 -0.195258846  0  0  1  0  1 #>  11:  59.83078 61.65488 -1.21536404 -0.45303708 -2.592327670  1  1  1  0  1 #>  12:  69.29516 64.88164 -0.02255863  2.16536850  1.314002167  0  0  0  0  0 #>  13:  40.78142 55.78330  0.70123930  1.24574667 -0.635543001  0  0  1  1  1 #>  14:  58.13608 55.14710 -0.58748203  0.59549803 -0.429978839  0  0  1  1  1 #>  15:  62.63612 51.14234 -0.60672794  0.00488445 -0.169318332  0  0  1  0  1 #>  16:  85.39161 58.38765  1.09664022  0.27936078  0.612218174  0  0  0  0  0 #>  17:  69.63199 53.30600 -0.24750968 -0.70590613  0.678340177  0  0  0  0  1 #>  18:  79.23350 63.44078 -0.15990171  0.62801715  0.567951972  0  0  0  0  1 #>  19:  62.10820 60.35640 -0.62577825  1.48021396 -0.572542604  0  0  0  1  1 #>  20:  43.31246 70.94876  0.90043464  1.08342991 -1.363291256  0  0  1  1  0 #>  21:  54.90485 54.21146 -0.99419363 -0.81324426 -0.388722244  0  1  0  1  0 #>  22:  35.02853 65.90844  0.84925039 -1.61887685  0.277914132  0  0  0  0  0 #>  23:  73.93278 57.36316  0.80570229 -0.10965570 -0.823081122  0  0  0  0  0 #>  24:  81.25240 52.71686 -0.46760094  0.44088937 -0.068840934  0  0  0  1  1 #>  25:  59.05919 62.86484  0.84842031  1.35099398 -1.167662326  0  0  0  1  1 #>  26:  45.28646 52.83311  0.98676986 -1.31860948 -0.008309014  0  1  0  1  1 #>  27:  76.30725 54.72407  0.57562029  0.36438459  0.128855402  0  1  0  1  0 #>  28:  62.08991 56.33444  2.02484205  0.23349984 -0.145875628  0  0  1  1  0 #>  29:  54.20592 61.05454 -1.96235319  1.19395526 -0.163910957  0  1  1  0  0 #>  30:  76.85378 55.00540 -1.16492093 -0.02790997  1.763552003  1  1  1  1  1 #>  31:  48.60232 65.38925 -1.37651921 -0.35729885  0.762586512  0  0  1  1  0 #>  32:  77.23439 54.00513  0.16767993 -1.14681414  1.111431081  0  0  0  0  0 #>  33:  47.36286 61.08319  1.58462908 -0.51742048 -0.923206953  0  0  0  0  0 #>  34:  65.87120 60.71544  1.67788895 -0.36212377  0.164341838  0  0  0  1  1 #>  35:  73.37066 54.67125  0.48829670  2.35055433  1.154825187  0  0  0  0  0 #>  36:  39.97112 57.85688  0.87867326  2.44653138 -0.056521425  0  0  1  0  1 #>  37:  65.97185 56.71910 -0.14487487 -0.16670328 -2.129360648  0  0  1  0  1 #>  38:  58.32620 64.79697  0.46897176 -1.04366744  0.344845762  0  0  0  0  1 #>  39:  70.13616 67.78026  0.37623548 -1.97293493 -1.904955446  0  0  0  0  0 #>  40:  48.17103 54.79602 -0.76104028  0.51467163 -0.811170153  0  0  1  1  0 #>  41:  58.69520 64.65286 -0.29329493 -1.09057358  1.324004321  1  0  0  1  0 #>  42:  80.73426 59.62277 -0.13484126  2.28465933  0.615636849  0  1  0  0  1 #>  43:  62.52735 50.16402  1.39384582 -0.88561757  1.091668956  1  0  0  0  1 #>  44:  72.34786 56.22048 -1.03698869  0.11110643  0.306604862  0  0  0  0  0 #>  45:  56.68658 62.30575 -2.11433515  3.81027668 -0.110158762  0  0  0  1  0 #>  46:  44.55913 60.72553  0.76827822 -1.10891000 -0.924312773  0  0  0  0  0 #>  47:  59.83611 47.78844 -0.81616062  0.30756662  1.592913754  0  1  0  0  0 #>  48:  41.62513 62.90159 -0.43610692 -1.10689447  0.045010598  0  0  1  0  0 #>  49:  21.05833 63.27526  0.90470503  0.34765365 -0.715128401  0  0  0  0  0 #>  50:  77.53684 58.47746 -0.76308626 -0.87326454  0.865223100  1  0  0  1  1 #>  51:  43.69637 56.46216 -0.34106698  0.07730312  1.074440958  0  1  1  0  1 #>  52:  32.60875 69.85786  1.50242453 -0.29686864  1.895654774  0  0  0  0  1 #>  53:  74.92923 59.55001  0.52830771 -1.18324224 -0.602997304  0  0  0  1  0 #>  54:  59.82207 59.92991  0.54219136  0.01129269 -0.390867821  0  1  0  0  1 #>  55:  51.00557 54.38272 -0.13667336  0.99160104 -0.416222032  0  0  0  1  0 #>  56:  57.33078 53.27935 -1.13673385  1.59396745 -0.375657423  0  0  0  0  0 #>  57:  53.61028 52.38422 -1.49662715 -1.37271127 -0.366630946  0  0  0  1  0 #>  58:  74.94988 57.89016 -0.22338564 -0.24961093 -0.295677453  0  0  1  0  0 #>  59:  70.91491 66.80462  2.00171923  1.15942453  1.441820410  0  1  0  1  0 #>  60:  34.10054 68.76897  0.22170382 -1.11422235 -0.697538292  0  1  0  0  1 #>  61:  65.30098 67.84182  0.16437291 -2.52850069 -0.388167506  0  0  0  0  1 #>  62:  70.90220 66.48378  0.33262361 -0.93590256  0.652536452  0  0  0  0  0 #>  63:  70.02391 58.81202 -0.38520800 -0.96723946  1.124772447  0  0  0  1  0 #>  64:  23.63524 53.87925 -1.39875403  0.04748859 -0.772110803  0  0  0  0  1 #>  65:  56.46964 58.36094  2.67574080 -0.40373679 -0.508086216  0  1  0  0  1 #>  66:  89.69450 47.93775 -0.42368609  0.23149613  0.523620590  0  0  1  1  0 #>  67:  71.95192 58.43104 -0.29860151 -0.42237241  1.017754227  1  0  1  0  0 #>  68:  34.36086 68.29939 -1.79234173  0.37411839 -0.251164588  0  0  0  1  1 #>  69:  35.04497 60.65477 -0.24800823 -0.36600577 -1.429993447  0  0  0  1  1 #>  70:  67.36664 65.47944 -0.24730392  1.19010145  1.709121032  0  1  0  0  0 #>  71:  57.38917 62.44670 -0.25551038 -0.73732753  1.435069572  0  0  0  0  0 #>  72:  74.41936 56.10545 -1.78693810  0.29066665 -0.710371146  0  0  1  0  0 #>  73:  64.40740 68.71780  1.78466282 -0.88484957 -0.065067574  0  0  1  1  0 #>  74:  61.21499 59.60806  1.76358635  0.20800648 -1.759468735  0  0  0  0  0 #>  75:  62.75493 55.12223  0.68960022 -0.04773017  0.569722972  0  1  0  0  0 #>  76:  62.49383 60.35330 -1.10074064 -1.68452065  1.612346798  0  0  0  0  0 #>  77:  40.95601 52.40700  0.71450936 -0.14422656 -1.637280647  0  0  1  0  0 #>  78:  95.24240 64.31890 -0.24647032  1.18021367 -0.779568513  0  0  0  1  0 #>  79:  38.81992 62.50784 -0.31978617  0.68139992 -0.641176934  0  1  0  0  0 #>  80:  59.74558 58.22609  1.36264429  0.14324763 -0.681131394  0  0  0  0  1 #>  81:  51.83521 57.55786 -1.22788259 -1.19231644 -2.033285596  0  0  1  0  0 #>  82:  87.00169 64.68147 -0.51121923  1.16922865  0.500963559  0  1  0  0  1 #>  83:  75.17160 54.68796 -0.73119500  0.07920171 -1.531798140  0  0  1  1  1 #>  84:  51.54425 55.08090  0.01975201 -0.45177375 -0.024997639  0  0  1  1  0 #>  85:  63.08131 62.12124 -1.57286391  1.64202821  0.592984721  0  0  0  0  0 #>  86:  77.48193 57.74343 -0.70333327 -0.76959232 -0.198195421  0  0  0  0  0 #>  87:  93.54484 64.62542  0.71593209  0.30336096  0.892008392  0  0  0  1  0 #>  88:  64.53398 59.00690  0.46521491  1.28173742 -0.025715071  0  0  0  1  0 #>  89:  44.36240 65.97426 -0.97390231  0.60222280 -0.647660451  0  1  1  0  0 #>  90:  45.24687 62.47772  0.55921773 -0.30702226  0.646359415  1  0  0  1  0 #>  91:  90.08578 48.77424 -2.43263975 -0.41841810 -0.433832740  0  0  0  0  0 #>  92:  28.94143 53.32314 -0.34048493  0.35513553  1.772611185  0  0  1  0  0 #>  93: 105.83614 66.41388  0.71303319  0.51348111 -0.018259711  0  0  0  1  1 #>  94:  56.07974 63.45398 -0.65903739  0.01860740  0.852814994  0  0  0  0  0 #>  95:  53.18410 55.16469 -0.03640262  1.31844897  0.205162903  0  1  0  0  1 #>  96:  62.36341 53.27103 -1.59328630 -0.06583200 -3.008048599  0  0  0  0  1 #>  97:  74.00083 65.16833  0.84779280 -0.70029608 -1.366111931  0  0  0  1  0 #>  98:  64.54242 55.94112 -1.85038885  0.53732613 -0.424102260  0  0  0  0  0 #>  99:  30.65775 69.00863 -0.32365063 -2.20178232  0.236803664  1  0  1  0  0 #> 100:  65.30305 68.85771 -0.25524811  0.39197374 -2.342723120  0  0  0  0  1 #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>      eventtime1 eventtime2   censtime       time event #>   1:  6.2835117  6.5080075 11.5156754  6.2835117     1 #>   2:  2.2341745 10.2016103  9.9424766  2.2341745     1 #>   3:  5.4227648 11.4384015  7.4640840  5.4227648     1 #>   4: 14.4463659  0.8569032  3.1029354  0.8569032     2 #>   5:  5.0566209  6.7565221 12.6533135  5.0566209     1 #>   6:  4.9180272 12.4317594  3.2733982  3.2733982     0 #>   7: 21.7373883 14.3005616  2.3856664  2.3856664     0 #>   8:  6.8654215  8.5900969  6.4366715  6.4366715     0 #>   9:  3.6545169  2.8100287  6.8076628  2.8100287     2 #>  10: 11.3187530  7.1616535 16.6855449  7.1616535     2 #>  11:  4.9578732  1.5529912 12.5698152  1.5529912     2 #>  12: 12.6136920  5.5880073 13.1685721  5.5880073     2 #>  13: 12.2705325 10.1527570  6.1268894  6.1268894     0 #>  14: 11.7160646  9.1681445  9.7818335  9.1681445     2 #>  15: 13.3093289 13.8170712  5.1143986  5.1143986     0 #>  16:  2.8558834 20.8251202  8.3531989  2.8558834     1 #>  17: 10.3116570  5.7851651  5.7603574  5.7603574     0 #>  18: 15.6965602 15.0706310  0.9014898  0.9014898     0 #>  19:  9.8658157  8.9821989  9.8361143  8.9821989     2 #>  20:  7.8103363  6.6792906  5.0173907  5.0173907     0 #>  21:  4.9754291  0.9052550  2.5985392  0.9052550     2 #>  22: 10.6698406  8.3785386 12.4518953  8.3785386     2 #>  23:  4.2034654  8.5143906  6.5437848  4.2034654     1 #>  24:  0.3912398 13.2359741 14.4048971  0.3912398     1 #>  25: 12.4273308  5.3035339 11.4877347  5.3035339     2 #>  26:  9.2460530  8.8875661  9.7551134  8.8875661     2 #>  27: 10.0175198  8.1917854 20.7682985  8.1917854     2 #>  28:  1.8716231 12.5395636  9.8046907  1.8716231     1 #>  29:  6.7783389 12.1471281  3.7365423  3.7365423     0 #>  30:  1.7361957  7.1972075 10.3816363  1.7361957     1 #>  31:  2.9051934  7.4404807  8.5419258  2.9051934     1 #>  32: 16.8423205 16.0097286  7.1522689  7.1522689     0 #>  33:  8.5958827 18.2676768  8.4032656  8.4032656     0 #>  34:  6.0094763  6.6477715 12.9647190  6.0094763     1 #>  35: 17.6307100  2.7214120  4.3531514  2.7214120     2 #>  36:  5.2781104  7.1694490  6.3464056  5.2781104     1 #>  37:  7.2443077  7.6040207  4.7996851  4.7996851     0 #>  38:  8.2040793  8.0149945 14.9202754  8.0149945     2 #>  39:  8.9036096  1.2254374  5.6865034  1.2254374     2 #>  40: 19.1566811  8.2339490  9.4259990  8.2339490     2 #>  41:  0.7256035  6.1771413  4.4418193  0.7256035     1 #>  42:  1.1343471  7.1292371  6.5978478  1.1343471     1 #>  43:  2.4818625 11.9659573  4.9468016  2.4818625     1 #>  44:  9.2433390 11.6368070  7.6963083  7.6963083     0 #>  45: 11.4974289  5.6183353  7.9712452  5.6183353     2 #>  46: 15.8702088  8.9039935  4.8635127  4.8635127     0 #>  47: 10.7024090 13.1994135 19.3854679 10.7024090     1 #>  48:  3.3465424  5.4045730  8.6009103  3.3465424     1 #>  49: 10.8718263 15.0130365  5.5816328  5.5816328     0 #>  50:  3.5098271  3.8151275  6.0589827  3.5098271     1 #>  51:  7.5771125  6.9764637  8.5961656  6.9764637     2 #>  52:  7.1823229  7.6478994  3.8654561  3.8654561     0 #>  53:  7.4972585 10.5469171  9.0846832  7.4972585     1 #>  54: 12.5460292  8.8970390 11.8630723  8.8970390     2 #>  55:  4.4530482  8.3202501 16.2776107  4.4530482     1 #>  56: 18.1829154 13.0766848 15.1918985 13.0766848     2 #>  57:  6.8488799  7.9722989 10.7291826  6.8488799     1 #>  58:  9.1428227 16.0829018  8.1028164  8.1028164     0 #>  59: 10.3188714 11.3181822  6.4224766  6.4224766     0 #>  60:  5.1499748 12.4413617  9.4834562  5.1499748     1 #>  61: 13.2357625 11.2071474  3.0191937  3.0191937     0 #>  62:  8.4072725  3.3290603 11.0703455  3.3290603     2 #>  63:  5.5218756  8.9828104  8.8236154  5.5218756     1 #>  64:  8.1938006  4.9847842 10.4949142  4.9847842     2 #>  65:  8.7705630  3.5655318  6.5532025  3.5655318     2 #>  66:  7.2883367  9.4021645 11.6392897  7.2883367     1 #>  67:  2.7472424 16.5887588  8.5848967  2.7472424     1 #>  68:  6.5057331 10.4506967  5.1591435  5.1591435     0 #>  69:  3.8063188  5.6863212 15.7289648  3.8063188     1 #>  70:  9.7735032 10.4204035  3.6491674  3.6491674     0 #>  71:  2.0174490  6.7924836 10.3997117  2.0174490     1 #>  72:  9.8248568  4.1667978  4.1835375  4.1667978     2 #>  73: 13.3095367  3.9412067 10.2924392  3.9412067     2 #>  74: 12.0943064  9.6857073 10.4751533  9.6857073     2 #>  75:  2.3043659  9.8299805  8.6116188  2.3043659     1 #>  76: 15.7569380  3.3231612  3.3773780  3.3231612     2 #>  77: 12.8251201  6.6299801  3.8182415  3.8182415     0 #>  78: 16.1069493  5.4740161  9.7037897  5.4740161     2 #>  79:  7.2066603  7.0853750  5.0189867  5.0189867     0 #>  80: 12.3822634  3.1928412  2.0044564  2.0044564     0 #>  81:  7.2873177 11.0683954  9.1279371  7.2873177     1 #>  82: 12.3448375 12.8612633  5.8219822  5.8219822     0 #>  83:  9.6914349  3.4717358  9.5723812  3.4717358     2 #>  84: 10.2753258  8.2854717 10.5964482  8.2854717     2 #>  85:  2.9179562  3.6219149  5.2751958  2.9179562     1 #>  86: 14.7949557 12.9034272 12.6335523 12.6335523     0 #>  87: 11.6901039  5.2624704  5.8387701  5.2624704     2 #>  88: 12.9563074  5.6769274 14.5129689  5.6769274     2 #>  89:  5.5090254  2.4066712 11.8511819  2.4066712     2 #>  90:  0.9690222  7.7596721 13.9383800  0.9690222     1 #>  91:  8.3891580  5.8312706 11.9526635  5.8312706     2 #>  92:  6.6220447  9.7181270 16.8265585  6.6220447     1 #>  93: 13.1848154 15.1455991  6.6537063  6.6537063     0 #>  94:  7.1122919  2.7472876  3.6343076  2.7472876     2 #>  95:  3.5078609 11.2315946  4.9985375  3.5078609     1 #>  96:  8.4434745  7.2571465  4.7593402  4.7593402     0 #>  97: 19.9907424 14.8458817  8.8704839  8.8704839     0 #>  98: 13.1079695  4.1683325  9.4413615  4.1683325     2 #>  99:  4.0399870 10.7042893  4.5787251  4.0399870     1 #> 100: 11.3307878  4.9478527  7.0896903  4.9478527     2 #>      eventtime1 eventtime2   censtime       time event d[,X4:=as.numeric(as.character(X4))] #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>   1:  38.17963 60.30461  0.49696095  0.96169663  1.473881181  0  0  0  1  0 #>   2:  47.31519 55.88254 -0.22487472 -0.60442573  0.677268492  1  0  0  0  0 #>   3:  41.24281 69.14865 -1.11714317 -0.75287728  0.379962687  0  0  1  0  1 #>   4:  70.00932 52.85042 -0.39499460 -1.55561159 -0.192798426  0  0  1  0  0 #>   5:  40.63845 61.27069  1.54983034 -1.45389374  1.577891795  1  0  1  0  0 #>   6:  29.47495 45.30113 -0.74351448  0.05633184  0.596234109  1  1  1  1  1 #>   7:  90.32020 60.01208 -2.33171212  0.50936941 -1.173576941  0  0  0  0  1 #>   8:  75.08960 62.54833  0.81224544 -2.09788296 -0.155642535  0  1  1  1  0 #>   9:  72.25685 54.57640 -0.50131066 -1.00436198 -1.918909820  1  0  0  0  0 #>  10:  50.04018 63.52416 -0.51088657  0.53577172 -0.195258846  0  0  1  0  1 #>  11:  59.83078 61.65488 -1.21536404 -0.45303708 -2.592327670  1  1  1  0  1 #>  12:  69.29516 64.88164 -0.02255863  2.16536850  1.314002167  0  0  0  0  0 #>  13:  40.78142 55.78330  0.70123930  1.24574667 -0.635543001  0  0  1  1  1 #>  14:  58.13608 55.14710 -0.58748203  0.59549803 -0.429978839  0  0  1  1  1 #>  15:  62.63612 51.14234 -0.60672794  0.00488445 -0.169318332  0  0  1  0  1 #>  16:  85.39161 58.38765  1.09664022  0.27936078  0.612218174  0  0  0  0  0 #>  17:  69.63199 53.30600 -0.24750968 -0.70590613  0.678340177  0  0  0  0  1 #>  18:  79.23350 63.44078 -0.15990171  0.62801715  0.567951972  0  0  0  0  1 #>  19:  62.10820 60.35640 -0.62577825  1.48021396 -0.572542604  0  0  0  1  1 #>  20:  43.31246 70.94876  0.90043464  1.08342991 -1.363291256  0  0  1  1  0 #>  21:  54.90485 54.21146 -0.99419363 -0.81324426 -0.388722244  0  1  0  1  0 #>  22:  35.02853 65.90844  0.84925039 -1.61887685  0.277914132  0  0  0  0  0 #>  23:  73.93278 57.36316  0.80570229 -0.10965570 -0.823081122  0  0  0  0  0 #>  24:  81.25240 52.71686 -0.46760094  0.44088937 -0.068840934  0  0  0  1  1 #>  25:  59.05919 62.86484  0.84842031  1.35099398 -1.167662326  0  0  0  1  1 #>  26:  45.28646 52.83311  0.98676986 -1.31860948 -0.008309014  0  1  0  1  1 #>  27:  76.30725 54.72407  0.57562029  0.36438459  0.128855402  0  1  0  1  0 #>  28:  62.08991 56.33444  2.02484205  0.23349984 -0.145875628  0  0  1  1  0 #>  29:  54.20592 61.05454 -1.96235319  1.19395526 -0.163910957  0  1  1  0  0 #>  30:  76.85378 55.00540 -1.16492093 -0.02790997  1.763552003  1  1  1  1  1 #>  31:  48.60232 65.38925 -1.37651921 -0.35729885  0.762586512  0  0  1  1  0 #>  32:  77.23439 54.00513  0.16767993 -1.14681414  1.111431081  0  0  0  0  0 #>  33:  47.36286 61.08319  1.58462908 -0.51742048 -0.923206953  0  0  0  0  0 #>  34:  65.87120 60.71544  1.67788895 -0.36212377  0.164341838  0  0  0  1  1 #>  35:  73.37066 54.67125  0.48829670  2.35055433  1.154825187  0  0  0  0  0 #>  36:  39.97112 57.85688  0.87867326  2.44653138 -0.056521425  0  0  1  0  1 #>  37:  65.97185 56.71910 -0.14487487 -0.16670328 -2.129360648  0  0  1  0  1 #>  38:  58.32620 64.79697  0.46897176 -1.04366744  0.344845762  0  0  0  0  1 #>  39:  70.13616 67.78026  0.37623548 -1.97293493 -1.904955446  0  0  0  0  0 #>  40:  48.17103 54.79602 -0.76104028  0.51467163 -0.811170153  0  0  1  1  0 #>  41:  58.69520 64.65286 -0.29329493 -1.09057358  1.324004321  1  0  0  1  0 #>  42:  80.73426 59.62277 -0.13484126  2.28465933  0.615636849  0  1  0  0  1 #>  43:  62.52735 50.16402  1.39384582 -0.88561757  1.091668956  1  0  0  0  1 #>  44:  72.34786 56.22048 -1.03698869  0.11110643  0.306604862  0  0  0  0  0 #>  45:  56.68658 62.30575 -2.11433515  3.81027668 -0.110158762  0  0  0  1  0 #>  46:  44.55913 60.72553  0.76827822 -1.10891000 -0.924312773  0  0  0  0  0 #>  47:  59.83611 47.78844 -0.81616062  0.30756662  1.592913754  0  1  0  0  0 #>  48:  41.62513 62.90159 -0.43610692 -1.10689447  0.045010598  0  0  1  0  0 #>  49:  21.05833 63.27526  0.90470503  0.34765365 -0.715128401  0  0  0  0  0 #>  50:  77.53684 58.47746 -0.76308626 -0.87326454  0.865223100  1  0  0  1  1 #>  51:  43.69637 56.46216 -0.34106698  0.07730312  1.074440958  0  1  1  0  1 #>  52:  32.60875 69.85786  1.50242453 -0.29686864  1.895654774  0  0  0  0  1 #>  53:  74.92923 59.55001  0.52830771 -1.18324224 -0.602997304  0  0  0  1  0 #>  54:  59.82207 59.92991  0.54219136  0.01129269 -0.390867821  0  1  0  0  1 #>  55:  51.00557 54.38272 -0.13667336  0.99160104 -0.416222032  0  0  0  1  0 #>  56:  57.33078 53.27935 -1.13673385  1.59396745 -0.375657423  0  0  0  0  0 #>  57:  53.61028 52.38422 -1.49662715 -1.37271127 -0.366630946  0  0  0  1  0 #>  58:  74.94988 57.89016 -0.22338564 -0.24961093 -0.295677453  0  0  1  0  0 #>  59:  70.91491 66.80462  2.00171923  1.15942453  1.441820410  0  1  0  1  0 #>  60:  34.10054 68.76897  0.22170382 -1.11422235 -0.697538292  0  1  0  0  1 #>  61:  65.30098 67.84182  0.16437291 -2.52850069 -0.388167506  0  0  0  0  1 #>  62:  70.90220 66.48378  0.33262361 -0.93590256  0.652536452  0  0  0  0  0 #>  63:  70.02391 58.81202 -0.38520800 -0.96723946  1.124772447  0  0  0  1  0 #>  64:  23.63524 53.87925 -1.39875403  0.04748859 -0.772110803  0  0  0  0  1 #>  65:  56.46964 58.36094  2.67574080 -0.40373679 -0.508086216  0  1  0  0  1 #>  66:  89.69450 47.93775 -0.42368609  0.23149613  0.523620590  0  0  1  1  0 #>  67:  71.95192 58.43104 -0.29860151 -0.42237241  1.017754227  1  0  1  0  0 #>  68:  34.36086 68.29939 -1.79234173  0.37411839 -0.251164588  0  0  0  1  1 #>  69:  35.04497 60.65477 -0.24800823 -0.36600577 -1.429993447  0  0  0  1  1 #>  70:  67.36664 65.47944 -0.24730392  1.19010145  1.709121032  0  1  0  0  0 #>  71:  57.38917 62.44670 -0.25551038 -0.73732753  1.435069572  0  0  0  0  0 #>  72:  74.41936 56.10545 -1.78693810  0.29066665 -0.710371146  0  0  1  0  0 #>  73:  64.40740 68.71780  1.78466282 -0.88484957 -0.065067574  0  0  1  1  0 #>  74:  61.21499 59.60806  1.76358635  0.20800648 -1.759468735  0  0  0  0  0 #>  75:  62.75493 55.12223  0.68960022 -0.04773017  0.569722972  0  1  0  0  0 #>  76:  62.49383 60.35330 -1.10074064 -1.68452065  1.612346798  0  0  0  0  0 #>  77:  40.95601 52.40700  0.71450936 -0.14422656 -1.637280647  0  0  1  0  0 #>  78:  95.24240 64.31890 -0.24647032  1.18021367 -0.779568513  0  0  0  1  0 #>  79:  38.81992 62.50784 -0.31978617  0.68139992 -0.641176934  0  1  0  0  0 #>  80:  59.74558 58.22609  1.36264429  0.14324763 -0.681131394  0  0  0  0  1 #>  81:  51.83521 57.55786 -1.22788259 -1.19231644 -2.033285596  0  0  1  0  0 #>  82:  87.00169 64.68147 -0.51121923  1.16922865  0.500963559  0  1  0  0  1 #>  83:  75.17160 54.68796 -0.73119500  0.07920171 -1.531798140  0  0  1  1  1 #>  84:  51.54425 55.08090  0.01975201 -0.45177375 -0.024997639  0  0  1  1  0 #>  85:  63.08131 62.12124 -1.57286391  1.64202821  0.592984721  0  0  0  0  0 #>  86:  77.48193 57.74343 -0.70333327 -0.76959232 -0.198195421  0  0  0  0  0 #>  87:  93.54484 64.62542  0.71593209  0.30336096  0.892008392  0  0  0  1  0 #>  88:  64.53398 59.00690  0.46521491  1.28173742 -0.025715071  0  0  0  1  0 #>  89:  44.36240 65.97426 -0.97390231  0.60222280 -0.647660451  0  1  1  0  0 #>  90:  45.24687 62.47772  0.55921773 -0.30702226  0.646359415  1  0  0  1  0 #>  91:  90.08578 48.77424 -2.43263975 -0.41841810 -0.433832740  0  0  0  0  0 #>  92:  28.94143 53.32314 -0.34048493  0.35513553  1.772611185  0  0  1  0  0 #>  93: 105.83614 66.41388  0.71303319  0.51348111 -0.018259711  0  0  0  1  1 #>  94:  56.07974 63.45398 -0.65903739  0.01860740  0.852814994  0  0  0  0  0 #>  95:  53.18410 55.16469 -0.03640262  1.31844897  0.205162903  0  1  0  0  1 #>  96:  62.36341 53.27103 -1.59328630 -0.06583200 -3.008048599  0  0  0  0  1 #>  97:  74.00083 65.16833  0.84779280 -0.70029608 -1.366111931  0  0  0  1  0 #>  98:  64.54242 55.94112 -1.85038885  0.53732613 -0.424102260  0  0  0  0  0 #>  99:  30.65775 69.00863 -0.32365063 -2.20178232  0.236803664  1  0  1  0  0 #> 100:  65.30305 68.85771 -0.25524811  0.39197374 -2.342723120  0  0  0  0  1 #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>      eventtime1 eventtime2   censtime       time event #>   1:  6.2835117  6.5080075 11.5156754  6.2835117     1 #>   2:  2.2341745 10.2016103  9.9424766  2.2341745     1 #>   3:  5.4227648 11.4384015  7.4640840  5.4227648     1 #>   4: 14.4463659  0.8569032  3.1029354  0.8569032     2 #>   5:  5.0566209  6.7565221 12.6533135  5.0566209     1 #>   6:  4.9180272 12.4317594  3.2733982  3.2733982     0 #>   7: 21.7373883 14.3005616  2.3856664  2.3856664     0 #>   8:  6.8654215  8.5900969  6.4366715  6.4366715     0 #>   9:  3.6545169  2.8100287  6.8076628  2.8100287     2 #>  10: 11.3187530  7.1616535 16.6855449  7.1616535     2 #>  11:  4.9578732  1.5529912 12.5698152  1.5529912     2 #>  12: 12.6136920  5.5880073 13.1685721  5.5880073     2 #>  13: 12.2705325 10.1527570  6.1268894  6.1268894     0 #>  14: 11.7160646  9.1681445  9.7818335  9.1681445     2 #>  15: 13.3093289 13.8170712  5.1143986  5.1143986     0 #>  16:  2.8558834 20.8251202  8.3531989  2.8558834     1 #>  17: 10.3116570  5.7851651  5.7603574  5.7603574     0 #>  18: 15.6965602 15.0706310  0.9014898  0.9014898     0 #>  19:  9.8658157  8.9821989  9.8361143  8.9821989     2 #>  20:  7.8103363  6.6792906  5.0173907  5.0173907     0 #>  21:  4.9754291  0.9052550  2.5985392  0.9052550     2 #>  22: 10.6698406  8.3785386 12.4518953  8.3785386     2 #>  23:  4.2034654  8.5143906  6.5437848  4.2034654     1 #>  24:  0.3912398 13.2359741 14.4048971  0.3912398     1 #>  25: 12.4273308  5.3035339 11.4877347  5.3035339     2 #>  26:  9.2460530  8.8875661  9.7551134  8.8875661     2 #>  27: 10.0175198  8.1917854 20.7682985  8.1917854     2 #>  28:  1.8716231 12.5395636  9.8046907  1.8716231     1 #>  29:  6.7783389 12.1471281  3.7365423  3.7365423     0 #>  30:  1.7361957  7.1972075 10.3816363  1.7361957     1 #>  31:  2.9051934  7.4404807  8.5419258  2.9051934     1 #>  32: 16.8423205 16.0097286  7.1522689  7.1522689     0 #>  33:  8.5958827 18.2676768  8.4032656  8.4032656     0 #>  34:  6.0094763  6.6477715 12.9647190  6.0094763     1 #>  35: 17.6307100  2.7214120  4.3531514  2.7214120     2 #>  36:  5.2781104  7.1694490  6.3464056  5.2781104     1 #>  37:  7.2443077  7.6040207  4.7996851  4.7996851     0 #>  38:  8.2040793  8.0149945 14.9202754  8.0149945     2 #>  39:  8.9036096  1.2254374  5.6865034  1.2254374     2 #>  40: 19.1566811  8.2339490  9.4259990  8.2339490     2 #>  41:  0.7256035  6.1771413  4.4418193  0.7256035     1 #>  42:  1.1343471  7.1292371  6.5978478  1.1343471     1 #>  43:  2.4818625 11.9659573  4.9468016  2.4818625     1 #>  44:  9.2433390 11.6368070  7.6963083  7.6963083     0 #>  45: 11.4974289  5.6183353  7.9712452  5.6183353     2 #>  46: 15.8702088  8.9039935  4.8635127  4.8635127     0 #>  47: 10.7024090 13.1994135 19.3854679 10.7024090     1 #>  48:  3.3465424  5.4045730  8.6009103  3.3465424     1 #>  49: 10.8718263 15.0130365  5.5816328  5.5816328     0 #>  50:  3.5098271  3.8151275  6.0589827  3.5098271     1 #>  51:  7.5771125  6.9764637  8.5961656  6.9764637     2 #>  52:  7.1823229  7.6478994  3.8654561  3.8654561     0 #>  53:  7.4972585 10.5469171  9.0846832  7.4972585     1 #>  54: 12.5460292  8.8970390 11.8630723  8.8970390     2 #>  55:  4.4530482  8.3202501 16.2776107  4.4530482     1 #>  56: 18.1829154 13.0766848 15.1918985 13.0766848     2 #>  57:  6.8488799  7.9722989 10.7291826  6.8488799     1 #>  58:  9.1428227 16.0829018  8.1028164  8.1028164     0 #>  59: 10.3188714 11.3181822  6.4224766  6.4224766     0 #>  60:  5.1499748 12.4413617  9.4834562  5.1499748     1 #>  61: 13.2357625 11.2071474  3.0191937  3.0191937     0 #>  62:  8.4072725  3.3290603 11.0703455  3.3290603     2 #>  63:  5.5218756  8.9828104  8.8236154  5.5218756     1 #>  64:  8.1938006  4.9847842 10.4949142  4.9847842     2 #>  65:  8.7705630  3.5655318  6.5532025  3.5655318     2 #>  66:  7.2883367  9.4021645 11.6392897  7.2883367     1 #>  67:  2.7472424 16.5887588  8.5848967  2.7472424     1 #>  68:  6.5057331 10.4506967  5.1591435  5.1591435     0 #>  69:  3.8063188  5.6863212 15.7289648  3.8063188     1 #>  70:  9.7735032 10.4204035  3.6491674  3.6491674     0 #>  71:  2.0174490  6.7924836 10.3997117  2.0174490     1 #>  72:  9.8248568  4.1667978  4.1835375  4.1667978     2 #>  73: 13.3095367  3.9412067 10.2924392  3.9412067     2 #>  74: 12.0943064  9.6857073 10.4751533  9.6857073     2 #>  75:  2.3043659  9.8299805  8.6116188  2.3043659     1 #>  76: 15.7569380  3.3231612  3.3773780  3.3231612     2 #>  77: 12.8251201  6.6299801  3.8182415  3.8182415     0 #>  78: 16.1069493  5.4740161  9.7037897  5.4740161     2 #>  79:  7.2066603  7.0853750  5.0189867  5.0189867     0 #>  80: 12.3822634  3.1928412  2.0044564  2.0044564     0 #>  81:  7.2873177 11.0683954  9.1279371  7.2873177     1 #>  82: 12.3448375 12.8612633  5.8219822  5.8219822     0 #>  83:  9.6914349  3.4717358  9.5723812  3.4717358     2 #>  84: 10.2753258  8.2854717 10.5964482  8.2854717     2 #>  85:  2.9179562  3.6219149  5.2751958  2.9179562     1 #>  86: 14.7949557 12.9034272 12.6335523 12.6335523     0 #>  87: 11.6901039  5.2624704  5.8387701  5.2624704     2 #>  88: 12.9563074  5.6769274 14.5129689  5.6769274     2 #>  89:  5.5090254  2.4066712 11.8511819  2.4066712     2 #>  90:  0.9690222  7.7596721 13.9383800  0.9690222     1 #>  91:  8.3891580  5.8312706 11.9526635  5.8312706     2 #>  92:  6.6220447  9.7181270 16.8265585  6.6220447     1 #>  93: 13.1848154 15.1455991  6.6537063  6.6537063     0 #>  94:  7.1122919  2.7472876  3.6343076  2.7472876     2 #>  95:  3.5078609 11.2315946  4.9985375  3.5078609     1 #>  96:  8.4434745  7.2571465  4.7593402  4.7593402     0 #>  97: 19.9907424 14.8458817  8.8704839  8.8704839     0 #>  98: 13.1079695  4.1683325  9.4413615  4.1683325     2 #>  99:  4.0399870 10.7042893  4.5787251  4.0399870     1 #> 100: 11.3307878  4.9478527  7.0896903  4.9478527     2 #>      eventtime1 eventtime2   censtime       time event d[,X5:=as.numeric(as.character(X5))] #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>   1:  38.17963 60.30461  0.49696095  0.96169663  1.473881181  0  0  0  1  0 #>   2:  47.31519 55.88254 -0.22487472 -0.60442573  0.677268492  1  0  0  0  0 #>   3:  41.24281 69.14865 -1.11714317 -0.75287728  0.379962687  0  0  1  0  1 #>   4:  70.00932 52.85042 -0.39499460 -1.55561159 -0.192798426  0  0  1  0  0 #>   5:  40.63845 61.27069  1.54983034 -1.45389374  1.577891795  1  0  1  0  0 #>   6:  29.47495 45.30113 -0.74351448  0.05633184  0.596234109  1  1  1  1  1 #>   7:  90.32020 60.01208 -2.33171212  0.50936941 -1.173576941  0  0  0  0  1 #>   8:  75.08960 62.54833  0.81224544 -2.09788296 -0.155642535  0  1  1  1  0 #>   9:  72.25685 54.57640 -0.50131066 -1.00436198 -1.918909820  1  0  0  0  0 #>  10:  50.04018 63.52416 -0.51088657  0.53577172 -0.195258846  0  0  1  0  1 #>  11:  59.83078 61.65488 -1.21536404 -0.45303708 -2.592327670  1  1  1  0  1 #>  12:  69.29516 64.88164 -0.02255863  2.16536850  1.314002167  0  0  0  0  0 #>  13:  40.78142 55.78330  0.70123930  1.24574667 -0.635543001  0  0  1  1  1 #>  14:  58.13608 55.14710 -0.58748203  0.59549803 -0.429978839  0  0  1  1  1 #>  15:  62.63612 51.14234 -0.60672794  0.00488445 -0.169318332  0  0  1  0  1 #>  16:  85.39161 58.38765  1.09664022  0.27936078  0.612218174  0  0  0  0  0 #>  17:  69.63199 53.30600 -0.24750968 -0.70590613  0.678340177  0  0  0  0  1 #>  18:  79.23350 63.44078 -0.15990171  0.62801715  0.567951972  0  0  0  0  1 #>  19:  62.10820 60.35640 -0.62577825  1.48021396 -0.572542604  0  0  0  1  1 #>  20:  43.31246 70.94876  0.90043464  1.08342991 -1.363291256  0  0  1  1  0 #>  21:  54.90485 54.21146 -0.99419363 -0.81324426 -0.388722244  0  1  0  1  0 #>  22:  35.02853 65.90844  0.84925039 -1.61887685  0.277914132  0  0  0  0  0 #>  23:  73.93278 57.36316  0.80570229 -0.10965570 -0.823081122  0  0  0  0  0 #>  24:  81.25240 52.71686 -0.46760094  0.44088937 -0.068840934  0  0  0  1  1 #>  25:  59.05919 62.86484  0.84842031  1.35099398 -1.167662326  0  0  0  1  1 #>  26:  45.28646 52.83311  0.98676986 -1.31860948 -0.008309014  0  1  0  1  1 #>  27:  76.30725 54.72407  0.57562029  0.36438459  0.128855402  0  1  0  1  0 #>  28:  62.08991 56.33444  2.02484205  0.23349984 -0.145875628  0  0  1  1  0 #>  29:  54.20592 61.05454 -1.96235319  1.19395526 -0.163910957  0  1  1  0  0 #>  30:  76.85378 55.00540 -1.16492093 -0.02790997  1.763552003  1  1  1  1  1 #>  31:  48.60232 65.38925 -1.37651921 -0.35729885  0.762586512  0  0  1  1  0 #>  32:  77.23439 54.00513  0.16767993 -1.14681414  1.111431081  0  0  0  0  0 #>  33:  47.36286 61.08319  1.58462908 -0.51742048 -0.923206953  0  0  0  0  0 #>  34:  65.87120 60.71544  1.67788895 -0.36212377  0.164341838  0  0  0  1  1 #>  35:  73.37066 54.67125  0.48829670  2.35055433  1.154825187  0  0  0  0  0 #>  36:  39.97112 57.85688  0.87867326  2.44653138 -0.056521425  0  0  1  0  1 #>  37:  65.97185 56.71910 -0.14487487 -0.16670328 -2.129360648  0  0  1  0  1 #>  38:  58.32620 64.79697  0.46897176 -1.04366744  0.344845762  0  0  0  0  1 #>  39:  70.13616 67.78026  0.37623548 -1.97293493 -1.904955446  0  0  0  0  0 #>  40:  48.17103 54.79602 -0.76104028  0.51467163 -0.811170153  0  0  1  1  0 #>  41:  58.69520 64.65286 -0.29329493 -1.09057358  1.324004321  1  0  0  1  0 #>  42:  80.73426 59.62277 -0.13484126  2.28465933  0.615636849  0  1  0  0  1 #>  43:  62.52735 50.16402  1.39384582 -0.88561757  1.091668956  1  0  0  0  1 #>  44:  72.34786 56.22048 -1.03698869  0.11110643  0.306604862  0  0  0  0  0 #>  45:  56.68658 62.30575 -2.11433515  3.81027668 -0.110158762  0  0  0  1  0 #>  46:  44.55913 60.72553  0.76827822 -1.10891000 -0.924312773  0  0  0  0  0 #>  47:  59.83611 47.78844 -0.81616062  0.30756662  1.592913754  0  1  0  0  0 #>  48:  41.62513 62.90159 -0.43610692 -1.10689447  0.045010598  0  0  1  0  0 #>  49:  21.05833 63.27526  0.90470503  0.34765365 -0.715128401  0  0  0  0  0 #>  50:  77.53684 58.47746 -0.76308626 -0.87326454  0.865223100  1  0  0  1  1 #>  51:  43.69637 56.46216 -0.34106698  0.07730312  1.074440958  0  1  1  0  1 #>  52:  32.60875 69.85786  1.50242453 -0.29686864  1.895654774  0  0  0  0  1 #>  53:  74.92923 59.55001  0.52830771 -1.18324224 -0.602997304  0  0  0  1  0 #>  54:  59.82207 59.92991  0.54219136  0.01129269 -0.390867821  0  1  0  0  1 #>  55:  51.00557 54.38272 -0.13667336  0.99160104 -0.416222032  0  0  0  1  0 #>  56:  57.33078 53.27935 -1.13673385  1.59396745 -0.375657423  0  0  0  0  0 #>  57:  53.61028 52.38422 -1.49662715 -1.37271127 -0.366630946  0  0  0  1  0 #>  58:  74.94988 57.89016 -0.22338564 -0.24961093 -0.295677453  0  0  1  0  0 #>  59:  70.91491 66.80462  2.00171923  1.15942453  1.441820410  0  1  0  1  0 #>  60:  34.10054 68.76897  0.22170382 -1.11422235 -0.697538292  0  1  0  0  1 #>  61:  65.30098 67.84182  0.16437291 -2.52850069 -0.388167506  0  0  0  0  1 #>  62:  70.90220 66.48378  0.33262361 -0.93590256  0.652536452  0  0  0  0  0 #>  63:  70.02391 58.81202 -0.38520800 -0.96723946  1.124772447  0  0  0  1  0 #>  64:  23.63524 53.87925 -1.39875403  0.04748859 -0.772110803  0  0  0  0  1 #>  65:  56.46964 58.36094  2.67574080 -0.40373679 -0.508086216  0  1  0  0  1 #>  66:  89.69450 47.93775 -0.42368609  0.23149613  0.523620590  0  0  1  1  0 #>  67:  71.95192 58.43104 -0.29860151 -0.42237241  1.017754227  1  0  1  0  0 #>  68:  34.36086 68.29939 -1.79234173  0.37411839 -0.251164588  0  0  0  1  1 #>  69:  35.04497 60.65477 -0.24800823 -0.36600577 -1.429993447  0  0  0  1  1 #>  70:  67.36664 65.47944 -0.24730392  1.19010145  1.709121032  0  1  0  0  0 #>  71:  57.38917 62.44670 -0.25551038 -0.73732753  1.435069572  0  0  0  0  0 #>  72:  74.41936 56.10545 -1.78693810  0.29066665 -0.710371146  0  0  1  0  0 #>  73:  64.40740 68.71780  1.78466282 -0.88484957 -0.065067574  0  0  1  1  0 #>  74:  61.21499 59.60806  1.76358635  0.20800648 -1.759468735  0  0  0  0  0 #>  75:  62.75493 55.12223  0.68960022 -0.04773017  0.569722972  0  1  0  0  0 #>  76:  62.49383 60.35330 -1.10074064 -1.68452065  1.612346798  0  0  0  0  0 #>  77:  40.95601 52.40700  0.71450936 -0.14422656 -1.637280647  0  0  1  0  0 #>  78:  95.24240 64.31890 -0.24647032  1.18021367 -0.779568513  0  0  0  1  0 #>  79:  38.81992 62.50784 -0.31978617  0.68139992 -0.641176934  0  1  0  0  0 #>  80:  59.74558 58.22609  1.36264429  0.14324763 -0.681131394  0  0  0  0  1 #>  81:  51.83521 57.55786 -1.22788259 -1.19231644 -2.033285596  0  0  1  0  0 #>  82:  87.00169 64.68147 -0.51121923  1.16922865  0.500963559  0  1  0  0  1 #>  83:  75.17160 54.68796 -0.73119500  0.07920171 -1.531798140  0  0  1  1  1 #>  84:  51.54425 55.08090  0.01975201 -0.45177375 -0.024997639  0  0  1  1  0 #>  85:  63.08131 62.12124 -1.57286391  1.64202821  0.592984721  0  0  0  0  0 #>  86:  77.48193 57.74343 -0.70333327 -0.76959232 -0.198195421  0  0  0  0  0 #>  87:  93.54484 64.62542  0.71593209  0.30336096  0.892008392  0  0  0  1  0 #>  88:  64.53398 59.00690  0.46521491  1.28173742 -0.025715071  0  0  0  1  0 #>  89:  44.36240 65.97426 -0.97390231  0.60222280 -0.647660451  0  1  1  0  0 #>  90:  45.24687 62.47772  0.55921773 -0.30702226  0.646359415  1  0  0  1  0 #>  91:  90.08578 48.77424 -2.43263975 -0.41841810 -0.433832740  0  0  0  0  0 #>  92:  28.94143 53.32314 -0.34048493  0.35513553  1.772611185  0  0  1  0  0 #>  93: 105.83614 66.41388  0.71303319  0.51348111 -0.018259711  0  0  0  1  1 #>  94:  56.07974 63.45398 -0.65903739  0.01860740  0.852814994  0  0  0  0  0 #>  95:  53.18410 55.16469 -0.03640262  1.31844897  0.205162903  0  1  0  0  1 #>  96:  62.36341 53.27103 -1.59328630 -0.06583200 -3.008048599  0  0  0  0  1 #>  97:  74.00083 65.16833  0.84779280 -0.70029608 -1.366111931  0  0  0  1  0 #>  98:  64.54242 55.94112 -1.85038885  0.53732613 -0.424102260  0  0  0  0  0 #>  99:  30.65775 69.00863 -0.32365063 -2.20178232  0.236803664  1  0  1  0  0 #> 100:  65.30305 68.85771 -0.25524811  0.39197374 -2.342723120  0  0  0  0  1 #>             X6       X7          X8          X9          X10 X1 X2 X3 X4 X5 #>      eventtime1 eventtime2   censtime       time event #>   1:  6.2835117  6.5080075 11.5156754  6.2835117     1 #>   2:  2.2341745 10.2016103  9.9424766  2.2341745     1 #>   3:  5.4227648 11.4384015  7.4640840  5.4227648     1 #>   4: 14.4463659  0.8569032  3.1029354  0.8569032     2 #>   5:  5.0566209  6.7565221 12.6533135  5.0566209     1 #>   6:  4.9180272 12.4317594  3.2733982  3.2733982     0 #>   7: 21.7373883 14.3005616  2.3856664  2.3856664     0 #>   8:  6.8654215  8.5900969  6.4366715  6.4366715     0 #>   9:  3.6545169  2.8100287  6.8076628  2.8100287     2 #>  10: 11.3187530  7.1616535 16.6855449  7.1616535     2 #>  11:  4.9578732  1.5529912 12.5698152  1.5529912     2 #>  12: 12.6136920  5.5880073 13.1685721  5.5880073     2 #>  13: 12.2705325 10.1527570  6.1268894  6.1268894     0 #>  14: 11.7160646  9.1681445  9.7818335  9.1681445     2 #>  15: 13.3093289 13.8170712  5.1143986  5.1143986     0 #>  16:  2.8558834 20.8251202  8.3531989  2.8558834     1 #>  17: 10.3116570  5.7851651  5.7603574  5.7603574     0 #>  18: 15.6965602 15.0706310  0.9014898  0.9014898     0 #>  19:  9.8658157  8.9821989  9.8361143  8.9821989     2 #>  20:  7.8103363  6.6792906  5.0173907  5.0173907     0 #>  21:  4.9754291  0.9052550  2.5985392  0.9052550     2 #>  22: 10.6698406  8.3785386 12.4518953  8.3785386     2 #>  23:  4.2034654  8.5143906  6.5437848  4.2034654     1 #>  24:  0.3912398 13.2359741 14.4048971  0.3912398     1 #>  25: 12.4273308  5.3035339 11.4877347  5.3035339     2 #>  26:  9.2460530  8.8875661  9.7551134  8.8875661     2 #>  27: 10.0175198  8.1917854 20.7682985  8.1917854     2 #>  28:  1.8716231 12.5395636  9.8046907  1.8716231     1 #>  29:  6.7783389 12.1471281  3.7365423  3.7365423     0 #>  30:  1.7361957  7.1972075 10.3816363  1.7361957     1 #>  31:  2.9051934  7.4404807  8.5419258  2.9051934     1 #>  32: 16.8423205 16.0097286  7.1522689  7.1522689     0 #>  33:  8.5958827 18.2676768  8.4032656  8.4032656     0 #>  34:  6.0094763  6.6477715 12.9647190  6.0094763     1 #>  35: 17.6307100  2.7214120  4.3531514  2.7214120     2 #>  36:  5.2781104  7.1694490  6.3464056  5.2781104     1 #>  37:  7.2443077  7.6040207  4.7996851  4.7996851     0 #>  38:  8.2040793  8.0149945 14.9202754  8.0149945     2 #>  39:  8.9036096  1.2254374  5.6865034  1.2254374     2 #>  40: 19.1566811  8.2339490  9.4259990  8.2339490     2 #>  41:  0.7256035  6.1771413  4.4418193  0.7256035     1 #>  42:  1.1343471  7.1292371  6.5978478  1.1343471     1 #>  43:  2.4818625 11.9659573  4.9468016  2.4818625     1 #>  44:  9.2433390 11.6368070  7.6963083  7.6963083     0 #>  45: 11.4974289  5.6183353  7.9712452  5.6183353     2 #>  46: 15.8702088  8.9039935  4.8635127  4.8635127     0 #>  47: 10.7024090 13.1994135 19.3854679 10.7024090     1 #>  48:  3.3465424  5.4045730  8.6009103  3.3465424     1 #>  49: 10.8718263 15.0130365  5.5816328  5.5816328     0 #>  50:  3.5098271  3.8151275  6.0589827  3.5098271     1 #>  51:  7.5771125  6.9764637  8.5961656  6.9764637     2 #>  52:  7.1823229  7.6478994  3.8654561  3.8654561     0 #>  53:  7.4972585 10.5469171  9.0846832  7.4972585     1 #>  54: 12.5460292  8.8970390 11.8630723  8.8970390     2 #>  55:  4.4530482  8.3202501 16.2776107  4.4530482     1 #>  56: 18.1829154 13.0766848 15.1918985 13.0766848     2 #>  57:  6.8488799  7.9722989 10.7291826  6.8488799     1 #>  58:  9.1428227 16.0829018  8.1028164  8.1028164     0 #>  59: 10.3188714 11.3181822  6.4224766  6.4224766     0 #>  60:  5.1499748 12.4413617  9.4834562  5.1499748     1 #>  61: 13.2357625 11.2071474  3.0191937  3.0191937     0 #>  62:  8.4072725  3.3290603 11.0703455  3.3290603     2 #>  63:  5.5218756  8.9828104  8.8236154  5.5218756     1 #>  64:  8.1938006  4.9847842 10.4949142  4.9847842     2 #>  65:  8.7705630  3.5655318  6.5532025  3.5655318     2 #>  66:  7.2883367  9.4021645 11.6392897  7.2883367     1 #>  67:  2.7472424 16.5887588  8.5848967  2.7472424     1 #>  68:  6.5057331 10.4506967  5.1591435  5.1591435     0 #>  69:  3.8063188  5.6863212 15.7289648  3.8063188     1 #>  70:  9.7735032 10.4204035  3.6491674  3.6491674     0 #>  71:  2.0174490  6.7924836 10.3997117  2.0174490     1 #>  72:  9.8248568  4.1667978  4.1835375  4.1667978     2 #>  73: 13.3095367  3.9412067 10.2924392  3.9412067     2 #>  74: 12.0943064  9.6857073 10.4751533  9.6857073     2 #>  75:  2.3043659  9.8299805  8.6116188  2.3043659     1 #>  76: 15.7569380  3.3231612  3.3773780  3.3231612     2 #>  77: 12.8251201  6.6299801  3.8182415  3.8182415     0 #>  78: 16.1069493  5.4740161  9.7037897  5.4740161     2 #>  79:  7.2066603  7.0853750  5.0189867  5.0189867     0 #>  80: 12.3822634  3.1928412  2.0044564  2.0044564     0 #>  81:  7.2873177 11.0683954  9.1279371  7.2873177     1 #>  82: 12.3448375 12.8612633  5.8219822  5.8219822     0 #>  83:  9.6914349  3.4717358  9.5723812  3.4717358     2 #>  84: 10.2753258  8.2854717 10.5964482  8.2854717     2 #>  85:  2.9179562  3.6219149  5.2751958  2.9179562     1 #>  86: 14.7949557 12.9034272 12.6335523 12.6335523     0 #>  87: 11.6901039  5.2624704  5.8387701  5.2624704     2 #>  88: 12.9563074  5.6769274 14.5129689  5.6769274     2 #>  89:  5.5090254  2.4066712 11.8511819  2.4066712     2 #>  90:  0.9690222  7.7596721 13.9383800  0.9690222     1 #>  91:  8.3891580  5.8312706 11.9526635  5.8312706     2 #>  92:  6.6220447  9.7181270 16.8265585  6.6220447     1 #>  93: 13.1848154 15.1455991  6.6537063  6.6537063     0 #>  94:  7.1122919  2.7472876  3.6343076  2.7472876     2 #>  95:  3.5078609 11.2315946  4.9985375  3.5078609     1 #>  96:  8.4434745  7.2571465  4.7593402  4.7593402     0 #>  97: 19.9907424 14.8458817  8.8704839  8.8704839     0 #>  98: 13.1079695  4.1683325  9.4413615  4.1683325     2 #>  99:  4.0399870 10.7042893  4.5787251  4.0399870     1 #> 100: 11.3307878  4.9478527  7.0896903  4.9478527     2 #>      eventtime1 eventtime2   censtime       time event setkey(d, time)  Utime <- sort(unique(d$time))  ## fit cox models m.CSC <- CSC(Hist(time, event) ~ X1 + X2, data = d) mStrata.CSC <- CSC(Hist(time, event) ~ strata(X1) + X2 + X3, data = d)  ## compare models outIF <- influenceTest(list(m.CSC, mStrata.CSC),               cause = 1, newdata = unique(d[,.(X1,X2,X3)]), times = Utime[1:5]) confint(outIF) #>         Comparison of two estimates of the absRisk at time 0.391 0.726 0.857 0.901 0.905 #>  #> model 1: #> CSC(formula = Hist(time, event) ~ X1 + X2, data = d) #> model 2: #> CSC(formula = Hist(time, event) ~ strata(X1) + X2 + X3, data = d) #>     X1 X2  time difference      se    conf.interval p.value quantileBand #>  1:  0  0 0.391  -0.007397 0.00744 [-0.022 ; 0.007]   0.320         2.14 #>  2:  0  0 0.726  -0.002655 0.00817 [-0.019 ; 0.013]   0.745         2.14 #>  3:  0  0 0.857  -0.002655 0.00817 [-0.019 ; 0.013]   0.745         2.14 #>  4:  0  0 0.901  -0.002655 0.00817 [-0.019 ; 0.013]   0.745         2.14 #>  5:  0  0 0.905  -0.002655 0.00817 [-0.019 ; 0.013]   0.745         2.14 #>  6:  1  0 0.391   0.050593 0.04990 [-0.047 ; 0.148]   0.311         2.20 #>  7:  1  0 0.726   0.006225 0.06230 [-0.116 ; 0.128]   0.920         2.20 #>  8:  1  0 0.857   0.006225 0.06230 [-0.116 ; 0.128]   0.920         2.20 #>  9:  1  0 0.901   0.006225 0.06230 [-0.116 ; 0.128]   0.920         2.20 #> 10:  1  0 0.905   0.006225 0.06230 [-0.116 ; 0.128]   0.920         2.20 #> 11:  0  0 0.391  -0.005261 0.00553 [-0.016 ; 0.006]   0.342         2.15 #> 12:  0  0 0.726  -0.000519 0.00702 [-0.014 ; 0.013]   0.941         2.15 #> 13:  0  0 0.857  -0.000519 0.00702 [-0.014 ; 0.013]   0.941         2.15 #> 14:  0  0 0.901  -0.000519 0.00702 [-0.014 ; 0.013]   0.941         2.15 #> 15:  0  0 0.905  -0.000519 0.00702 [-0.014 ; 0.013]   0.941         2.15 #> 16:  0  1 0.391  -0.007153 0.00745 [-0.022 ; 0.007]   0.337         2.14 #> 17:  0  1 0.726  -0.002897 0.00794 [-0.018 ; 0.013]   0.715         2.14 #> 18:  0  1 0.857  -0.002897 0.00794 [-0.018 ; 0.013]   0.715         2.14 #> 19:  0  1 0.901  -0.002897 0.00794 [-0.018 ; 0.013]   0.715         2.14 #> 20:  0  1 0.905  -0.002897 0.00794 [-0.018 ; 0.013]   0.715         2.14 #> 21:  1  1 0.391   0.045388 0.04538 [-0.044 ; 0.134]   0.317         2.14 #> 22:  1  1 0.726   0.017186 0.04965  [-0.08 ; 0.114]   0.729         2.14 #> 23:  1  1 0.857   0.017186 0.04965  [-0.08 ; 0.114]   0.729         2.14 #> 24:  1  1 0.901   0.017186 0.04965  [-0.08 ; 0.114]   0.729         2.14 #> 25:  1  1 0.905   0.017186 0.04965  [-0.08 ; 0.114]   0.729         2.14 #> 26:  0  1 0.391  -0.005146 0.00535 [-0.016 ; 0.005]   0.336         2.15 #> 27:  0  1 0.726  -0.000890 0.00664 [-0.014 ; 0.012]   0.893         2.15 #> 28:  0  1 0.857  -0.000890 0.00664 [-0.014 ; 0.012]   0.893         2.15 #> 29:  0  1 0.901  -0.000890 0.00664 [-0.014 ; 0.012]   0.893         2.15 #> 30:  0  1 0.905  -0.000890 0.00664 [-0.014 ; 0.012]   0.893         2.15 #> 31:  1  0 0.391   0.050593 0.04990 [-0.047 ; 0.148]   0.311         2.14 #> 32:  1  0 0.726   0.022522 0.05427 [-0.084 ; 0.129]   0.678         2.14 #> 33:  1  0 0.857   0.022522 0.05427 [-0.084 ; 0.129]   0.678         2.14 #> 34:  1  0 0.901   0.022522 0.05427 [-0.084 ; 0.129]   0.678         2.14 #> 35:  1  0 0.905   0.022522 0.05427 [-0.084 ; 0.129]   0.678         2.14 #>     X1 X2  time difference      se    conf.interval p.value quantileBand #>            conf.band #>  1: [-0.023 ; 0.009] #>  2:  [-0.02 ; 0.015] #>  3:  [-0.02 ; 0.015] #>  4:  [-0.02 ; 0.015] #>  5:  [-0.02 ; 0.015] #>  6:  [-0.059 ; 0.16] #>  7: [-0.131 ; 0.143] #>  8: [-0.131 ; 0.143] #>  9: [-0.131 ; 0.143] #> 10: [-0.131 ; 0.143] #> 11: [-0.017 ; 0.007] #> 12: [-0.016 ; 0.015] #> 13: [-0.016 ; 0.015] #> 14: [-0.016 ; 0.015] #> 15: [-0.016 ; 0.015] #> 16: [-0.023 ; 0.009] #> 17:  [-0.02 ; 0.014] #> 18:  [-0.02 ; 0.014] #> 19:  [-0.02 ; 0.014] #> 20:  [-0.02 ; 0.014] #> 21: [-0.052 ; 0.142] #> 22: [-0.089 ; 0.123] #> 23: [-0.089 ; 0.123] #> 24: [-0.089 ; 0.123] #> 25: [-0.089 ; 0.123] #> 26: [-0.017 ; 0.006] #> 27: [-0.015 ; 0.013] #> 28: [-0.015 ; 0.013] #> 29: [-0.015 ; 0.013] #> 30: [-0.015 ; 0.013] #> 31: [-0.056 ; 0.158] #> 32: [-0.094 ; 0.139] #> 33: [-0.094 ; 0.139] #> 34: [-0.094 ; 0.139] #> 35: [-0.094 ; 0.139] #>            conf.band"},{"path":"/reference/information.wglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Information for IPCW Logistic Regressions — information.wglm","title":"Information for IPCW Logistic Regressions — information.wglm","text":"Compute information (.e. opposit expectation second derivative log-likelihood) IPCW logistic regressions.","code":""},{"path":"/reference/information.wglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information for IPCW Logistic Regressions — information.wglm","text":"","code":"# S3 method for wglm information(x, times = NULL, simplifies = TRUE, ...)"},{"path":"/reference/information.wglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information for IPCW Logistic Regressions — information.wglm","text":"x wglm object. times [numeric vector] time points score output. simplifies [logical] ouput converted matrix one timepoint requested. Otherwise always return list. ... used.","code":""},{"path":"/reference/ipcw.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of censoring probabilities — ipcw","title":"Estimation of censoring probabilities — ipcw","text":"function used internally obtain inverse probability censoring weights.","code":""},{"path":"/reference/ipcw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of censoring probabilities — ipcw","text":"","code":"ipcw(   formula,   data,   method,   args,   times,   subject.times,   lag = 1,   what,   keep = NULL )"},{"path":"/reference/ipcw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of censoring probabilities — ipcw","text":"formula survival formula like, Surv(time,status)~1, usual status=0 means censored. status variable internally reversed estimation censoring rather survival probabilities. available models (see argument model) use predictors right hand side formula. data data used fitting censoring model method Censoring model used estimation (conditional) censoring distribution. args list arguments passed method times =\"IPCW.times\" vector times compute probabilities censored. subject.times =\"IPCW.subject.times\" vector individual times probabilities censored computed. lag equal 1 obtain G(T_i-|X_i), equal 0 estimate conditional censoring distribution subject.times, .e. (G(T_i|X_i)). Decide : equal \"IPCW.times\" weights estimated given times.  equal \"IPCW.subject.times\" weights estimated individual subject.times.  missing produce . keep elements add output. subset vector c(\"times\",\"fit\",\"call\").","code":""},{"path":"/reference/ipcw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of censoring probabilities — ipcw","text":"list elements depending argument keep. times times weights estimated IPCW.times Estimated weights times IPCW.subject.times Estimated weights individual time values subject.times fit fitted censoring model method method modelling censoring distribution call call","code":""},{"path":"/reference/ipcw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of censoring probabilities — ipcw","text":"Inverse probability censoring weights (IPCW) usually refer probabilities censored certain time points. probabilities also values conditional survival function censoring time given covariates. function ipcw estimates conditional survival function censoring times derives weights. IMPORTANT: data set ordered, order(time,-status) order get values IPCW.subject.times right order choices method.","code":""},{"path":"/reference/ipcw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation of censoring probabilities — ipcw","text":"Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/ipcw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of censoring probabilities — ipcw","text":"","code":"library(prodlim) library(rms) dat=SimSurv(30)  dat <- dat[order(dat$time),]  # using the marginal Kaplan-Meier for the censoring times  WKM=ipcw(Hist(time,status)~X2,   data=dat,   method=\"marginal\",   times=sort(unique(dat$time)),   subject.times=dat$time,keep=c(\"fit\")) plot(WKM$fit) WKM$fit #>  #> Call: prodlim::prodlim(formula = formula, data = data, reverse = TRUE) #>  #> Kaplan-Meier estimator for the censoring time survival function #>  #> No covariates #>  #> Right-censored response of a survival model #>  #> No.Observations: 30  #>  #> Pattern: #>                 Freq #>  event          17   #>  right.censored 13    # using the Cox model for the censoring times given X2 library(survival) WCox=ipcw(Hist(time=time,event=status)~X2,   data=dat,   method=\"cox\",   times=sort(unique(dat$time)),   subject.times=dat$time,keep=c(\"fit\")) WCox$fit #> Cox Proportional Hazards Model #>   #>  (function (formula = formula(data), data = environment(formula),  #>      weights, subset, na.action = na.delete, method = c(\"efron\",  #>          \"breslow\", \"exact\", \"model.frame\", \"model.matrix\"), singular.ok = FALSE,  #>      robust = FALSE, model = FALSE, x = FALSE, y = FALSE, se.fit = FALSE,  #>      linear.predictors = TRUE, residuals = TRUE, nonames = FALSE,  #>      eps = 1e-04, init, iter.max = 10, tol = 1e-09, surv = FALSE,  #>      time.inc, type = NULL, vartype = NULL, debug = FALSE, ...)  #>  { #>      method <- match.arg(method) #>      call <- match.call() #>      if (!inherits(formula, \"formula\")) { #>          if (inherits(formula, \"Surv\")) { #>              xx <- function(x) formula(x) #>              formula <- xx(paste(deparse(substitute(formula)),  #>                  1, sep = \"~\")) #>          } #>          else stop(\"Invalid formula\") #>      } #>      callenv <- parent.frame() #>      weights <- if (!missing(weights))  #>          eval(substitute(weights), data, callenv) #>      subset <- if (!missing(subset))  #>          eval(substitute(subset), data, callenv) #>      data <- modelData(data, formula, weights = weights, subset = subset,  #>          na.action = na.action, dotexpand = FALSE, callenv = callenv) #>      nstrata <- 0 #>      Strata <- NULL #>      odb <- .Options$debug #>      if (length(odb) && is.logical(odb) && odb)  #>          debug <- TRUE #>      if (length(z <- attr(terms(formula, allowDotAsName = TRUE),  #>          \"term.labels\")) > 0 && any(z != \".\")) { #>          X <- Design(data, formula, specials = c(\"strat\", \"strata\")) #>          atrx <- attributes(X) #>          atr <- atrx$Design #>          nact <- atrx$na.action #>          sformula <- atrx$sformula #>          mmcolnames <- atr$mmcolnames #>          if (method == \"model.frame\")  #>              return(X) #>          Terms <- terms(sformula, specials = c(\"strat\", \"strata\"),  #>              data = data) #>          asm <- atr$assume.code #>          name <- atr$name #>          specials <- attr(Terms, \"specials\") #>          if (length(specials$strata))  #>              stop(\"cph supports strat(), not strata()\") #>          stra <- specials$strat #>          cluster <- attr(X, \"cluster\") #>          if (length(cluster)) { #>              if (missing(robust))  #>                  robust <- TRUE #>              attr(X, \"cluster\") <- NULL #>          } #>          Terms.ns <- Terms #>          if (length(stra)) { #>              temp <- untangle.specials(Terms.ns, \"strat\", 1) #>              Terms.ns <- Terms.ns[-temp$terms] #>              Strata <- list() #>              strataname <- attr(Terms, \"term.labels\")[stra - 1] #>              j <- 0 #>              for (i in (1:length(asm))[asm == 8]) { #>                  nstrata <- nstrata + 1 #>                  xi <- X[[i + 1]] #>                  levels(xi) <- paste(name[i], \"=\", levels(xi),  #>                    sep = \"\") #>                  Strata[[nstrata]] <- xi #>              } #>              Strata <- interaction(as.data.frame(Strata), drop = TRUE) #>          } #>          xpres <- length(asm) && any(asm != 8) #>          Y <- model.extract(X, \"response\") #>          if (!inherits(Y, \"Surv\"))  #>              stop(\"response variable should be a Surv object\") #>          n <- nrow(Y) #>          weights <- model.extract(X, \"weights\") #>          offset <- attr(X, \"offset\") #>          if (!xpres) { #>              X <- matrix(nrow = 0, ncol = 0) #>              assign <- NULL #>          } #>          else { #>              X <- model.matrix(sformula, X) #>              alt <- attr(mmcolnames, \"alt\") #>              if (debug) { #>                  print(cbind(`colnames(X)` = colnames(X)[-1],  #>                    mmcolnames = mmcolnames, `Design colnames` = atr$colnames,  #>                    alt = alt)) #>              } #>              if (!all(mmcolnames %in% colnames(X)) && length(alt))  #>                  mmcolnames <- alt #>              X <- X[, mmcolnames, drop = FALSE] #>              assign <- attr(X, \"assign\") #>              assign[[1]] <- NULL #>          } #>          nullmod <- FALSE #>      } #>      else { #>          X <- NULL #>          Y <- data[[1]] #>          sformula <- formula #>          mmcolnames <- \"\" #>          weights <- if (\"(weights)\" %in% names(data))  #>              data[[\"(weights)\"]] #>          atr <- atrx <- NULL #>          Terms <- terms(formula, allowDotAsName = TRUE) #>          if (!inherits(Y, \"Surv\"))  #>              stop(\"response variable should be a Surv object\") #>          Y <- Y[!is.na(Y)] #>          assign <- NULL #>          xpres <- FALSE #>          nullmod <- TRUE #>          nact <- NULL #>      } #>      ny <- ncol(Y) #>      maxtime <- max(Y[, ny - 1]) #>      rnam <- if (!nonames)  #>          dimnames(Y)[[1]] #>      if (xpres)  #>          dimnames(X) <- list(rnam, atr$colnames) #>      if (method == \"model.matrix\")  #>          return(X) #>      time.units <- units(Y) #>      if (!length(time.units) || time.units == \"\")  #>          time.units <- \"Day\" #>      if (missing(time.inc)) { #>          time.inc <- switch(time.units, Day = 30, Month = 1, Year = 1,  #>              maxtime/10) #>          if (time.inc >= maxtime | maxtime/time.inc > 25)  #>              time.inc <- max(pretty(c(0, maxtime)))/10 #>      } #>      ytype <- attr(Y, \"type\") #>      if (nullmod)  #>          f <- NULL #>      else { #>          fitter <- if (method == \"breslow\" || method == \"efron\") { #>              if (ytype == \"right\")  #>                  coxph.fit #>              else agreg.fit #>          } #>          else if (method == \"exact\") { #>              if (ytype == \"right\")  #>                  getFromNamespace(\"coxexact.fit\", \"survival\") #>              else agexact.fit #>          } #>          else stop(paste(\"Unknown method\", method)) #>          if (missing(init))  #>              init <- NULL #>          f <- fitter(X, Y, strata = Strata, offset = offset, weights = weights,  #>              init = init, method = method, rownames = rnam, control = coxph.control(eps = eps,  #>                  toler.chol = tol, toler.inf = 1, iter.max = iter.max)) #>      } #>      if (is.character(f)) { #>          cat(\"Failure in cph:\\n\", f, \"\\n\") #>          return(structure(list(fail = TRUE), class = \"cph\")) #>      } #>      else { #>          if (length(f$coefficients) && any(is.na(f$coefficients))) { #>              vars <- names(f$coefficients)[is.na(f$coefficients)] #>              msg <- paste(\"X matrix deemed to be singular; variable\",  #>                  paste(vars, collapse = \" \")) #>              if (singular.ok)  #>                  warning(msg) #>              else { #>                  cat(msg, \"\\n\") #>                  return(structure(list(fail = TRUE), class = \"cph\")) #>              } #>          } #>      } #>      f$terms <- Terms #>      f$sformula <- sformula #>      f$mmcolnames <- mmcolnames #>      if (robust) { #>          f$naive.var <- f$var #>          if (!length(cluster))  #>              cluster <- FALSE #>          fit2 <- c(f, list(x = X, y = Y, weights = weights, method = method)) #>          if (length(stra))  #>              fit2$strata <- Strata #>          r <- getS3method(\"residuals\", \"coxph\")(fit2, type = \"dfbeta\",  #>              collapse = cluster, weighted = TRUE) #>          f$var <- t(r) %*% r #>      } #>      nvar <- length(f$coefficients) #>      ev <- factor(Y[, ny], levels = 0:1, labels = c(\"No Event\",  #>          \"Event\")) #>      n.table <- { #>          if (!length(Strata))  #>              table(ev, dnn = \"Status\") #>          else table(Strata, ev, dnn = c(\"Stratum\", \"Status\")) #>      } #>      f$n <- n.table #>      nevent <- sum(Y[, ny]) #>      if (xpres) { #>          logtest <- -2 * (f$loglik[1] - f$loglik[2]) #>          R2.max <- 1 - exp(2 * f$loglik[1]/n) #>          R2 <- (1 - exp(-logtest/n))/R2.max #>          P <- 1 - pchisq(logtest, nvar) #>          gindex <- GiniMd(f$linear.predictors) #>          dxy <- dxy.cens(f$linear.predictors, Y, type = \"hazard\")[\"Dxy\"] #>          stats <- c(n, nevent, logtest, nvar, P, f$score, 1 -  #>              pchisq(f$score, nvar), R2, dxy, gindex, exp(gindex)) #>          names(stats) <- c(\"Obs\", \"Events\", \"Model L.R.\", \"d.f.\",  #>              \"P\", \"Score\", \"Score P\", \"R2\", \"Dxy\", \"g\", \"gr\") #>      } #>      else { #>          stats <- c(n, nevent) #>          names(stats) <- c(\"Obs\", \"Events\") #>      } #>      f$method <- NULL #>      if (xpres)  #>          dimnames(f$var) <- list(atr$colnames, atr$colnames) #>      f <- c(f, list(call = call, Design = atr, assign = DesignAssign(atr,  #>          0, atrx$terms), na.action = nact, fail = FALSE, non.slopes = 0,  #>          stats = stats, method = method, maxtime = maxtime, time.inc = time.inc,  #>          units = time.units)) #>      if (xpres) { #>          f$center <- sum(f$means * f$coefficients) #>          f$scale.pred <- c(\"log Relative Hazard\", \"Hazard Ratio\") #>          attr(f$linear.predictors, \"strata\") <- Strata #>          names(f$linear.predictors) <- rnam #>          if (se.fit) { #>              XX <- X - rep(f$means, rep.int(n, nvar)) #>              se.fit <- drop(((XX %*% f$var) * XX) %*% rep(1, ncol(XX)))^0.5 #>              names(se.fit) <- rnam #>              f$se.fit <- se.fit #>          } #>      } #>      if (model)  #>          f$model <- data #>      if (is.character(surv) || surv) { #>          if (length(Strata)) { #>              iStrata <- as.character(Strata) #>              slev <- levels(Strata) #>              nstr <- length(slev) #>          } #>          else nstr <- 1 #>          srv <- NULL #>          tim <- NULL #>          s.e. <- NULL #>          timepts <- seq(0, maxtime, by = time.inc) #>          s.sum <- array(double(1), c(length(timepts), nstr, 3),  #>              list(format(timepts), paste(\"Stratum\", 1:nstr), c(\"Survival\",  #>                  \"n.risk\", \"std.err\"))) #>          g <- list(n = sum(f$n), coefficients = f$coefficients,  #>              linear.predictors = f$linear.predictors, method = f$method,  #>              type = type, means = f$means, var = f$var, x = X,  #>              y = Y, strata = Strata, offset = offset, weights = weights,  #>              terms = Terms, call = call) #>          g <- survfit.cph(g, se.fit = is.character(surv) || surv,  #>              type = type, vartype = vartype, conf.type = \"log\") #>          strt <- if (nstr > 1)  #>              rep(names(g$strata), g$strata) #>          for (k in 1:nstr) { #>              j <- if (nstr == 1)  #>                  TRUE #>              else strt == slev[k] #>              yy <- Y[if (nstr == 1)  #>                  TRUE #>              else iStrata == slev[k], ny - 1] #>              maxt <- max(yy) #>              tt <- c(0, g$time[j]) #>              su <- c(1, g$surv[j]) #>              se <- c(NA, g$std.err[j]) #>              if (maxt > tt[length(tt)]) { #>                  tt <- c(tt, maxt) #>                  su <- c(su, su[length(su)]) #>                  se <- c(se, NA) #>              } #>              kk <- 0 #>              for (tp in timepts) { #>                  kk <- kk + 1 #>                  t.choice <- max((1:length(tt))[tt <= tp + 1e-06]) #>                  if (tp > max(tt) + 1e-06 & su[length(su)] > 0) { #>                    Su <- NA #>                    Se <- NA #>                  } #>                  else { #>                    Su <- su[t.choice] #>                    Se <- se[t.choice] #>                  } #>                  n.risk <- sum(yy >= tp) #>                  s.sum[kk, k, 1:3] <- c(Su, n.risk, Se) #>              } #>              if (!is.character(surv)) { #>                  if (nstr == 1) { #>                    tim <- tt #>                    srv <- su #>                    s.e. <- se #>                  } #>                  else { #>                    tim <- c(tim, list(tt)) #>                    srv <- c(srv, list(su)) #>                    s.e. <- c(s.e., list(se)) #>                  } #>              } #>          } #>          if (is.character(surv))  #>              f$surv.summary <- s.sum #>          else { #>              if (nstr > 1) { #>                  names(srv) <- names(tim) <- names(s.e.) <- levels(Strata) #>              } #>              f <- c(f, list(time = tim, surv = srv, std.err = s.e.,  #>                  surv.summary = s.sum)) #>          } #>      } #>      f$strata <- Strata #>      if (x)  #>          f$x <- X #>      if (y)  #>          f$y <- Y #>      f$weights <- weights #>      f$offset <- offset #>      if (!linear.predictors)  #>          f$linear.predictors <- NULL #>      if (!residuals)  #>          f$residuals <- NULL #>      class(f) <- c(\"cph\", \"rms\", \"coxph\") #>      f #>  })(formula = Surv(time, status) ~ X2, data = structure(list(time = c(0.485624671863262,  #>  1.26409376042954, 1.33666658193828, 1.8876406134119, 2.31585909834859,  #>  2.53142323120341, 2.67405539887999, 2.69682636249489, 3.04496515034811,  #>  3.33099029359641, 3.45667132868933, 3.6604107498161, 3.9366262675404,  #>  4.23594158088559, 4.34869495838047, 4.43144745795761, 4.4598771336945,  #>  4.68239441160373, 5.06756240443228, 6.36681483353204, 6.46626318654265,  #>  7.12297337435571, 7.30485475634867, 7.34387535566165, 7.56803748444143,  #>  7.62294895297476, 8.4923916991555, 8.82720753717643, 11.9858149603988,  #>  14.6952284599549), status = c(1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,  #>  0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1), X2 = c(0.737784077209451,  #>  0.208242935671302, -0.0857343344820172, -1.17625414199995, 0.134013692019997,  #>  0.88812084100851, 0.761534674446218, -0.230798720053901, -0.551165311562187,  #>  0.0203205955518868, 1.15478690980615, 2.06122996814056, -1.23681891186452,  #>  1.50293414722451, 0.806509249150504, 0.670331809310477, -1.29286800723766,  #>  0.441911199605587, -0.920611029980694, 0.427200660684708, 1.43374439008612,  #>  -0.92076145785956, -2.09617436394711, -0.310693352821634, 0.310154484013825,  #>  0.250866817041062, -0.0648836508035696, -0.145929333271849, -0.839686914881022,  #>  -0.179535721967552)), row.names = c(\"27\", \"9\", \"11\", \"12\", \"26\",  #>  \"21\", \"5\", \"28\", \"3\", \"4\", \"22\", \"7\", \"18\", \"6\", \"24\", \"14\",  #>  \"17\", \"1\", \"8\", \"16\", \"23\", \"25\", \"13\", \"15\", \"30\", \"2\", \"19\",  #>  \"29\", \"10\", \"20\"), class = \"data.frame\"), x = TRUE, y = TRUE,  #>      eps = 1e-06, surv = TRUE) #>   #>                          Model Tests    Discrimination     #>                                                Indexes     #>  Obs         30    LR chi2      3.41    R2       0.123     #>  Events      13    d.f.            1    Dxy      0.253     #>  Center -0.0369    Pr(> chi2) 0.0648    g        0.674     #>                    Score chi2   3.52    gr       1.962     #>                    Pr(> chi2) 0.0606                       #>   #>     Coef    S.E.   Wald Z Pr(>|Z|) #>  X2 -0.6300 0.3394 -1.86  0.0634   #>    plot(WKM$fit) lines(sort(unique(dat$time)),       1-WCox$IPCW.times[1,],       type=\"l\",       col=2,       lty=3,       lwd=3) lines(sort(unique(dat$time)),       1-WCox$IPCW.times[5,],       type=\"l\",       col=3,       lty=3,       lwd=3)   # using the stratified Kaplan-Meier # for the censoring times given X2  WKM2=ipcw(Hist(time,status)~X2,   data=dat,   method=\"nonpar\",   times=sort(unique(dat$time)),   subject.times=dat$time,keep=c(\"fit\")) plot(WKM2$fit,add=FALSE)"},{"path":"/reference/model.matrix.cph.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract design matrix for cph objects — model.matrix.cph","title":"Extract design matrix for cph objects — model.matrix.cph","text":"Extract design matrix cph objects","code":""},{"path":"/reference/model.matrix.cph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract design matrix for cph objects — model.matrix.cph","text":"","code":"# S3 method for cph model.matrix(object, data)"},{"path":"/reference/model.matrix.cph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract design matrix for cph objects — model.matrix.cph","text":"object cph object. data dataset.","code":""},{"path":"/reference/model.matrix.phreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract design matrix for phreg objects — model.matrix.phreg","title":"Extract design matrix for phreg objects — model.matrix.phreg","text":"Extract design matrix phreg objects","code":""},{"path":"/reference/model.matrix.phreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract design matrix for phreg objects — model.matrix.phreg","text":"","code":"# S3 method for phreg model.matrix(object, data)"},{"path":"/reference/model.matrix.phreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract design matrix for phreg objects — model.matrix.phreg","text":"object phreg object. data dataset.","code":""},{"path":"/reference/model.matrix.phreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract design matrix for phreg objects — model.matrix.phreg","text":"mainly copy paste begining phreg function.","code":""},{"path":"/reference/penalizedS3.html","id":null,"dir":"Reference","previous_headings":"","what":"S3-wrapper for S4 function penalized — penalizedS3","title":"S3-wrapper for S4 function penalized — penalizedS3","text":"S3-wrapper S4 function penalized","code":""},{"path":"/reference/penalizedS3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3-wrapper for S4 function penalized — penalizedS3","text":"","code":"penalizedS3(formula, data, type = \"elastic.net\", lambda1, lambda2, fold, ...)"},{"path":"/reference/penalizedS3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3-wrapper for S4 function penalized — penalizedS3","text":"formula Communicated outcome explanatory variables. See examples. data Data set formula interpreted type String specifying type penalization. match one following values: \"ridge\", \"lasso\", \"elastic.net\". lambda1 Lasso penalty lambda2 ridge penalty fold passed penalized::profL1 ... Arguments passed penalized","code":""},{"path":"/reference/penalizedS3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S3-wrapper for S4 function penalized — penalizedS3","text":"","code":"library(prodlim) if (FALSE) { ## too slow if (requireNamespace(\"penalized\",quietly=TRUE)){ library(penalized) set.seed(8) d <- sampleData(200,outcome=\"binary\") newd <- sampleData(80,outcome=\"binary\") fitridge <- penalizedS3(Y~X1+X2+pen(7:8), data=d, type=\"ridge\",                 standardize=TRUE, model=\"logistic\",trace=FALSE) fitlasso <- penalizedS3(Y~X1+X2+pen(7:8), data=d, type=\"lasso\",                 standardize=TRUE, model=\"logistic\",trace=FALSE) # fitnet <- penalizedS3(Y~X1+X2+pen(7:8), data=d, type=\"elastic.net\", # standardize=TRUE, model=\"logistic\",trace=FALSE) predictRisk(fitridge,newdata=newd) predictRisk(fitlasso,newdata=newd) # predictRisk(fitnet,newdata=newd) Score(list(fitridge),data=newd,formula=Y~1) Score(list(fitridge),data=newd,formula=Y~1,split.method=\"bootcv\",B=2) data(nki70) ## S4 fit fitS4 <- penalized(Surv(time, event), penalized = nki70[,8:77],                  unpenalized = ~ER+Age+Diam+N+Grade, data = nki70,                  lambda1 = 1) fitS3 <- penalizedS3(Surv(time,event)~ER+Age+Diam+pen(8:77)+N+Grade,                      data=nki70, lambda1=1) ## or penS3 <- penalizedS3(Surv(time,event)~ER+pen(TSPYL5,Contig63649_RC)+pen(10:77)+N+Grade,                      data=nki70, lambda1=1) ## also this works penS3 <- penalizedS3(Surv(time,event)~ER+Age+pen(8:33)+Diam+pen(34:77)+N+Grade,                     data=nki70, lambda1=1) }}"},{"path":"/reference/plot.riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting predicted risk — plot.riskRegression","title":"Plotting predicted risk — plot.riskRegression","text":"Show predicted risk obtained risk prediction model function time.","code":""},{"path":"/reference/plot.riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting predicted risk — plot.riskRegression","text":"","code":"# S3 method for riskRegression plot(x,   cause,   newdata,   xlab,   ylab,   xlim,   ylim,   lwd,   col,   lty,   axes=TRUE,   percent=TRUE,   legend=TRUE,   add=FALSE,   ...)"},{"path":"/reference/plot.riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting predicted risk — plot.riskRegression","text":"x Fitted object obtained one ARR, LRR, riskRegression. cause CauseSpecificCox models cause interest. newdata data frame containing predictor variable combinations compute predicted risk. xlab See plot ylab See plot xlim See plot ylim See plot lwd vector line thicknesses regression coefficients. col vector colors regression coefficients. lty vector line types regression coefficients. axes Logical. FALSE draw axes. percent true y-axis labeled percent. legend true draw legend. add Logical. TRUE add lines existing plot. ... Used transclusion smart arguments plot, lines, axis background. See function SmartControl prodlim.","code":""},{"path":"/reference/plot.riskRegression.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting predicted risk — plot.riskRegression","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/plot.riskRegression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting predicted risk — plot.riskRegression","text":"","code":"library(survival) library(prodlim) data(Melanoma) fit.arr <- ARR(Hist(time,status)~invasion+age+strata(sex),data=Melanoma,cause=1) plot(fit.arr,xlim=c(500,3000)) #> Warning: Argument newdata is missing. #> Shown are the cumulative incidence curves from the original data set. #> Selected are curves based on individual risk (min,q25,median,q75,max) at the median time:1112.25714285714"},{"path":"/reference/plotAUC.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of time-dependent AUC curves — plotAUC","title":"Plot of time-dependent AUC curves — plotAUC","text":"Plot time-dependent AUC curves","code":""},{"path":"/reference/plotAUC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of time-dependent AUC curves — plotAUC","text":"","code":"plotAUC(   x,   models,   which = \"score\",   xlim,   ylim,   xlab,   ylab,   col,   lwd,   lty = 1,   cex = 1,   pch = 1,   type = \"l\",   axes = 1L,   percent = 1L,   conf.int = 0L,   legend = 1L,   ... )"},{"path":"/reference/plotAUC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of time-dependent AUC curves — plotAUC","text":"x Object obtained Score.list models Choice models plot Character. Either \"score\" show AUC \"contrasts\" show differences AUC. xlim Limits x-axis ylim Limits y-axis xlab Label x-axis ylab Label y-axis col line color lwd line width lty line style cex point size pch point style type line type axes Logical. TRUE draw axes. percent Logical. TRUE scale y-axis percent. conf.int Logical. TRUE draw confidence shadows. legend Logical. TRUE draw legend. ... Used additional control subroutines: plot,","code":""},{"path":"/reference/plotAUC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of time-dependent AUC curves — plotAUC","text":"","code":"library(survival) library(prodlim) d=sampleData(100,outcome=\"survival\") nd=sampleData(100,outcome=\"survival\") f1=coxph(Surv(time,event)~X1+X6+X8,data=d,x=TRUE,y=TRUE) f2=coxph(Surv(time,event)~X2+X5+X9,data=d,x=TRUE,y=TRUE) xx=Score(list(\"X1+X6+X8\"=f1,\"X2+X5+X9\"=f2), formula=Surv(time,event)~1, data=nd, metrics=\"auc\", null.model=FALSE, times=seq(3:10)) aucgraph <- plotAUC(xx)  plotAUC(xx,conf.int=TRUE)  ## difference between  plotAUC(xx,which=\"contrasts\",conf.int=TRUE)"},{"path":"/reference/plotBrier.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Brier curve — plotBrier","title":"Plot Brier curve — plotBrier","text":"Plot Brier score curves","code":""},{"path":"/reference/plotBrier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Brier curve — plotBrier","text":"","code":"plotBrier(   x,   models,   which = \"score\",   xlim,   ylim,   xlab,   ylab,   col,   lwd,   lty = 1,   cex = 1,   pch = 1,   type = \"l\",   axes = 1L,   percent = 1L,   conf.int = 0L,   legend = 1L,   ... )"},{"path":"/reference/plotBrier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Brier curve — plotBrier","text":"x Object obtained Score models Choice models plot Character. Either \"score\" show AUC \"contrasts\" show differences AUC. xlim Limits x-axis ylim Limits y-axis xlab Label x-axis ylab Label y-axis col line color lwd line width lty line style cex point size pch point style type line type axes Logical. TRUE draw axes. percent Logical. TRUE scale y-axis percent. conf.int Logical. TRUE draw confidence shadows. legend Logical. TRUE draw legend. ... Used additional control subroutines: plot, axis, lines, legend. See SmartControl.","code":""},{"path":"/reference/plotBrier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Brier curve — plotBrier","text":"","code":"# survival library(survival) library(prodlim) ds1=sampleData(40,outcome=\"survival\") ds2=sampleData(40,outcome=\"survival\") f1 <- coxph(Surv(time,event)~X1+X3+X5+X7+X9,data=ds1,x=TRUE) f2 <- coxph(Surv(time,event)~X2+X4+X6+X8+X10,data=ds1,x=TRUE) xscore <- Score(list(f1,f2),formula=Hist(time,event)~1,data=ds2,times=0:12,metrics=\"brier\") plotBrier(xscore)"},{"path":"/reference/plotCalibration.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Calibration curve — plotCalibration","title":"Plot Calibration curve — plotCalibration","text":"Plot Calibration curves risk prediction models","code":""},{"path":"/reference/plotCalibration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Calibration curve — plotCalibration","text":"","code":"plotCalibration(   x,   models,   times,   method = \"nne\",   cens.method,   round = TRUE,   bandwidth = NULL,   q = 10,   bars = FALSE,   hanging = FALSE,   names = \"quantiles\",   pseudo = FALSE,   rug,   show.frequencies = FALSE,   plot = TRUE,   add = FALSE,   diag = !add,   legend = !add,   auc.in.legend,   brier.in.legend,   axes = !add,   xlim = c(0, 1),   ylim = c(0, 1),   xlab = ifelse(bars, \"Risk groups\", \"Predicted risk\"),   ylab,   col,   lwd,   lty,   pch,   type,   percent = TRUE,   na.action = na.fail,   cex = 1,   ... )"},{"path":"/reference/plotCalibration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Calibration curve — plotCalibration","text":"x Object obtained function Score models Choice models plot times Time point specifying prediction horizon. method method estimating calibration curve(s): \"quantile\"observed proportion predicted risk value 'p' obtained groups defined quantiles predicted event probabilities subjects. number groups controlled argument q. \"nne\": observed proportion predicted risk value 'p' obtained based subjects whose predicted risk inside nearest neighborhood around value 'p'. larger bandwidth subjects included current neighborhood. cens.method right censored data . observed proportions calculated. Either \"jackknife\" \"local\": \"jackknife\"Compute running mean jackknife pseudovalues across neighborhoods/groups predicted risks. rely assumption censoring independent event time covariates, see References. \"local\"Compute Kaplan-Meier estimator absence competing risks Aalen-Johansen estimator presence competing risks locally like running mean neighborhoods predicted risks. widths neighborhoods defined according method. round TRUE predicted probabilities rounded two digits smoothing. may considerable effect computing efficiency large data sets. bandwidth bandwidth method=\"nne\" q number quantiles method=\"quantile\" bars=TRUE. bars TRUE, use barplots show calibration. hanging Barplots . TRUE, hang bars corresponding observed frequencies (estimated actual risk)  value corresponding prediction. names Barplots . Names argument passed names.arg barplot. pseudo TRUE show pseudo values (right censored data). rug TRUE show rug plot predictions show.frequencies Barplots . TRUE, show frequencies bars. plot FALSE, plot results, just return plottable object. add TRUE line(s) added existing plot. diag FALSE diagonal line drawn. legend Logical. TRUE draw legend. auc..legend Logical. TRUE add AUC legend. brier..legend Logical. TRUE add Brier score legend. axes FALSE axes drawn. xlim Limits x-axis. ylim Limits y-axis. xlab Label y-axis. ylab Label x-axis. col Vector colors, one element object. Passed lines. lwd Vector line widths, one element object. Passed lines. lty lwd Vector line style, one element object.  Passed lines. pch Passed lines. type Passed lines. percent TRUE axes labels multiplied 100 thus interpretable percent scale. na.action NA values. Passed model.frame cex Default cex used legend labels. ... Used control subroutines: plot, axis, lines, barplot, legend, addtable2plot, points (pseudo values), rug. See SmartControl.","code":""},{"path":"/reference/plotCalibration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Calibration curve — plotCalibration","text":"uncensored data, observed frequency outcome event calculated locally predicted risk. right censored data without competing risks, actual risk calculated using Kaplan-Meier Aalen-Johansen method, respectively, locally predicted risk.","code":""},{"path":"/reference/plotCalibration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Calibration curve — plotCalibration","text":"","code":"library(prodlim) # binary  db=sampleData(100,outcome=\"binary\") fb1=glm(Y~X1+X5+X7,data=db,family=\"binomial\") fb2=glm(Y~X1+X3+X6+X7,data=db,family=\"binomial\") xb=Score(list(model1=fb1,model2=fb2),Y~1,data=db,           plots=\"cal\") plotCalibration(xb,brier.in.legend=TRUE)  plotCalibration(xb,bars=TRUE,model=\"model1\")  plotCalibration(xb,models=1,bars=TRUE,names.cex=1.3)   # survival library(survival) library(prodlim) dslearn=sampleData(56,outcome=\"survival\") dstest=sampleData(100,outcome=\"survival\") fs1=coxph(Surv(time,event)~X1+X5+X7,data=dslearn,x=1) fs2=coxph(Surv(time,event)~strata(X1)+X3+X6+X7,data=dslearn,x=1) xs=Score(list(Cox1=fs1,Cox2=fs2),Surv(time,event)~1,data=dstest,           plots=\"cal\",metrics=NULL) plotCalibration(xs) #> The default method for estimating calibration curves based on censored data has changed for riskRegression version 2019-9-8 or higher #> Set cens.method=\"jackknife\" to get the estimate using pseudo-values. #> However, note that the option \"jackknife\" is sensititve to violations of the assumption that the censoring is independent of both the event times and the covariates. #> Set cens.method=\"local\" to suppress this message.  plotCalibration(xs,cens.method=\"local\",pseudo=1)  plotCalibration(xs,method=\"quantile\") #> The default method for estimating calibration curves based on censored data has changed for riskRegression version 2019-9-8 or higher #> Set cens.method=\"jackknife\" to get the estimate using pseudo-values. #> However, note that the option \"jackknife\" is sensititve to violations of the assumption that the censoring is independent of both the event times and the covariates. #> Set cens.method=\"local\" to suppress this message.    # competing risks  if (FALSE) { data(Melanoma) f1 <- CSC(Hist(time,status)~age+sex+epicel+ulcer,data=Melanoma) f2 <- CSC(Hist(time,status)~age+sex+logthick+epicel+ulcer,data=Melanoma) x <- Score(list(model1=f1,model2=f2),Hist(time,status)~1,data=Melanoma,            cause= 2,times=5*365.25,plots=\"cal\") plotCalibration(x) }"},{"path":"/reference/plotEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting time-varying effects from a risk regression model. — plotEffects","title":"Plotting time-varying effects from a risk regression model. — plotEffects","text":"Plot time-varying effects risk regression model.","code":""},{"path":"/reference/plotEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting time-varying effects from a risk regression model. — plotEffects","text":"","code":"plotEffects(   x,   formula,   level,   ref.line = TRUE,   conf.int = 0.95,   xlim,   ylim,   xlab = \"Time\",   ylab = \"Cumulative coefficient\",   col,   lty,   lwd,   add = FALSE,   legend,   axes = TRUE,   ... )"},{"path":"/reference/plotEffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting time-varying effects from a risk regression model. — plotEffects","text":"x Fitted object obtained one ARR, LRR, riskRegression. formula formula specify variable(s) whose regression coefficients plotted. level categorical variables level (group) whose contrast reference level (group) plotted. ref.line Logical. TRUE add horizontal line zero. conf.int Logical. TRUE add confidence limits.  Can controlled using smart arguments. See examples xlim See plot ylim See plot xlab See plot ylab See plot col vector colors regression coefficients. lty vector line types regression coefficients. lwd vector line thicknesses regression coefficients. add Logical. TRUE add lines existing plot. legend Logical. TRUE add legend. Can controlled using smart arguments. See examples. axes Logical. FALSE draw axes. ... Used transclusion smart arguments plot, axis. See function SmartControl prodlim.","code":""},{"path":"/reference/plotEffects.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting time-varying effects from a risk regression model. — plotEffects","text":"Thomas H. Scheike ts@biostat.ku.dk Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/plotEffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting time-varying effects from a risk regression model. — plotEffects","text":"","code":"library(survival) library(prodlim) data(Melanoma)  fit.tarr <- ARR(Hist(time,status)~strata(sex),                 data=Melanoma,                 cause=1) plotEffects(fit.tarr)   fit.tarr <- ARR(Hist(time,status)~strata(sex)+strata(invasion),                 data=Melanoma,                 cause=1,                 times=seq(800,3000,20)) plotEffects(fit.tarr,formula=~sex)  plotEffects(fit.tarr,formula=~invasion)  plotEffects(fit.tarr,             formula=~invasion,             level=\"invasionlevel.1\")   ## legend arguments are transcluded: plotEffects(fit.tarr,             formula=~invasion,             legend.bty=\"b\",             legend.cex=1)   ## and other smart arguments too: plotEffects(fit.tarr,       formula=~invasion,       legend.bty=\"b\", axis2.las=2,       legend.cex=1)"},{"path":"/reference/plotPredictRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting predicted risks curves. — plotPredictRisk","title":"Plotting predicted risks curves. — plotPredictRisk","text":"Time-dependent event risk predictions.","code":""},{"path":"/reference/plotPredictRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting predicted risks curves. — plotPredictRisk","text":"","code":"plotPredictRisk(   x,   newdata,   times,   cause = 1,   xlim,   ylim,   xlab,   ylab,   axes = TRUE,   col,   density,   lty,   lwd,   add = FALSE,   legend = TRUE,   percent = FALSE,   ... )"},{"path":"/reference/plotPredictRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting predicted risks curves. — plotPredictRisk","text":"x Object specifying event risk prediction model. newdata data frame variable names used fit model x. times Vector times return estimated probabilities. cause Show predicted risk events cause xlim Plotting range x-axis. ylim Plotting range y-axis. xlab Label given x-axis. ylab Label given y-axis. axes Logical. FALSE axes drawn. col Vector colors given survival curve. density Densitiy color -- useful showing many (overlapping) curves. lty Vector lty's given survival curve. lwd Vector lwd's given survival curve. add Logical. TRUE lines added existing device legend Logical. TRUE legend plotted calling function legend.  Optional arguments function legend can given form legend.x=val x name argument val desired value. See also Details. percent Logical. TRUE y-axis labeled percent. ... Parameters filtered SmartControl passed functions: plot, axis, legend.","code":""},{"path":"/reference/plotPredictRisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting predicted risks curves. — plotPredictRisk","text":"(invisible) object.","code":""},{"path":"/reference/plotPredictRisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting predicted risks curves. — plotPredictRisk","text":"Arguments invoked functions legend axis can specified legend.lty=2. specification case sensitive, thus Legend.lty=2 LEGEND.lty=2 effect. function axis called twice, arguments form axis1.labels, axis1.used time axis whereas axis2.pos, axis1.labels, etc., used y-axis. arguments processed via ...{} plotPredictRisk inside using function SmartControl.","code":""},{"path":"/reference/plotPredictRisk.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting predicted risks curves. — plotPredictRisk","text":"Ulla B. Mogensen, Hemant Ishwaran, Thomas . Gerds (2012). Evaluating Random Forests Survival Analysis Using Prediction Error Curves. Journal Statistical Software, 50(11), 1-23. URL http://www.jstatsoft.org/v50/i11/.","code":""},{"path":[]},{"path":"/reference/plotPredictRisk.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting predicted risks curves. — plotPredictRisk","text":"Ulla B. Mogensen Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/plotPredictRisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting predicted risks curves. — plotPredictRisk","text":"","code":"library(survival) # generate survival data # no effect set.seed(8) d <- sampleData(80,outcome=\"survival\",formula = ~f(X6, 0) + f(X7, 0)) d[,table(event)] #> event #>  0  1  #> 40 40  f <- coxph(Surv(time,event)~X6+X7,data=d,x=1) plotPredictRisk(f) #> Error in eval(x$call$data): object 'd' not found  # large effect set.seed(8) d <- sampleData(80,outcome=\"survival\",formula = ~f(X6, 0.1) + f(X7, -0.1)) d[,table(event)] #> event #>  0  1  #> 41 39  f <- coxph(Surv(time,event)~X6+X7,data=d,x=1) plotPredictRisk(f) #> Error in eval(x$call$data): object 'd' not found  # generate competing risk data # small effect set.seed(8) d <- sampleData(40,formula = ~f(X6, 0.01) + f(X7, -0.01)) d[,table(event)] #> event #>  0  1  2  #> 11 16 13  f <- CSC(Hist(time,event)~X5+X6,data=d) plotPredictRisk(f) #> Error in eval(x$call$data): object 'd' not found  # large effect set.seed(8) d <- sampleData(40,formula = ~f(X6, 0.1) + f(X7, -0.1)) d[,table(event)] #> event #>  0  1  2  #>  7 21 12  f <- CSC(Hist(time,event)~X5+X6,data=d) plotPredictRisk(f) #> Error in eval(x$call$data): object 'd' not found"},{"path":"/reference/plotROC.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot ROC curves — plotROC","title":"Plot ROC curves — plotROC","text":"Plot ROC curve","code":""},{"path":"/reference/plotROC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot ROC curves — plotROC","text":"","code":"plotROC(   x,   models,   times,   xlab = \"1-Specificity\",   ylab = \"Sensitivity\",   col,   lwd,   lty = 1,   cex = 1,   pch = 1,   legend = TRUE,   auc.in.legend = TRUE,   brier.in.legend = FALSE,   add = FALSE,   ... )"},{"path":"/reference/plotROC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot ROC curves — plotROC","text":"x Object obtained function Score models Choice models plot times Time point(s) specifying prediction horizon xlab Label x-axis ylab Label y-axis col line color lwd line width lty line style cex point size pch point style legend logical. 1L draw legend values AUC. auc..legend Logical. TRUE add AUC legend. brier..legend Logical. TRUE add Brier score legend. add logical. 1L add lines existing plot. ... Used additional control subroutines: plot, axis, lines, legend, addtable2plot. See SmartControl.","code":""},{"path":"/reference/plotROC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot ROC curves — plotROC","text":"","code":"## binary set.seed(18) if (requireNamespace(\"randomForest\",quietly=TRUE)){ library(randomForest) library(prodlim) bdl <- sampleData(40,outcome=\"binary\") bdt <- sampleData(58,outcome=\"binary\") bdl[,y:=factor(Y)] bdt[,y:=factor(Y)] fb1 <- glm(y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,data=bdl,family=\"binomial\") fb2 <- randomForest(y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10,data=bdl) xb <- Score(list(\"glm\"=fb1,\"rf\"=fb2),y~1,data=bdt,             plots=\"roc\",metrics=c(\"auc\",\"brier\")) plotROC(xb,brier.in.legend=1L)  # with cross-validation if (FALSE) { xb3 <- Score(list(\"glm\"=fb1,\"rf\"=fb2),y~1,data=bdl,             plots=\"roc\",B=3,split.method=\"bootcv\",             metrics=c(\"auc\")) } } #> randomForest 4.6-14 #> Type rfNews() to see new features/changes/bug fixes. #>  #> Attaching package: ‘randomForest’ #> The following object is masked from ‘package:ggplot2’: #>  #>     margin  ## survival set.seed(18) library(survival) sdl <- sampleData(40,outcome=\"survival\") sdt <- sampleData(58,outcome=\"survival\") fs1 <- coxph(Surv(time,event)~X3+X5+X6+X7+X8+X10,data=sdl,x=TRUE) fs2 <- coxph(Surv(time,event)~X1+X2+X9,data=sdl,x=TRUE) xs <- Score(list(model1=fs1,model2=fs2),Hist(time,event)~1,data=sdt,             times=5,plots=\"roc\",metrics=\"auc\") plotROC(xs)  ## competing risks data(Melanoma) f1 <- CSC(Hist(time,status)~age+sex+epicel+ulcer,data=Melanoma) f2 <- CSC(Hist(time,status)~age+sex+logthick+epicel+ulcer,data=Melanoma) x <- Score(list(model1=f1,model2=f2),Hist(time,status)~1,data=Melanoma,             cause=1,times=5*365.25,plots=\"roc\",metrics=\"auc\") plotROC(x)"},{"path":"/reference/plotRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"plot predicted risks — plotRisk","title":"plot predicted risks — plotRisk","text":"plot predicted risks","code":""},{"path":"/reference/plotRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot predicted risks — plotRisk","text":"","code":"plotRisk(   x,   models,   times,   xlim = c(0, 1),   ylim = c(0, 1),   xlab,   ylab,   col,   pch,   cex = 1,   preclipse = 0,   preclipse.shade = FALSE,   ... )"},{"path":"/reference/plotRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot predicted risks — plotRisk","text":"x Object obtained function Score models Choice two models plot. predicted risks first (second) shown along x-axis (y-axis). times Time point specifying prediction horizon. xlim x-axis limits ylim y-axis limits xlab x-axis labels ylab y-axis labels col Colors used according outcome. binary outcome (two colors: event, event), survival outcome (three colors: censored, event, event) competing risk outcome (4 colors: event, competing risk 1, ..., competing risk k, censored, event) pch Symbols used according outcome binary outcome (two symbols: event, event), survival outcome (three symbols: censored, event, event) competing risk outcome (4 symbols: event, competing risk 1, ..., competing risk k, censored, event) cex point size preclipse Value 0 1 defining preclipse area preclipse.shade Logical. TRUE shade area clinically meaningful change. ... Used control subroutines: plot, axis, lines, barplot, legend. See SmartControl.","code":""},{"path":"/reference/plotRisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot predicted risks — plotRisk","text":"nice graph","code":""},{"path":"/reference/plotRisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plot predicted risks — plotRisk","text":"Two rival prediction models applied data.","code":""},{"path":"/reference/plotRisk.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plot predicted risks — plotRisk","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/plotRisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot predicted risks — plotRisk","text":"","code":"library(prodlim) ## uncensored learndat = sampleData(40,outcome=\"binary\") testdat = sampleData(40,outcome=\"binary\") lr1 = glm(Y~X1+X2+X7+X9,data=learndat,family=\"binomial\") lr2 = glm(Y~X3+X5+X6,data=learndat,family=\"binomial\") xb=Score(list(\"LR(X1+X2+X7+X9)\"=lr1,\"LR(X3+X5+X6)\"=lr2),formula=Y~1,          data=testdat,summary=\"risks\",null.model=0L) plotRisk(xb)  ## survival library(survival) learndat = sampleData(40,outcome=\"survival\") testdat = sampleData(40,outcome=\"survival\") cox1 = coxph(Surv(time,event)~X1+X2+X7+X9,data=learndat,x=TRUE) cox2 = coxph(Surv(time,event)~X3+X5+X6,data=learndat,x=TRUE) xs=Score(list(\"Cox(X1+X2+X7+X9)\"=cox1,\"Cox(X3+X5+X6)\"=cox2),formula=Surv(time,event)~1,          data=testdat,summary=\"risks\",null.model=0L,times=c(3,5,6)) plotRisk(xs,times=5)  ## competing risk if (FALSE) { library(prodlim) library(survival) set.seed(8) learndat = sampleData(80,outcome=\"competing.risk\") testdat = sampleData(140,outcome=\"competing.risk\") m1 = FGR(Hist(time,event)~X2+X7+X9,data=learndat,cause=1) m2 = CSC(Hist(time,event)~X2+X7+X9,data=learndat,cause=1) xcr=Score(list(\"FGR\"=m1,\"CSC\"=m2),formula=Hist(time,event)~1,          data=testdat,summary=\"risks\",null.model=0L,times=c(3,5)) plotRisk(xcr,times=1) }"},{"path":"/reference/predict.CauseSpecificCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"Apply formula combine two Cox models absolute risk (cumulative incidence function).","code":""},{"path":"/reference/predict.CauseSpecificCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"","code":"# S3 method for CauseSpecificCox predict(   object,   newdata,   times,   cause,   type = \"absRisk\",   landmark = NA,   keep.times = 1L,   keep.newdata = 1L,   keep.strata = 1L,   se = FALSE,   band = FALSE,   iid = FALSE,   confint = (se + band) > 0,   average.iid = FALSE,   product.limit = TRUE,   store.iid = \"full\",   diag = FALSE,   max.time = NULL,   ... )"},{"path":"/reference/predict.CauseSpecificCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"object fitted cause specific Cox model newdata [data.frame data.table]  Contain values predictor variables defining subject specific predictions relative cause. structure data set used fit object. times [numeric vector] Time points return estimated absolute risk. cause [integer/character] Identifies cause interest among competing events. type [character] Can changed \"survival\" event free survival output instead absolute risk. landmark [integer] starting time computation cumulative risk. keep.times [logical] TRUE add evaluation times output. keep.newdata [logical] TRUE add value covariates used make prediction output list. keep.strata [logical] TRUE add value strata used make prediction output list. se [logical] TRUE compute add standard errors output. band [logical] TRUE compute add quantiles confidence bands output. iid [logical] TRUE compute add influence function output. confint [logical] TRUE compute add confidence intervals/bands output. computed applying confint function output. average.iid [logical]. TRUE add average influence function newdata output. product.limit [logical]. TRUE survival computed using product limit estimator. Otherwise exponential approximation used (.e. exp(-cumulative hazard)). store.iid [character] Implementation used estimate influence function standard error. Can \"full\" \"minimal\". diag [logical] FALSE absolute risk/survival observations times computed, otherwise computed -th observation -th time. max.time [numeric] maximum time response fitted data.  relevant model response element removed ... used.","code":""},{"path":"/reference/predict.CauseSpecificCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"function computes absolute risk given formula 2 (Ozenne et al., 2017). Confidence intervals confidence bands can computed using first order von Mises expansion. See section \"Construction confidence intervals\" (Ozenne et al., 2017). detailed explanation meaning argument store.iid can found (Ozenne et al., 2017) Appendix B \"Saving influence functions\". Note: Cox regression models time varying     covariates make sense use function,     predicted risk measurable function data     available time origin. iid decomposition output using array containing value influence subject used fit object (dim 1), subject newdata (dim 3), time (dim 2).","code":""},{"path":"/reference/predict.CauseSpecificCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"Brice Ozenne, Anne Lyngholm Sorensen, Thomas Scheike, Christian Torp-Pedersen Thomas Alexander Gerds. riskRegression: Predicting Risk Event using Cox Regression Models. R Journal (2017) 9:2, pages 440-460.","code":""},{"path":[]},{"path":"/reference/predict.CauseSpecificCox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"Brice Ozenne broz@sund.ku.dk, Thomas . Gerds     tag@biostat.ku.dk","code":""},{"path":"/reference/predict.CauseSpecificCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predicting Absolute Risk from Cause-Specific Cox Models — predict.CauseSpecificCox","text":"","code":"library(survival) library(prodlim) #### generate data #### set.seed(5) d <- sampleData(80,outcome=\"comp\") ## training dataset nd <- sampleData(4,outcome=\"comp\") ## validation dataset d$time <- round(d$time,1) ## create tied events ttt <- sort(sample(x = unique(d$time), size = 10))  ## estimate a CSC model based on the coxph function CSC.fit <- CSC(Hist(time,event)~ X3+X8, data=d, method = \"breslow\")  ## compute the absolute risk of cause 1, in the validation dataset ## at time 1:10 CSC.risk <-  predict(CSC.fit, newdata=nd, times=1:10, cause=1) CSC.risk #>     observation X3      X8 times absRisk #>  1:           1  1 -1.5612     1  0.0969 #>  2:           2  1 -0.7577     1  0.0948 #>  3:           3  0  1.5421     1  0.0810 #>  4:           4  0 -0.0647     1  0.0847 #>  5:           1  1 -1.5612     2  0.2667 #>  6:           2  1 -0.7577     2  0.2617 #>  7:           3  0  1.5421     2  0.2270 #>  8:           4  0 -0.0647     2  0.2359 #>  9:           1  1 -1.5612     3  0.3574 #> 10:           2  1 -0.7577     3  0.3520 #> 11:           3  0  1.5421     3  0.3085 #> 12:           4  0 -0.0647     3  0.3186 #> 13:           1  1 -1.5612     4  0.4220 #> 14:           2  1 -0.7577     4  0.4172 #> 15:           3  0  1.5421     4  0.3689 #> 16:           4  0 -0.0647     4  0.3784 #> 17:           1  1 -1.5612     5  0.4572 #> 18:           2  1 -0.7577     5  0.4535 #> 19:           3  0  1.5421     5  0.4036 #> 20:           4  0 -0.0647     5  0.4113 #> 21:           1  1 -1.5612     6  0.4765 #> 22:           2  1 -0.7577     6  0.4738 #> 23:           3  0  1.5421     6  0.4235 #> 24:           4  0 -0.0647     6  0.4295 #> 25:           1  1 -1.5612     7  0.5401 #> 26:           2  1 -0.7577     7  0.5428 #> 27:           3  0  1.5421     7  0.4934 #> 28:           4  0 -0.0647     7  0.4903 #> 29:           1  1 -1.5612     8  0.5625 #> 30:           2  1 -0.7577     8  0.5671 #> 31:           3  0  1.5421     8  0.5185 #> 32:           4  0 -0.0647     8  0.5120 #> 33:           1  1 -1.5612     9  0.5625 #> 34:           2  1 -0.7577     9  0.5671 #> 35:           3  0  1.5421     9  0.5185 #> 36:           4  0 -0.0647     9  0.5120 #> 37:           1  1 -1.5612    10  0.5967 #> 38:           2  1 -0.7577    10  0.6073 #> 39:           3  0  1.5421    10  0.5629 #> 40:           4  0 -0.0647    10  0.5456 #>     observation X3      X8 times absRisk  ## compute absolute risks with CI for cause 2 ## (without displaying the value of the covariates) predict(CSC.fit,newdata=nd,times=1:10,cause=2,se=TRUE,         keep.newdata = FALSE) #>     observation times absRisk absRisk.se absRisk.lower absRisk.upper #>  1:           1     1 0.00000     0.0000      0.000000        0.0000 #>  2:           2     1 0.00000     0.0000      0.000000        0.0000 #>  3:           3     1 0.00000     0.0000      0.000000        0.0000 #>  4:           4     1 0.00000     0.0000      0.000000        0.0000 #>  5:           1     2 0.01409     0.0155      0.000855        0.0764 #>  6:           2     2 0.01107     0.0113      0.000904        0.0554 #>  7:           3     2 0.00907     0.0111      0.000397        0.0593 #>  8:           4     2 0.01470     0.0153      0.001073        0.0739 #>  9:           1     3 0.06024     0.0455      0.008579        0.1904 #> 10:           2     3 0.04785     0.0258      0.013482        0.1170 #> 11:           3     3 0.04038     0.0297      0.006543        0.1290 #> 12:           4     3 0.06422     0.0379      0.015235        0.1651 #> 13:           1     4 0.06024     0.0455      0.008579        0.1904 #> 14:           2     4 0.04785     0.0258      0.013482        0.1170 #> 15:           3     4 0.04038     0.0297      0.006543        0.1290 #> 16:           4     4 0.06422     0.0379      0.015235        0.1651 #> 17:           1     5 0.14687     0.0920      0.026324        0.3636 #> 18:           2     5 0.11898     0.0639      0.030524        0.2729 #> 19:           3     5 0.10403     0.0816      0.011531        0.3174 #> 20:           4     5 0.15961     0.0563      0.068873        0.2841 #> 21:           1     6 0.18485     0.1198      0.027826        0.4513 #> 22:           2     6 0.15128     0.0838      0.034903        0.3454 #> 23:           3     6 0.13399     0.0953      0.017909        0.3663 #> 24:           4     6 0.20173     0.0599      0.100005        0.3286 #> 25:           1     7 0.18485     0.1198      0.027826        0.4513 #> 26:           2     7 0.15128     0.0838      0.034903        0.3454 #> 27:           3     7 0.13399     0.0953      0.017909        0.3663 #> 28:           4     7 0.20173     0.0599      0.100005        0.3286 #> 29:           1     8 0.20546     0.1285      0.032271        0.4822 #> 30:           2     8 0.16927     0.0915      0.039727        0.3760 #> 31:           3     8 0.15172     0.1087      0.018870        0.4083 #> 32:           4     8 0.22556     0.0641      0.114794        0.3590 #> 33:           1     9 0.25516     0.1524      0.040038        0.5600 #> 34:           2     9 0.21404     0.1110      0.050731        0.4506 #> 35:           3     9 0.19687     0.1332      0.025363        0.4873 #> 36:           4     9 0.28284     0.0732      0.151571        0.4294 #> 37:           1    10 0.25516     0.1524      0.040038        0.5600 #> 38:           2    10 0.21404     0.1110      0.050731        0.4506 #> 39:           3    10 0.19687     0.1332      0.025363        0.4873 #> 40:           4    10 0.28284     0.0732      0.151571        0.4294 #>     observation times absRisk absRisk.se absRisk.lower absRisk.upper  ## other example library(survival) CSC.fit.s <- CSC(list(Hist(time,event)~ strata(X1)+X2+X9,  Hist(time,event)~ X2+strata(X4)+X8+X7),data=d, method = \"breslow\") predict(CSC.fit.s,cause=1,times=ttt,se=1L) ## note: absRisk>1 due to small number of observations #> Error in eval(object$call$data): object 'd' not found  ## using the cph function instead of coxph CSC.cph <- CSC(Hist(time,event)~ X1+X2,data=d, method = \"breslow\", fitter = \"cph\")#'  predict(CSC.cph, newdata = d, cause = 2, times = ttt) #>      observation X1 X2 times absRisk #>   1:           1  0  0   0.6   0.000 #>   2:           2  0  0   0.6   0.000 #>   3:           3  0  0   0.6   0.000 #>   4:           4  0  0   0.6   0.000 #>   5:           5  0  1   0.6   0.000 #>  ---                                 #> 796:          76  0  0  11.8   0.499 #> 797:          77  0  0  11.8   0.499 #> 798:          78  0  0  11.8   0.499 #> 799:          79  0  1  11.8   0.340 #> 800:          80  1  0  11.8   0.242  ## landmark analysis T0 <- 1 predCSC.afterT0 <- predict(CSC.fit, newdata = d, cause = 2, times = ttt[ttt>T0], landmark = T0) predCSC.afterT0 #>      observation X3       X8 times absRisk #>   1:           1  0 -0.39410   2.9  0.0761 #>   2:           2  1 -1.51024   2.9  0.0647 #>   3:           3  1  0.00599   2.9  0.0417 #>   4:           4  0  0.85501   2.9  0.0530 #>   5:           5  0  0.72985   2.9  0.0550 #>  ---                                       #> 636:          76  1  0.36861  11.8  0.3184 #> 637:          77  0  0.64851  11.8  0.4514 #> 638:          78  1 -0.43983  11.8  0.3727 #> 639:          79  1 -0.86642  11.8  0.4022 #> 640:          80  0  0.86530  11.8  0.4346"},{"path":"/reference/predict.FGR.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict subject specific risks (cumulative incidence) based on Fine-Gray regression model — predict.FGR","title":"Predict subject specific risks (cumulative incidence) based on Fine-Gray regression model — predict.FGR","text":"Predict subject specific risks (cumulative incidence) based Fine-Gray regression model","code":""},{"path":"/reference/predict.FGR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict subject specific risks (cumulative incidence) based on Fine-Gray regression model — predict.FGR","text":"","code":"# S3 method for FGR predict(object, newdata, times, ...)"},{"path":"/reference/predict.FGR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict subject specific risks (cumulative incidence) based on Fine-Gray regression model — predict.FGR","text":"object Result call FGR newdata Predictor values subjects predict risks times Time points evaluate risks ... passed predict.crr","code":""},{"path":"/reference/predict.FGR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict subject specific risks (cumulative incidence) based on Fine-Gray regression model — predict.FGR","text":"","code":"library(prodlim) library(survival) set.seed(10) d <- sampleData(101, outcome = \"competing.risk\") tFun<-function(t) {t} fgr<-FGR(Hist(time, event)~X1+strata(X2)+X6+cov2(X7, tf=tFun),          data=d, cause=1) #> Error in tFun(c(0.392911272224431, 0.421904610479685, 0.601575364691142, 0.633385199582455, 1.22669236124746, 1.26683498766524, 1.33667437200371, 1.3387626959894, 1.45057104326339, 1.48048991452947, 1.49463893555186, 1.55355521268125, 1.60470135704216, 1.86205485756249, 1.88581229810137, 1.94453437174651, 2.05312486051872, 2.06172320228514, 2.2661119820921, 2.3552778705572, 2.652937999544, 3.11269541580694, 3.45103076329057, 3.78815561354943, 3.78942740213315, 3.81737290768793, 3.98192821690229, 4.43636091274909, 4.46826580155329, 4.58042705407726, 4.63404219292273, 4.72410354359003, 5.00496408681733, 5.4626939690073, 5.65208780128825, 5.73210907408649, 7.43027521529108, 7.77654150983806, 8.75972496611783, 9.34147845016349, 9.53743150919039)): could not find function \"tFun\" predictRisk(fgr,times=5,newdata=d[1:10]) #> Error in predictRisk(fgr, times = 5, newdata = d[1:10]): object 'fgr' not found"},{"path":"/reference/predict.riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict individual risk. — predict.riskRegression","title":"Predict individual risk. — predict.riskRegression","text":"Extract predictions risk prediction model.","code":""},{"path":"/reference/predict.riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict individual risk. — predict.riskRegression","text":"","code":"# S3 method for riskRegression predict(object, newdata, ...)"},{"path":"/reference/predict.riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict individual risk. — predict.riskRegression","text":"object Fitted object obtained one ARR, LRR, riskRegression. newdata data frame containing predictor variable combinations compute predicted risk. ... used","code":""},{"path":"/reference/predict.riskRegression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict individual risk. — predict.riskRegression","text":"Gerds, TA Scheike, T Andersen, PK (2011) Absolute risk regression competing risks: interpretation, link functions prediction Research report 11/8. Department Biostatistics, University Copenhagen","code":""},{"path":"/reference/predict.riskRegression.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predict individual risk. — predict.riskRegression","text":"Thomas H. Scheike ts@biostat.ku.dk Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/predict.riskRegression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict individual risk. — predict.riskRegression","text":"","code":"data(Melanoma) library(prodlim) library(survival)  fit.tarr <- ARR(Hist(time,status)~age+invasion+strata(sex),data=Melanoma,cause=1) predict(fit.tarr,newdata=data.frame(age=48,                      invasion=factor(\"level.1\",                          levels=levels(Melanoma$invasion)),                      sex=factor(\"Female\",levels=levels(Melanoma$sex)))) #> $time #>  [1]  227.6000  273.6286  294.5429  388.2857  432.1429  482.7143  557.9143 #>  [8]  624.2000  643.5714  663.5714  700.5143  743.2571  774.3714  791.8000 #> [15]  817.0000  835.1429  859.8857  869.7714  904.5714  971.2857  979.5714 #> [22] 1017.4000 1050.6000 1060.4000 1073.1429 1151.3714 1228.6857 1254.1714 #> [29] 1279.2000 1347.1429 1461.3714 1510.5714 1533.3714 1555.5429 1577.1429 #> [36] 1613.6000 1661.7429 1689.3429 1737.8286 1951.2857 2061.2286 2074.8857 #> [43] 2105.0000 2179.8857 2331.4286 2439.9143 2539.8000 2744.8000 3019.7143 #> [50] 3338.0000 #>  #> $risk #>   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> 1    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #>   [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] #> 1     1     1     1     1     1     1     1     1     1     1 #>  #> attr(,\"class\") #> [1] \"predictedRisk\" predict(fit.tarr,newdata=data.frame(age=48,                      invasion=factor(\"level.1\",                          levels=levels(Melanoma$invasion)),                      sex=factor(\"Male\",levels=levels(Melanoma$sex)))) #> $time #>  [1]  227.6000  273.6286  294.5429  388.2857  432.1429  482.7143  557.9143 #>  [8]  624.2000  643.5714  663.5714  700.5143  743.2571  774.3714  791.8000 #> [15]  817.0000  835.1429  859.8857  869.7714  904.5714  971.2857  979.5714 #> [22] 1017.4000 1050.6000 1060.4000 1073.1429 1151.3714 1228.6857 1254.1714 #> [29] 1279.2000 1347.1429 1461.3714 1510.5714 1533.3714 1555.5429 1577.1429 #> [36] 1613.6000 1661.7429 1689.3429 1737.8286 1951.2857 2061.2286 2074.8857 #> [43] 2105.0000 2179.8857 2331.4286 2439.9143 2539.8000 2744.8000 3019.7143 #> [50] 3338.0000 #>  #> $risk #>   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> 1    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #>   [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] #> 1     1     1     1     1     1     1     1     1     1     1 #>  #> attr(,\"class\") #> [1] \"predictedRisk\" predict(fit.tarr,newdata=data.frame(age=c(48,58,68),                      invasion=factor(\"level.1\",                          levels=levels(Melanoma$invasion)),                      sex=factor(\"Male\",levels=levels(Melanoma$sex)))) #> $time #>  [1]  227.6000  273.6286  294.5429  388.2857  432.1429  482.7143  557.9143 #>  [8]  624.2000  643.5714  663.5714  700.5143  743.2571  774.3714  791.8000 #> [15]  817.0000  835.1429  859.8857  869.7714  904.5714  971.2857  979.5714 #> [22] 1017.4000 1050.6000 1060.4000 1073.1429 1151.3714 1228.6857 1254.1714 #> [29] 1279.2000 1347.1429 1461.3714 1510.5714 1533.3714 1555.5429 1577.1429 #> [36] 1613.6000 1661.7429 1689.3429 1737.8286 1951.2857 2061.2286 2074.8857 #> [43] 2105.0000 2179.8857 2331.4286 2439.9143 2539.8000 2744.8000 3019.7143 #> [50] 3338.0000 #>  #> $risk #>   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> 1    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #> 2    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #> 3    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #>   [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] #> 1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1 #>  #> attr(,\"class\") #> [1] \"predictedRisk\" predict(fit.tarr,newdata=Melanoma[1:4,]) #> $time #>  [1]  227.6000  273.6286  294.5429  388.2857  432.1429  482.7143  557.9143 #>  [8]  624.2000  643.5714  663.5714  700.5143  743.2571  774.3714  791.8000 #> [15]  817.0000  835.1429  859.8857  869.7714  904.5714  971.2857  979.5714 #> [22] 1017.4000 1050.6000 1060.4000 1073.1429 1151.3714 1228.6857 1254.1714 #> [29] 1279.2000 1347.1429 1461.3714 1510.5714 1533.3714 1555.5429 1577.1429 #> [36] 1613.6000 1661.7429 1689.3429 1737.8286 1951.2857 2061.2286 2074.8857 #> [43] 2105.0000 2179.8857 2331.4286 2439.9143 2539.8000 2744.8000 3019.7143 #> [50] 3338.0000 #>  #> $risk #>   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] #> 1    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #> 2    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #> 3    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #> 4    1    1    1    1    1    1    1    1    1     1     1     1     1     1 #>   [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 4     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] #> 1     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1     1     1     1 #> 4     1     1     1     1     1     1     1     1     1     1     1     1     1 #>   [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] #> 1     1     1     1     1     1     1     1     1     1     1 #> 2     1     1     1     1     1     1     1     1     1     1 #> 3     1     1     1     1     1     1     1     1     1     1 #> 4     1     1     1     1     1     1     1     1     1     1 #>  #> attr(,\"class\") #> [1] \"predictedRisk\""},{"path":"/reference/predictCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"Fast routine get baseline hazards subject specific hazards well survival probabilities survival::coxph rms::cph object","code":""},{"path":"/reference/predictCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"","code":"predictCox(   object,   times,   newdata = NULL,   centered = TRUE,   type = c(\"cumhazard\", \"survival\"),   keep.strata = TRUE,   keep.times = TRUE,   keep.newdata = FALSE,   keep.infoVar = FALSE,   se = FALSE,   band = FALSE,   iid = FALSE,   confint = (se + band) > 0,   diag = FALSE,   average.iid = FALSE,   store.iid = \"full\" )"},{"path":"/reference/predictCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"object fitted Cox regression model object either obtained coxph (survival package) cph (rms package). times [numeric vector] Time points return estimated hazard/cumulative hazard/survival. newdata [data.frame data.table]  Contain values predictor variables defining subject specific predictions. structure data set used fit object. centered [logical] TRUE return prediction mean values covariates fit$mean, FALSE return prediction covariates equal zero.  linear predictor. ignored argument newdata used. internal use. type [character vector] type predicted value. Choices \"hazard\" baseline hazard function argument newdata used hazard function argument newdata used. \"cumhazard\" cumulative baseline hazard function argument newdata used cumulative hazard function argument newdata used. \"survival\" survival baseline hazard function argument newdata used cumulative hazard function argument newdata used. Several choices can combined vector strings match (matter case) strings \"hazard\",\"cumhazard\", \"survival\". keep.strata [logical] TRUE add (newdata) strata output. . keep.times [logical] TRUE add evaluation times output. keep.newdata [logical] TRUE add value covariates used make prediction output list. keep.infoVar [logical] internal use. se [logical] TRUE compute add standard errors output. band [logical] TRUE compute add quantiles confidence bands output. iid [logical] TRUE compute add influence function output. confint [logical] TRUE compute add confidence intervals/bands output. computed applying confint function output. diag [logical] FALSE hazard/cumlative hazard/survival observations times computed, otherwise computed -th observation -th time. average.iid [logical] TRUE add average influence function newdata output. store.iid [character] Implementation used estimate influence function standard error. Can \"full\" \"minimal\".","code":""},{"path":"/reference/predictCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"argument newdata specified, function computes baseline hazard estimate. See (Ozenne et al., 2017) section \"Handling tied event times\". Otherwise function computes survival probabilities confidence intervals/bands. See (Ozenne et al., 2017) section \"Confidence intervals confidence bands survival probabilities\". survival computed using exponential approximation (equation 3). detailed explanation meaning argument store.iid can found (Ozenne et al., 2017) Appendix B \"Saving influence functions\". function compatible time varying predictor variables. centered argument enables us reproduce results obtained basehaz function survival package modified user. iid decomposition output using array containing value influence subject used fit object (dim 1), subject newdata (dim 3), time (dim 2).","code":""},{"path":"/reference/predictCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"Brice Ozenne, Anne Lyngholm Sorensen, Thomas Scheike, Christian Torp-Pedersen Thomas Alexander Gerds. riskRegression: Predicting Risk Event using Cox Regression Models. R Journal (2017) 9:2, pages 440-460.","code":""},{"path":[]},{"path":"/reference/predictCox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"Brice Ozenne broz@sund.ku.dk, Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/predictCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast computation of survival probabilities, hazards and cumulative hazards from Cox regression models — predictCox","text":"","code":"library(survival) library(data.table)  #### generate data #### set.seed(10) d <- sampleData(40,outcome=\"survival\") ## training dataset nd <- sampleData(4,outcome=\"survival\") ## validation dataset d$time <- round(d$time,1) ## create tied events # table(duplicated(d$time))  #### stratified Cox model #### fit <- coxph(Surv(time,event)~X1 + strata(X2) + X6,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  ## compute the baseline cumulative hazard fit.haz <- predictCox(fit) cbind(survival::basehaz(fit), fit.haz$cumhazard) #>        hazard time strata fit.haz$cumhazard #> 1  0.02740075  1.0      0        0.02740075 #> 2  0.04639643  1.8      0        0.04639643 #> 3  0.06604836  2.1      0        0.06604836 #> 4  0.10786058  2.2      0        0.10786058 #> 5  0.13034065  2.5      0        0.13034065 #> 6  0.15857763  2.7      0        0.15857763 #> 7  0.18834334  3.0      0        0.18834334 #> 8  0.18834334  3.2      0        0.18834334 #> 9  0.22364602  3.5      0        0.22364602 #> 10 0.25999786  3.6      0        0.25999786 #> 11 0.30157505  3.7      0        0.30157505 #> 12 0.34570093  4.0      0        0.34570093 #> 13 0.39935781  4.7      0        0.39935781 #> 14 0.39935781  5.1      0        0.39935781 #> 15 0.45630007  5.5      0        0.45630007 #> 16 0.51549299  5.8      0        0.51549299 #> 17 0.58000429  5.9      0        0.58000429 #> 18 0.65531323  6.6      0        0.65531323 #> 19 0.73137572  6.9      0        0.73137572 #> 20 0.73137572  7.0      0        0.73137572 #> 21 0.73137572  7.2      0        0.73137572 #> 22 0.83727365  7.7      0        0.83727365 #> 23 1.01024745  8.4      0        1.01024745 #> 24 1.01024745  9.2      0        1.01024745 #> 25 1.01024745  9.5      0        1.01024745 #> 26 1.01024745  9.6      0        1.01024745 #> 27 1.85095070 11.0      0        1.85095070 #> 28 3.88020663 11.1      0        3.88020663 #> 29 3.88020663 11.5      0        3.88020663 #> 30 8.67043704 12.0      0        8.67043704 #> 31 0.03325983  0.6      1        0.03325983 #> 32 0.15046226  3.6      1        0.15046226 #> 33 0.15046226  4.2      1        0.15046226 #> 34 0.80091039  4.7      1        0.80091039 #> 35 2.87808974  7.5      1        2.87808974  ## compute individual specific cumulative hazard and survival probabilities  fit.pred <- predictCox(fit, newdata=nd, times=c(3,8), se = TRUE, band = TRUE) fit.pred #>    observation strata times cumhazard cumhazard.se cumhazard.lower #> 1:           1      1     3    0.3728       0.1390          0.1795 #> 2:           2      0     3    0.0677       0.0382          0.0224 #> 3:           3      0     3    0.1181       0.0541          0.0482 #> 4:           4      0     3    0.2030       0.0750          0.0985 #> 5:           1      1     8        NA           NA              NA #> 6:           2      0     8    0.3008       0.1401          0.1207 #> 7:           3      0     8    0.5251       0.1885          0.2598 #> 8:           4      0     8    0.9026       0.2504          0.5240 #>    cumhazard.upper cumhazard.quantileBand cumhazard.lowerBand #> 1:           0.774                   1.96              0.1797 #> 2:           0.205                   2.14              0.0202 #> 3:           0.290                   2.17              0.0438 #> 4:           0.419                   2.20              0.0900 #> 5:              NA                   1.96                  NA #> 6:           0.749                   2.14              0.1110 #> 7:           1.061                   2.17              0.2412 #> 8:           1.555                   2.20              0.4899 #>    cumhazard.upperBand survival survival.se survival.lower survival.upper #> 1:               0.773    0.689      0.0957          0.461          0.836 #> 2:               0.227    0.935      0.0357          0.815          0.978 #> 3:               0.318    0.889      0.0480          0.749          0.953 #> 4:               0.458    0.816      0.0612          0.658          0.906 #> 5:                  NA       NA          NA             NA             NA #> 6:               0.815    0.740      0.1037          0.473          0.886 #> 7:               1.143    0.592      0.1115          0.346          0.771 #> 8:               1.663    0.406      0.1016          0.211          0.592 #>    survival.quantileBand survival.lowerBand survival.upperBand #> 1:                  1.99              0.457              0.837 #> 2:                  2.13              0.798              0.980 #> 3:                  2.16              0.728              0.957 #> 4:                  2.20              0.633              0.914 #> 5:                  1.99                 NA                 NA #> 6:                  2.13              0.444              0.895 #> 7:                  2.16              0.320              0.785 #> 8:                  2.20              0.190              0.612  ####  other examples #### # one strata variable fitS <- coxph(Surv(time,event)~strata(X1)+X2,               data=d, ties=\"breslow\", x = TRUE, y = TRUE)  predictCox(fitS) #>     observation strata times cumhazard survival #>  1:           1      0   0.6    0.0241   0.9762 #>  2:           2      0   1.0    0.0743   0.9284 #>  3:           3      0   1.8    0.1007   0.9042 #>  4:           4      0   2.1    0.1278   0.8800 #>  5:           5      0   2.2    0.1836   0.8323 #>  6:           6      0   2.5    0.2140   0.8074 #>  7:           7      0   2.7    0.2454   0.7824 #>  8:           8      0   3.0    0.2778   0.7575 #>  9:           9      0   3.2    0.2778   0.7575 #> 10:          10      0   3.5    0.3124   0.7317 #> 11:          11      0   3.6    0.3483   0.7059 #> 12:          12      0   3.7    0.3855   0.6801 #> 13:          13      0   4.0    0.4241   0.6543 #> 14:          14      0   4.2    0.4241   0.6543 #> 15:          15      0   4.7    0.5102   0.6004 #> 16:          16      0   5.1    0.5102   0.6004 #> 17:          17      0   5.5    0.5611   0.5706 #> 18:          18      0   5.8    0.6148   0.5407 #> 19:          19      0   5.9    0.6716   0.5109 #> 20:          20      0   6.6    0.7356   0.4792 #> 21:          21      0   6.9    0.8040   0.4475 #> 22:          22      0   7.0    0.8040   0.4475 #> 23:          23      0   7.2    0.8040   0.4475 #> 24:          24      0   7.5    0.8900   0.4106 #> 25:          25      0   7.7    0.9900   0.3716 #> 26:          26      0   8.4    1.1011   0.3325 #> 27:          27      0   9.2    1.1011   0.3325 #> 28:          28      0   9.5    1.1011   0.3325 #> 29:          29      0   9.6    1.1011   0.3325 #> 30:          30      0  11.0    1.3511   0.2589 #> 31:          31      0  11.1    1.6845   0.1855 #> 32:          32      0  11.5    1.6845   0.1855 #> 33:          33      0  12.0    2.6845   0.0683 #> 34:          34      1   3.6    0.6161   0.5400 #>     observation strata times cumhazard survival predictCox(fitS, newdata=nd, times = 1) #>    observation strata times cumhazard survival #> 1:           1      0     1    0.1205    0.886 #> 2:           2      0     1    0.0743    0.928 #> 3:           3      0     1    0.0743    0.928 #> 4:           4      0     1    0.0743    0.928  # two strata variables set.seed(1) d$U=sample(letters[1:5],replace=TRUE,size=NROW(d)) d$V=sample(letters[4:10],replace=TRUE,size=NROW(d)) nd$U=sample(letters[1:5],replace=TRUE,size=NROW(nd)) nd$V=sample(letters[4:10],replace=TRUE,size=NROW(nd)) fit2S <- coxph(Surv(time,event)~X1+strata(U)+strata(V)+X2,               data=d, ties=\"breslow\", x = TRUE, y = TRUE) #> Warning: Loglik converged before variable  1 ; coefficient may be infinite.   cbind(survival::basehaz(fit2S),predictCox(fit2S,type=\"cumhazard\")$cumhazard) #>          hazard time strata predictCox(fit2S, type = \"cumhazard\")$cumhazard #> 1  0.000000e+00  5.9   a, d                                    0.000000e+00 #> 2  0.000000e+00  9.2   a, e                                    0.000000e+00 #> 3  3.333333e-01  1.0   a, g                                    3.333333e-01 #> 4  8.333333e-01  2.5   a, g                                    8.333333e-01 #> 5  8.333333e-01 11.5   a, g                                    8.333333e-01 #> 6  3.333333e-01  0.6   a, h                                    3.333333e-01 #> 7  1.333333e+00  2.7   a, h                                    1.333333e+00 #> 8  2.500000e-01  4.0   a, i                                    2.500000e-01 #> 9  5.833333e-01  4.7   a, i                                    5.833333e-01 #> 10 5.833333e-01  9.6   a, i                                    5.833333e-01 #> 11 1.000000e+00  4.7   a, j                                    1.000000e+00 #> 12 1.000000e+00  3.7   b, d                                    1.000000e+00 #> 13 0.000000e+00  7.2   b, f                                    0.000000e+00 #> 14 1.000000e+00 12.0   b, f                                    1.000000e+00 #> 15 5.000000e-01  2.2   b, g                                    5.000000e-01 #> 16 5.000000e-01  5.1   b, g                                    5.000000e-01 #> 17 5.000000e-01  6.9   b, h                                    5.000000e-01 #> 18 1.500000e+00 11.0   b, h                                    1.500000e+00 #> 19 5.000000e-01  2.1   b, i                                    5.000000e-01 #> 20 5.000000e-01  3.2   b, i                                    5.000000e-01 #> 21 1.000000e+00  6.6   b, j                                    1.000000e+00 #> 22 4.573922e-09  3.6   c, e                                    4.573922e-09 #> 23 1.000000e+00 11.1   c, e                                    1.000000e+00 #> 24 5.000000e-01  1.8   c, i                                    5.000000e-01 #> 25 5.000000e-01  7.0   c, i                                    5.000000e-01 #> 26 0.000000e+00  2.2   d, d                                    0.000000e+00 #> 27 0.000000e+00  9.5   d, d                                    0.000000e+00 #> 28 1.000000e+00  8.4   d, f                                    1.000000e+00 #> 29 1.000000e+00  1.0   d, g                                    1.000000e+00 #> 30 2.500000e-01  5.9   d, h                                    2.500000e-01 #> 31 5.833333e-01  7.5   d, h                                    5.833333e-01 #> 32 1.583333e+00  7.7   d, h                                    1.583333e+00 #> 33 0.000000e+00  4.2   d, j                                    0.000000e+00 #> 34 1.000000e+00  5.8   e, d                                    1.000000e+00 #> 35 1.000000e+00  3.0   e, f                                    1.000000e+00 #> 36 5.000000e-01  3.5   e, i                                    5.000000e-01 #> 37 1.500000e+00  5.5   e, i                                    1.500000e+00 #> 38 3.333333e-01  2.2   e, j                                    3.333333e-01 #> 39 8.333333e-01  3.6   e, j                                    8.333333e-01 #> 40 8.333333e-01  9.2   e, j                                    8.333333e-01 predictCox(fit2S) #>     observation strata times cumhazard survival #>  1:           1   a, d   5.9  0.00e+00    1.000 #>  2:           2   a, e   9.2  0.00e+00    1.000 #>  3:           3   a, g   1.0  3.33e-01    0.717 #>  4:           4   a, g   2.5  8.33e-01    0.435 #>  5:           5   a, g  11.5  8.33e-01    0.435 #>  6:           6   a, h   0.6  3.33e-01    0.717 #>  7:           7   a, h   2.7  1.33e+00    0.264 #>  8:           8   a, i   4.0  2.50e-01    0.779 #>  9:           9   a, i   4.7  5.83e-01    0.558 #> 10:          10   a, i   9.6  5.83e-01    0.558 #> 11:          11   a, j   4.7  1.00e+00    0.368 #> 12:          12   b, d   3.7  1.00e+00    0.368 #> 13:          13   b, f   7.2  0.00e+00    1.000 #> 14:          14   b, f  12.0  1.00e+00    0.368 #> 15:          15   b, g   2.2  5.00e-01    0.607 #> 16:          16   b, g   5.1  5.00e-01    0.607 #> 17:          17   b, h   6.9  5.00e-01    0.607 #> 18:          18   b, h  11.0  1.50e+00    0.223 #> 19:          19   b, i   2.1  5.00e-01    0.607 #> 20:          20   b, i   3.2  5.00e-01    0.607 #> 21:          21   b, j   6.6  1.00e+00    0.368 #> 22:          22   c, e   3.6  4.57e-09    1.000 #> 23:          23   c, e  11.1  1.00e+00    0.368 #> 24:          24   c, i   1.8  5.00e-01    0.607 #> 25:          25   c, i   7.0  5.00e-01    0.607 #> 26:          26   d, d   2.2  0.00e+00    1.000 #> 27:          27   d, d   9.5  0.00e+00    1.000 #> 28:          28   d, f   8.4  1.00e+00    0.368 #> 29:          29   d, g   1.0  1.00e+00    0.368 #> 30:          30   d, h   5.9  2.50e-01    0.779 #> 31:          31   d, h   7.5  5.83e-01    0.558 #> 32:          32   d, h   7.7  1.58e+00    0.205 #> 33:          33   d, j   4.2  0.00e+00    1.000 #> 34:          34   e, d   5.8  1.00e+00    0.368 #> 35:          35   e, f   3.0  1.00e+00    0.368 #> 36:          36   e, i   3.5  5.00e-01    0.607 #> 37:          37   e, i   5.5  1.50e+00    0.223 #> 38:          38   e, j   2.2  3.33e-01    0.717 #> 39:          39   e, j   3.6  8.33e-01    0.435 #> 40:          40   e, j   9.2  8.33e-01    0.435 #>     observation strata times cumhazard survival predictCox(fitS, newdata=nd, times = 3) #>    observation strata times cumhazard survival #> 1:           1      0     3     0.451    0.637 #> 2:           2      0     3     0.278    0.757 #> 3:           3      0     3     0.278    0.757 #> 4:           4      0     3     0.278    0.757  # left truncation test2 <- list(start=c(1,2,5,2,1,7,3,4,8,8),                stop=c(2,3,6,7,8,9,9,9,14,17),                event=c(1,1,1,1,1,1,1,0,0,0),                x=c(1,0,0,1,0,1,1,1,0,0))  m.cph <- coxph(Surv(start, stop, event) ~ 1, test2, x = TRUE) as.data.table(predictCox(m.cph)) #> Warning: The current version of predictCox was not designed to handle left censoring  #> The function may be used on own risks  #>    observation times cumhazard  survival #> 1:           1     2 0.5000000 0.6065307 #> 2:           2     3 0.8333333 0.4345982 #> 3:           3     6 1.0333333 0.3558189 #> 4:           4     7 1.2833333 0.2771121 #> 5:           5     8 1.5333333 0.2158151 #> 6:           6     9 1.9833333 0.1376098 #> 7:           7    14 1.9833333 0.1376098 #> 8:           8    17 1.9833333 0.1376098  basehaz(m.cph) #>      hazard time #> 1 0.5000000    2 #> 2 0.8333333    3 #> 3 1.0333333    6 #> 4 1.2833333    7 #> 5 1.5333333    8 #> 6 1.9833333    9 #> 7 1.9833333   14 #> 8 1.9833333   17"},{"path":"/reference/predictCoxPL.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","title":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","text":"predictCox except survival estimated using product limit estimator.","code":""},{"path":"/reference/predictCoxPL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","text":"","code":"predictCoxPL(   object,   times,   newdata = NULL,   type = c(\"cumhazard\", \"survival\"),   keep.strata = TRUE,   keep.infoVar = FALSE,   ... )"},{"path":"/reference/predictCoxPL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","text":"object fitted Cox regression model object either obtained coxph (survival package) cph (rms package). times [numeric vector] Time points return estimated hazard/cumulative hazard/survival. newdata [data.frame data.table]  Contain values predictor variables defining subject specific predictions. structure data set used fit object. type [character vector] type predicted value. Choices \"hazard\" baseline hazard function argument newdata used hazard function argument newdata used. \"cumhazard\" cumulative baseline hazard function argument newdata used cumulative hazard function argument newdata used. \"survival\" survival baseline hazard function argument newdata used cumulative hazard function argument newdata used. Several choices can combined vector strings match (matter case) strings \"hazard\",\"cumhazard\", \"survival\". keep.strata [logical] TRUE add (newdata) strata output. . keep.infoVar [logical] internal use. ... additional arguments passed predictCox.","code":""},{"path":"/reference/predictCoxPL.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","text":"Note: iid standard errors computed using exponential approximation.","code":""},{"path":"/reference/predictCoxPL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computation of survival probabilities from Cox regression models using the product limit estimator. — predictCoxPL","text":"","code":"library(survival)  #### generate data #### set.seed(10) d <- sampleData(40,outcome=\"survival\") nd <- sampleData(4,outcome=\"survival\") d$time <- round(d$time,1)  #### Cox model #### fit <- coxph(Surv(time,event)~ X1 + X2 + X6,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  ## exponential approximation predictCox(fit, newdata = d, times = 1:5) #>      observation times cumhazard survival #>   1:           1     1   0.02767 9.73e-01 #>   2:           2     1   0.01904 9.81e-01 #>   3:           3     1   0.00346 9.97e-01 #>   4:           4     1   0.09274 9.11e-01 #>   5:           5     1   0.01844 9.82e-01 #>  ---                                      #> 196:          36     5   3.99435 1.84e-02 #> 197:          37     5   2.10055 1.22e-01 #> 198:          38     5   0.04125 9.60e-01 #> 199:          39     5  29.60459 1.39e-13 #> 200:          40     5   0.68889 5.02e-01  ## product limit predictCoxPL(fit, newdata = d, times = 1:5) #> Warning: Estimated survival outside the range [0,1].  #> Consider using predictCox instead of predictCoxPL.  #>      observation times cumhazard survival #>   1:           1     1   0.02767  0.97246 #>   2:           2     1   0.01904  0.98102 #>   3:           3     1   0.00346  0.99655 #>   4:           4     1   0.09274  0.90869 #>   5:           5     1   0.01844  0.98161 #>  ---                                      #> 196:          36     5   3.99435  0.00262 #> 197:          37     5   2.10055  0.08913 #> 198:          38     5   0.04125  0.95949 #> 199:          39     5  29.60459  0.14730 #> 200:          40     5   0.68889  0.48818  #### stratified Cox model #### fitS <- coxph(Surv(time,event)~ X1 + strata(X2) + X6,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  ## exponential approximation predictCox(fitS, newdata = d, times = 1:5) #>      observation strata times cumhazard survival #>   1:           1      0     1   0.02680 9.74e-01 #>   2:           2      0     1   0.01885 9.81e-01 #>   3:           3      0     1   0.00378 9.96e-01 #>   4:           4      0     1   0.08365 9.20e-01 #>   5:           5      0     1   0.01830 9.82e-01 #>  ---                                             #> 196:          36      0     5   3.62189 2.67e-02 #> 197:          37      0     5   1.97830 1.38e-01 #> 198:          38      0     5   0.04899 9.52e-01 #> 199:          39      1     5  17.24685 3.23e-08 #> 200:          40      0     5   0.69291 5.00e-01  ## product limit predictCoxPL(fitS, newdata = d, times = 1:5) #> Warning: Estimated survival outside the range [0,1].  #> Consider using predictCox instead of predictCoxPL.  #>      observation strata times cumhazard survival #>   1:           1      0     1   0.02680    0.973 #>   2:           2      0     1   0.01885    0.981 #>   3:           3      0     1   0.00378    0.996 #>   4:           4      0     1   0.08365    0.916 #>   5:           5      0     1   0.01830    0.982 #>  ---                                             #> 196:          36      0     5   3.62189    0.012 #> 197:          37      0     5   1.97830    0.113 #> 198:          38      0     5   0.04899    0.952 #> 199:          39      1     5  17.24685    5.625 #> 200:          40      0     5   0.69291    0.489  #### fully stratified Cox model #### fitS <- coxph(Surv(time,event)~ 1,              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  ## product limit GS <- survfit(Surv(time,event)~1, data = d) range(predictCoxPL(fitS)$survival - GS$surv) #> [1] 0.000000e+00 1.110223e-16  fitS <- coxph(Surv(time,event)~ strata(X2),              data=d, ties=\"breslow\", x = TRUE, y = TRUE)  ## product limit GS <- survfit(Surv(time,event)~X2, data = d) range(predictCoxPL(fitS)$survival - GS$surv) #> [1] 0.000000e+00 2.220446e-16"},{"path":"/reference/predictRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Extrating predicting risks from regression models — predictRisk","title":"Extrating predicting risks from regression models — predictRisk","text":"Extract event probabilities fitted regression models machine learning objects.  function predictRisk generic function, meaning invokes specifically designed functions depending 'class' first argument. See predictRisk.","code":""},{"path":"/reference/predictRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extrating predicting risks from regression models — predictRisk","text":"","code":"predictRisk(object, newdata, ...)  # S3 method for default predictRisk(object, newdata, times, cause, ...)  # S3 method for double predictRisk(object, newdata, times, cause, ...)  # S3 method for integer predictRisk(object, newdata, times, cause, ...)  # S3 method for factor predictRisk(object, newdata, times, cause, ...)  # S3 method for numeric predictRisk(object, newdata, times, cause, ...)  # S3 method for glm predictRisk(object, newdata, iid = FALSE, average.iid = FALSE, ...)  # S3 method for formula predictRisk(object, newdata, ...)  # S3 method for BinaryTree predictRisk(object, newdata, ...)  # S3 method for lrm predictRisk(object, newdata, ...)  # S3 method for rpart predictRisk(object, newdata, ...)  # S3 method for randomForest predictRisk(object, newdata, ...)  # S3 method for matrix predictRisk(object, newdata, times, cause, ...)  # S3 method for aalen predictRisk(object, newdata, times, ...)  # S3 method for cox.aalen predictRisk(object, newdata, times, ...)  # S3 method for coxph predictRisk(   object,   newdata,   times,   product.limit = FALSE,   diag = FALSE,   iid = FALSE,   average.iid = FALSE,   ... )  # S3 method for coxphTD predictRisk(object, newdata, times, landmark, ...)  # S3 method for CSCTD predictRisk(object, newdata, times, cause, landmark, ...)  # S3 method for coxph.penal predictRisk(object, newdata, times, ...)  # S3 method for cph predictRisk(   object,   newdata,   times,   product.limit = FALSE,   diag = FALSE,   iid = FALSE,   average.iid = FALSE,   ... )  # S3 method for selectCox predictRisk(object, newdata, times, ...)  # S3 method for prodlim predictRisk(object, newdata, times, cause, ...)  # S3 method for survfit predictRisk(object, newdata, times, ...)  # S3 method for psm predictRisk(object, newdata, times, ...)  # S3 method for ranger predictRisk(object, newdata, times, cause, ...)  # S3 method for rfsrc predictRisk(object, newdata, times, cause, ...)  # S3 method for FGR predictRisk(object, newdata, times, cause, ...)  # S3 method for riskRegression predictRisk(object, newdata, times, cause, ...)  # S3 method for ARR predictRisk(object, newdata, times, cause, ...)  # S3 method for CauseSpecificCox predictRisk(   object,   newdata,   times,   cause,   product.limit = TRUE,   diag = FALSE,   iid = FALSE,   average.iid = FALSE,   ... )  # S3 method for penfitS3 predictRisk(object, newdata, times, ...)  # S3 method for SuperPredictor predictRisk(object, newdata, ...)  # S3 method for gbm predictRisk(object, newdata, times, ...)  # S3 method for flexsurvreg predictRisk(object, newdata, times, ...)  # S3 method for hal9001 predictRisk(object, newdata, times, cause, ...)  # S3 method for singleEventCB predictRisk(object, newdata, times, cause, ...)  # S3 method for wglm predictRisk(   object,   newdata,   times = NULL,   product.limit = FALSE,   diag = FALSE,   iid = FALSE,   average.iid = FALSE,   ... )"},{"path":"/reference/predictRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extrating predicting risks from regression models — predictRisk","text":"object fitted model extract predicted event probabilities. newdata data frame containing predictor variable combinations compute predicted event probabilities. ... Additional arguments passed current method. times vector times range response variable, cumulative incidences event probabilities computed. cause Identifies cause interest among competing events. iid iid decomposition output using attribute? average.iid average iid decomposition output using attribute? product.limit TRUE survival computed using product limit estimator. Otherwise exponential approximation used (.e. exp(-cumulative hazard)). diag FALSE hazard/cumlative hazard/survival observations times computed, otherwise computed -th observation -th time. landmark starting time computation cumulative risk.","code":""},{"path":"/reference/predictRisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extrating predicting risks from regression models — predictRisk","text":"binary outcome vector predicted risks. survival outcome without competing risks matrix many rows NROW(newdata) many columns length(times). entry probability rows values increasing.","code":""},{"path":"/reference/predictRisk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extrating predicting risks from regression models — predictRisk","text":"uncensored binary outcome data need choose time point. operating models survival analysis (without competing risks) function still predicts risk, 1 - S(t|X) S(t|X) survival chance subject characterized X. competing risks (data right censored) one needs specify time horizon prediction (can vector) cause event. function extracts absolute risks F_c(t|X) aka cumulative incidence event type/cause c time t subject characterized X. Depending model may possible predict risk causes competing risks setting. example. cause-specific Cox (CSC) object allows predict cases whereas Fine-Gray regression model (FGR) specific one causes.","code":""},{"path":"/reference/predictRisk.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extrating predicting risks from regression models — predictRisk","text":"Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/predictRisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extrating predicting risks from regression models — predictRisk","text":"","code":"## binary outcome library(rms) set.seed(7) d <- sampleData(80,outcome=\"binary\") nd <- sampleData(80,outcome=\"binary\") fit <- lrm(Y~X1+X8,data=d) predictRisk(fit,newdata=nd) #>  [1] 0.7339412 0.5205004 0.6501073 0.5979307 0.5552337 0.6813442 0.5138679 #>  [8] 0.4869184 0.5723498 0.7074138 0.4503456 0.6303146 0.6940030 0.7019831 #> [15] 0.7304874 0.5405902 0.6450002 0.6896565 0.6689911 0.6865119 0.7344731 #> [22] 0.6689586 0.6906598 0.6615316 0.6682134 0.7072245 0.5725908 0.6725140 #> [29] 0.7493084 0.5723684 0.5466048 0.5498836 0.6665991 0.4635920 0.6969143 #> [36] 0.5879416 0.5341623 0.6023531 0.5320208 0.6121940 0.5766031 0.4807605 #> [43] 0.7727554 0.5650180 0.5466259 0.6760755 0.6716273 0.6953790 0.6627699 #> [50] 0.6865030 0.7738892 0.5867579 0.7673772 0.5591252 0.6120579 0.7014891 #> [57] 0.5616479 0.6084543 0.5823368 0.4629641 0.5386492 0.7027465 0.6637092 #> [64] 0.6194466 0.4777845 0.4645041 0.5229923 0.5819439 0.5879641 0.5579212 #> [71] 0.6642978 0.5665127 0.4391573 0.4995590 0.6802095 0.5770284 0.5952840 #> [78] 0.5303929 0.5633104 0.7699667 if (FALSE) { library(SuperLearner) set.seed(1) sl = SuperLearner(Y = d$Y, X = d[,-1], family = binomial(),       SL.library = c(\"SL.mean\", \"SL.glmnet\", \"SL.randomForest\")) }  ## survival outcome # generate survival data library(prodlim) set.seed(100) d <- sampleData(100,outcome=\"survival\") d[,X1:=as.numeric(as.character(X1))] #>            X6       X7            X8          X9         X10 X1 X2 X3 X4 X5 #>   1: 67.60713 69.67119 -1.446287e+00 -1.28482865 -1.85544523  0  0  1  0  0 #>   2: 60.83520 59.93708  3.158558e-01 -0.14178173 -1.01856471  0  0  0  1  0 #>   3: 80.69528 53.74057 -3.427475e-01  1.43878477 -1.04511109  0  0  1  1  0 #>   4: 73.35923 63.87398 -1.931353e+00 -1.04005754 -0.65128765  0  0  0  1  0 #>   5: 37.84050 64.01945  2.428210e-01 -1.02383795  0.38268265  0  1  0  0  1 #>   6: 90.13616 52.50619 -3.627679e-01  1.09477379  1.03189971  0  0  1  1  1 #>   7: 73.57762 62.92928  2.432729e+00 -2.01392688  0.13107497  0  0  0  1  1 #>   8: 69.44575 55.79672  5.920912e-01 -1.04657680  0.37719173  0  1  0  1  1 #>   9: 79.20880 56.13008 -5.762008e-01  0.83340995 -1.88769508  0  1  0  0  0 #>  10: 39.05374 53.95725  4.066282e-01  0.60860245  0.52021940  0  0  1  0  1 #>  11: 61.16817 60.09412 -4.525463e-02  1.08405733  0.85915316  0  0  0  0  1 #>  12: 34.08836 53.16334  4.409000e-01  0.17271042 -0.80248866  0  0  1  1  1 #>  13: 71.57107 50.04946  2.235376e+00  1.51619199 -0.49196052  0  0  0  0  0 #>  14: 62.34562 49.21902 -5.861548e-01 -0.21720846 -0.21095432  0  1  0  0  0 #>  15: 52.31432 60.33588  5.993602e-01 -0.10825074 -0.46367661  1  0  0  0  1 #>  16: 63.89778 64.30127  1.274233e+00 -0.35771655  0.29947957  0  1  0  1  0 #>  17: 78.02487 56.08356 -9.117712e-01  0.32704438 -0.60547383  0  0  0  1  1 #>  18: 66.53057 57.21910 -1.375459e+00 -2.01294422 -0.43901213  0  0  1  1  1 #>  19: 64.85693 63.53475 -2.877269e-01 -0.14969455 -0.72075363  0  0  0  0  0 #>  20: 76.68702 60.95784  8.148341e-02 -0.93219123  0.78080503  1  0  1  0  1 #>  21: 95.81304 68.19839  3.378953e-01  0.27841306 -1.22228428  0  1  0  0  0 #>  22: 71.07430 59.12232  5.661375e-01  0.81683628  0.89119404  0  0  0  0  0 #>  23: 46.48704 58.18766 -9.342229e-01 -0.43026026  0.25392284  0  0  0  1  0 #>  24: 71.36911 70.80791  1.726770e+00  0.57233004 -0.06581643  0  1  1  1  1 #>  25: 79.60886 59.34964  1.588315e+00  0.17699375  0.20146603  0  0  0  0  0 #>  26: 66.70295 53.43514 -1.037447e+00  1.11357174  2.47770051  0  0  1  1  0 #>  27: 47.23156 63.29879  3.695074e-01 -0.58710491  0.47175279  0  0  1  0  1 #>  28: 44.28079 60.45902  4.386581e-01 -1.73823332  1.32619808  1  1  0  0  1 #>  29: 60.05991 62.24036 -8.779960e-01  0.65367143  0.66859849  0  0  0  0  1 #>  30: 38.70624 62.72042  7.609176e-01 -0.18665642 -0.13739441  0  0  1  0  0 #>  31: 67.43238 68.10389  6.428198e-02  0.63935678 -1.41117170  0  1  0  0  0 #>  32: 74.46442 66.60646  2.298479e+00 -0.03184133  1.20036310  0  0  0  0  1 #>  33: 67.72103 59.51079 -1.299978e+00  1.00223585  0.29909011  0  0  0  1  1 #>  34: 43.33935 61.92117 -1.079637e+00 -0.64106663  0.45622688  0  0  0  1  0 #>  35: 55.61299 63.87521  1.488323e+00  0.25103701  0.43807844  0  0  0  0  1 #>  36: 88.86030 62.03224 -2.307636e-01  0.57503544 -0.21502114  0  1  0  0  0 #>  37: 24.58929 59.86608  6.650739e-01 -0.63502220 -0.31212248  0  1  0  0  0 #>  38: 53.61840 66.70530 -1.160317e+00  0.85728350 -0.69263042  0  1  0  1  0 #>  39: 57.00281 63.72455  1.081541e+00  1.10488241 -2.39622968  0  0  1  1  0 #>  40: 76.21916 57.76666  4.242119e-01 -2.40522528 -1.58427493  0  1  0  1  1 #>  41: 51.28725 56.31585  7.760563e-01 -0.70096498  1.75874823  0  0  1  0  1 #>  42: 56.82391 55.74713 -7.227887e-01  0.02844935 -2.36288679  0  0  0  1  0 #>  43: 53.81463 53.29963  5.090754e-01  1.71749203  0.39317207  0  0  0  1  0 #>  44: 65.93194 63.29139  1.546150e-01 -1.12829486  0.56593786  0  0  0  1  1 #>  45: 39.94235 58.21823  3.092472e-01  1.08624613 -1.04399037  0  0  0  0  0 #>  46: 94.66977 60.24721  3.165137e-01  1.30588495  1.02311329  0  0  0  1  1 #>  47: 54.74263 54.57329  7.076799e-01 -0.98826461 -0.51266401  0  0  0  1  1 #>  48: 55.18345 60.18326 -4.624353e-01 -0.22741791  0.04773667  0  0  1  0  0 #>  49: 53.56558 46.88199  1.698303e+00 -0.14210333  1.39287700  0  0  0  0  0 #>  50: 56.55583 49.26344 -8.619856e-01  0.39601296 -0.43249913  0  0  1  0  0 #>  51: 59.16123 65.46242 -1.051830e+00 -1.93943938 -0.13516784  0  0  0  0  1 #>  52: 54.41932 51.57829  5.315186e-01 -3.32078221  1.29773515  0  0  0  1  1 #>  53: 67.11450 57.46777  7.728399e-02  0.94208189 -0.07072648  0  0  0  0  0 #>  54: 59.07443 53.54999 -1.024841e+00  0.03715139 -0.42082819  1  0  0  0  0 #>  55: 28.08466 56.69819  1.441593e-01 -0.25855501  1.14134036  0  0  0  1  1 #>  56: 44.96644 60.55578 -2.208962e-01  0.34439414 -0.42712648  1  0  0  1  1 #>  57: 52.23293 68.44091 -9.773315e-01  0.14935523  1.39566961  0  1  1  0  1 #>  58: 93.15315 67.20975  3.352802e-01  0.94046373 -0.29618717  0  0  0  0  1 #>  59: 64.87477 61.03908  1.587367e+00 -2.21790192  0.58265961  0  0  1  1  0 #>  60: 40.84787 57.32315  1.269826e+00 -1.79355876 -2.67622935  0  0  0  1  1 #>  61: 91.17939 61.26102  2.887333e+00  1.69210689 -1.40067901  0  0  0  0  1 #>  62: 68.26378 55.15752  6.832389e-01 -1.67249615  3.30415111  0  1  0  1  1 #>  63: 90.15721 60.25976 -6.769761e-01 -1.73719284  0.85677754  0  0  1  0  0 #>  64: 55.68636 66.36291 -1.638704e-01 -0.02663486  1.16101645  0  1  0  1  0 #>  65: 67.22259 57.66221  7.096116e-01  0.06580442  0.27893689  1  0  0  1  0 #>  66: 39.32216 57.32037 -1.053669e+00 -1.46232344 -0.01354850  0  1  0  1  0 #>  67: 73.84366 64.15761 -9.562285e-01 -0.41940470 -2.67637889  0  0  0  0  0 #>  68: 47.70464 61.77510 -9.451874e-01  0.57684701  0.12131445  0  0  0  0  1 #>  69: 50.25840 62.26019  2.247884e-01 -0.60692236 -0.50054324  0  0  1  1  1 #>  70: 82.33657 64.39757  3.594552e-01 -0.06921954  1.37967791  1  0  1  1  1 #>  71: 45.88178 59.45799 -6.637104e-01  1.33394384 -0.40598666  0  0  1  1  0 #>  72: 42.38993 47.80939 -1.265082e-01 -0.76774206  1.39593194  0  0  0  1  0 #>  73: 71.89668 63.67757  1.642374e+00  0.55319467  0.73859616  0  0  0  0  1 #>  74: 48.05875 52.65778 -5.070985e-01 -1.70865790  0.73661415  0  0  0  0  1 #>  75: 74.84172 61.88597 -5.184870e-01 -0.52672810 -0.73308795  0  1  0  1  1 #>  76: 91.60804 63.32283  1.343653e+00  2.06376423 -1.89839605  0  1  0  1  0 #>  77: 87.40961 59.72468  8.748702e-02  0.42372826  0.44587930  0  0  0  0  1 #>  78: 65.89167 60.84810  5.376727e-01  1.00855573  0.45626086  0  0  0  0  1 #>  79: 58.56517 65.99554  1.492186e+00  1.36114180 -1.52619721  0  0  0  1  0 #>  80: 71.10492 64.14804  8.767927e-01 -0.10595486 -0.08058262  0  0  1  0  1 #>  81: 77.02966 66.49966  4.958852e-01  0.04150070 -0.34001061  0  0  0  0  0 #>  82: 71.90150 53.59561 -2.473539e-01  1.11989772  0.05368080  0  0  0  0  1 #>  83: 71.35316 55.32200 -7.287776e-01  0.23916287 -0.69163485  0  1  0  0  1 #>  84: 55.30238 61.83689  8.741936e-01 -1.03908394 -0.30349490  0  0  0  0  1 #>  85: 22.60817 59.94846 -7.606030e-01 -0.49175571 -1.19501405  0  0  1  0  0 #>  86: 58.87421 57.04893  4.029195e-01  0.38418962  1.01973592  0  0  0  1  0 #>  87: 46.09025 64.62609 -5.317420e-01 -0.14747227 -0.47844422  0  0  0  1  0 #>  88: 78.52232 59.53003  1.193348e-05 -0.65047518 -0.65949205  1  1  0  1  0 #>  89: 62.74970 64.89474  8.181784e-01  0.05630389  0.67887965  0  0  1  0  0 #>  90: 72.57549 55.50661  2.691192e-01 -0.24660122 -0.10535533  1  0  0  0  1 #>  91: 70.05943 61.18653 -3.880011e-01  1.23622156 -0.45371767  0  1  0  0  1 #>  92: 39.53909 56.46051 -3.247585e-01 -0.17832690  1.34143863  0  0  0  1  0 #>  93: 69.97910 53.47501  1.680009e+00  1.23646958  0.98595720  0  0  1  0  0 #>  94: 70.89334 64.13688 -2.880736e+00 -1.08216683 -1.19546478  0  0  0  1  1 #>  95: 64.40614 62.91072  6.221381e-01 -0.49419020 -0.57485857  1  0  0  0  1 #>  96: 45.97832 53.21347 -2.203552e+00 -1.71111303  0.98199136  1  0  0  0  0 #>  97: 78.72715 61.59434 -2.726918e-01  0.04005805 -1.65738323  0  0  0  1  0 #>  98: 34.65440 58.68629 -9.221195e-01 -0.56114348 -1.11964693  0  0  0  1  1 #>  99: 82.23566 54.07995 -3.062827e-01 -2.55736206 -1.17082441  0  1  1  0  0 #> 100: 76.36865 60.93626  2.536559e+00 -0.69677881 -1.13905161  0  0  0  0  1 #>            X6       X7            X8          X9         X10 X1 X2 X3 X4 X5 #>       eventtime  censtime       time event #>   1:  6.7778319 10.855483  6.7778319     1 #>   2:  9.9851341 11.645024  9.9851341     1 #>   3:  0.8401512  7.704695  0.8401512     1 #>   4:  8.5391295 16.957550  8.5391295     1 #>   5: 14.9499500  8.706974  8.7069741     0 #>   6:  2.6489767  8.521409  2.6489767     1 #>   7:  1.3483311  4.558061  1.3483311     1 #>   8:  0.5893505  9.966877  0.5893505     1 #>   9:  2.4964235  7.772476  2.4964235     1 #>  10: 18.8061049 13.305700 13.3057001     0 #>  11: 12.0984084  6.855722  6.8557222     0 #>  12: 21.3980774  3.540841  3.5408414     0 #>  13:  7.8763135 11.276980  7.8763135     1 #>  14:  4.8244485  9.592070  4.8244485     1 #>  15:  4.3768039  5.206590  4.3768039     1 #>  16:  9.3937423  6.339864  6.3398641     0 #>  17:  8.5220276 12.596186  8.5220276     1 #>  18:  1.4842932 10.141747  1.4842932     1 #>  19: 10.6713543 10.114892 10.1148916     0 #>  20:  1.7064612  6.088043  1.7064612     1 #>  21:  2.8615077  7.899199  2.8615077     1 #>  22:  1.9236250  5.842592  1.9236250     1 #>  23:  5.5264960  7.869236  5.5264960     1 #>  24: 12.0467048  5.376368  5.3763684     0 #>  25:  4.3452714  9.312674  4.3452714     1 #>  26:  3.9798130 13.280201  3.9798130     1 #>  27:  9.7418576  5.108553  5.1085530     0 #>  28:  1.6712251  3.544233  1.6712251     1 #>  29: 14.2462641  7.742614  7.7426139     0 #>  30: 29.8433725 11.318694 11.3186940     0 #>  31: 14.9946246  8.466481  8.4664812     0 #>  32:  1.2118202  2.723590  1.2118202     1 #>  33: 18.4143115 10.264338 10.2643379     0 #>  34: 26.0671465  2.166248  2.1662481     0 #>  35:  6.0249198  6.028674  6.0249198     1 #>  36:  0.6641801  3.422689  0.6641801     1 #>  37: 22.5921361 13.086399 13.0863995     0 #>  38: 40.7684690  6.804431  6.8044311     0 #>  39: 10.9267374  1.024241  1.0242411     0 #>  40:  0.4892511 14.275858  0.4892511     1 #>  41:  4.3338206 10.519805  4.3338206     1 #>  42: 11.2127745  3.806395  3.8063949     0 #>  43:  4.5942554  5.015606  4.5942554     1 #>  44:  4.9708097  4.354121  4.3541213     0 #>  45: 16.6936971  7.108448  7.1084479     0 #>  46:  6.3725349  8.431128  6.3725349     1 #>  47:  5.0931095  4.979978  4.9799783     0 #>  48:  4.7723257  3.507726  3.5077262     0 #>  49:  3.9452410 12.536322  3.9452410     1 #>  50:  9.9472450 10.865670  9.9472450     1 #>  51:  6.5412516 10.521684  6.5412516     1 #>  52:  1.2047660 12.712452  1.2047660     1 #>  53:  3.2931742 12.021729  3.2931742     1 #>  54:  2.8338257 11.363962  2.8338257     1 #>  55: 36.7224759  7.248422  7.2484217     0 #>  56:  8.9401593 11.716753  8.9401593     1 #>  57: 36.2736286 14.462426 14.4624255     0 #>  58:  1.4994490 12.124707  1.4994490     1 #>  59:  0.8575735  7.175479  0.8575735     1 #>  60:  3.8093308 12.465804  3.8093308     1 #>  61:  1.0798844  8.766498  1.0798844     1 #>  62:  1.2428148  6.597368  1.2428148     1 #>  63:  0.4860709  2.005622  0.4860709     1 #>  64: 22.4887895  6.252786  6.2527863     0 #>  65:  0.7896928  8.996379  0.7896928     1 #>  66: 22.7244665 10.138315 10.1383154     0 #>  67:  4.7921419  8.864827  4.7921419     1 #>  68: 14.6746626  8.993059  8.9930592     0 #>  69: 18.5979601 11.857990 11.8579898     0 #>  70:  1.6670672  6.039686  1.6670672     1 #>  71: 24.7839327  9.413590  9.4135900     0 #>  72:  5.7111205 10.562092  5.7111205     1 #>  73:  2.2063292  7.467459  2.2063292     1 #>  74:  6.8294418  1.831877  1.8318769     0 #>  75:  2.4217336  6.425135  2.4217336     1 #>  76:  4.6512264  6.859208  4.6512264     1 #>  77:  3.5804775  3.933475  3.5804775     1 #>  78:  9.7949584  5.051511  5.0515106     0 #>  79:  9.6808401  4.260157  4.2601571     0 #>  80:  5.4480162 15.463842  5.4480162     1 #>  81:  1.6643375  8.817941  1.6643375     1 #>  82:  6.2972809  7.154224  6.2972809     1 #>  83:  0.9294319  2.892817  0.9294319     1 #>  84:  7.6141555  1.316250  1.3162500     0 #>  85: 16.2001667 18.098005 16.2001667     1 #>  86: 11.4249161  7.404659  7.4046588     0 #>  87: 20.8327994  5.569390  5.5693901     0 #>  88:  0.4273145 11.795497  0.4273145     1 #>  89:  3.3500529 10.961390  3.3500529     1 #>  90:  0.5275823  5.567523  0.5275823     1 #>  91:  4.1258922  3.125110  3.1251101     0 #>  92:  5.5389253 12.496082  5.5389253     1 #>  93:  1.8459367 10.133296  1.8459367     1 #>  94:  9.9258411  8.957090  8.9570896     0 #>  95:  1.2407218  3.134412  1.2407218     1 #>  96:  4.6466306  9.711062  4.6466306     1 #>  97:  1.9163111  8.116795  1.9163111     1 #>  98: 14.5709719 14.413642 14.4136417     0 #>  99:  1.0470911 18.712860  1.0470911     1 #> 100:  2.2608531  5.089427  2.2608531     1 #>       eventtime  censtime       time event d[,X2:=as.numeric(as.character(X2))] #>            X6       X7            X8          X9         X10 X1 X2 X3 X4 X5 #>   1: 67.60713 69.67119 -1.446287e+00 -1.28482865 -1.85544523  0  0  1  0  0 #>   2: 60.83520 59.93708  3.158558e-01 -0.14178173 -1.01856471  0  0  0  1  0 #>   3: 80.69528 53.74057 -3.427475e-01  1.43878477 -1.04511109  0  0  1  1  0 #>   4: 73.35923 63.87398 -1.931353e+00 -1.04005754 -0.65128765  0  0  0  1  0 #>   5: 37.84050 64.01945  2.428210e-01 -1.02383795  0.38268265  0  1  0  0  1 #>   6: 90.13616 52.50619 -3.627679e-01  1.09477379  1.03189971  0  0  1  1  1 #>   7: 73.57762 62.92928  2.432729e+00 -2.01392688  0.13107497  0  0  0  1  1 #>   8: 69.44575 55.79672  5.920912e-01 -1.04657680  0.37719173  0  1  0  1  1 #>   9: 79.20880 56.13008 -5.762008e-01  0.83340995 -1.88769508  0  1  0  0  0 #>  10: 39.05374 53.95725  4.066282e-01  0.60860245  0.52021940  0  0  1  0  1 #>  11: 61.16817 60.09412 -4.525463e-02  1.08405733  0.85915316  0  0  0  0  1 #>  12: 34.08836 53.16334  4.409000e-01  0.17271042 -0.80248866  0  0  1  1  1 #>  13: 71.57107 50.04946  2.235376e+00  1.51619199 -0.49196052  0  0  0  0  0 #>  14: 62.34562 49.21902 -5.861548e-01 -0.21720846 -0.21095432  0  1  0  0  0 #>  15: 52.31432 60.33588  5.993602e-01 -0.10825074 -0.46367661  1  0  0  0  1 #>  16: 63.89778 64.30127  1.274233e+00 -0.35771655  0.29947957  0  1  0  1  0 #>  17: 78.02487 56.08356 -9.117712e-01  0.32704438 -0.60547383  0  0  0  1  1 #>  18: 66.53057 57.21910 -1.375459e+00 -2.01294422 -0.43901213  0  0  1  1  1 #>  19: 64.85693 63.53475 -2.877269e-01 -0.14969455 -0.72075363  0  0  0  0  0 #>  20: 76.68702 60.95784  8.148341e-02 -0.93219123  0.78080503  1  0  1  0  1 #>  21: 95.81304 68.19839  3.378953e-01  0.27841306 -1.22228428  0  1  0  0  0 #>  22: 71.07430 59.12232  5.661375e-01  0.81683628  0.89119404  0  0  0  0  0 #>  23: 46.48704 58.18766 -9.342229e-01 -0.43026026  0.25392284  0  0  0  1  0 #>  24: 71.36911 70.80791  1.726770e+00  0.57233004 -0.06581643  0  1  1  1  1 #>  25: 79.60886 59.34964  1.588315e+00  0.17699375  0.20146603  0  0  0  0  0 #>  26: 66.70295 53.43514 -1.037447e+00  1.11357174  2.47770051  0  0  1  1  0 #>  27: 47.23156 63.29879  3.695074e-01 -0.58710491  0.47175279  0  0  1  0  1 #>  28: 44.28079 60.45902  4.386581e-01 -1.73823332  1.32619808  1  1  0  0  1 #>  29: 60.05991 62.24036 -8.779960e-01  0.65367143  0.66859849  0  0  0  0  1 #>  30: 38.70624 62.72042  7.609176e-01 -0.18665642 -0.13739441  0  0  1  0  0 #>  31: 67.43238 68.10389  6.428198e-02  0.63935678 -1.41117170  0  1  0  0  0 #>  32: 74.46442 66.60646  2.298479e+00 -0.03184133  1.20036310  0  0  0  0  1 #>  33: 67.72103 59.51079 -1.299978e+00  1.00223585  0.29909011  0  0  0  1  1 #>  34: 43.33935 61.92117 -1.079637e+00 -0.64106663  0.45622688  0  0  0  1  0 #>  35: 55.61299 63.87521  1.488323e+00  0.25103701  0.43807844  0  0  0  0  1 #>  36: 88.86030 62.03224 -2.307636e-01  0.57503544 -0.21502114  0  1  0  0  0 #>  37: 24.58929 59.86608  6.650739e-01 -0.63502220 -0.31212248  0  1  0  0  0 #>  38: 53.61840 66.70530 -1.160317e+00  0.85728350 -0.69263042  0  1  0  1  0 #>  39: 57.00281 63.72455  1.081541e+00  1.10488241 -2.39622968  0  0  1  1  0 #>  40: 76.21916 57.76666  4.242119e-01 -2.40522528 -1.58427493  0  1  0  1  1 #>  41: 51.28725 56.31585  7.760563e-01 -0.70096498  1.75874823  0  0  1  0  1 #>  42: 56.82391 55.74713 -7.227887e-01  0.02844935 -2.36288679  0  0  0  1  0 #>  43: 53.81463 53.29963  5.090754e-01  1.71749203  0.39317207  0  0  0  1  0 #>  44: 65.93194 63.29139  1.546150e-01 -1.12829486  0.56593786  0  0  0  1  1 #>  45: 39.94235 58.21823  3.092472e-01  1.08624613 -1.04399037  0  0  0  0  0 #>  46: 94.66977 60.24721  3.165137e-01  1.30588495  1.02311329  0  0  0  1  1 #>  47: 54.74263 54.57329  7.076799e-01 -0.98826461 -0.51266401  0  0  0  1  1 #>  48: 55.18345 60.18326 -4.624353e-01 -0.22741791  0.04773667  0  0  1  0  0 #>  49: 53.56558 46.88199  1.698303e+00 -0.14210333  1.39287700  0  0  0  0  0 #>  50: 56.55583 49.26344 -8.619856e-01  0.39601296 -0.43249913  0  0  1  0  0 #>  51: 59.16123 65.46242 -1.051830e+00 -1.93943938 -0.13516784  0  0  0  0  1 #>  52: 54.41932 51.57829  5.315186e-01 -3.32078221  1.29773515  0  0  0  1  1 #>  53: 67.11450 57.46777  7.728399e-02  0.94208189 -0.07072648  0  0  0  0  0 #>  54: 59.07443 53.54999 -1.024841e+00  0.03715139 -0.42082819  1  0  0  0  0 #>  55: 28.08466 56.69819  1.441593e-01 -0.25855501  1.14134036  0  0  0  1  1 #>  56: 44.96644 60.55578 -2.208962e-01  0.34439414 -0.42712648  1  0  0  1  1 #>  57: 52.23293 68.44091 -9.773315e-01  0.14935523  1.39566961  0  1  1  0  1 #>  58: 93.15315 67.20975  3.352802e-01  0.94046373 -0.29618717  0  0  0  0  1 #>  59: 64.87477 61.03908  1.587367e+00 -2.21790192  0.58265961  0  0  1  1  0 #>  60: 40.84787 57.32315  1.269826e+00 -1.79355876 -2.67622935  0  0  0  1  1 #>  61: 91.17939 61.26102  2.887333e+00  1.69210689 -1.40067901  0  0  0  0  1 #>  62: 68.26378 55.15752  6.832389e-01 -1.67249615  3.30415111  0  1  0  1  1 #>  63: 90.15721 60.25976 -6.769761e-01 -1.73719284  0.85677754  0  0  1  0  0 #>  64: 55.68636 66.36291 -1.638704e-01 -0.02663486  1.16101645  0  1  0  1  0 #>  65: 67.22259 57.66221  7.096116e-01  0.06580442  0.27893689  1  0  0  1  0 #>  66: 39.32216 57.32037 -1.053669e+00 -1.46232344 -0.01354850  0  1  0  1  0 #>  67: 73.84366 64.15761 -9.562285e-01 -0.41940470 -2.67637889  0  0  0  0  0 #>  68: 47.70464 61.77510 -9.451874e-01  0.57684701  0.12131445  0  0  0  0  1 #>  69: 50.25840 62.26019  2.247884e-01 -0.60692236 -0.50054324  0  0  1  1  1 #>  70: 82.33657 64.39757  3.594552e-01 -0.06921954  1.37967791  1  0  1  1  1 #>  71: 45.88178 59.45799 -6.637104e-01  1.33394384 -0.40598666  0  0  1  1  0 #>  72: 42.38993 47.80939 -1.265082e-01 -0.76774206  1.39593194  0  0  0  1  0 #>  73: 71.89668 63.67757  1.642374e+00  0.55319467  0.73859616  0  0  0  0  1 #>  74: 48.05875 52.65778 -5.070985e-01 -1.70865790  0.73661415  0  0  0  0  1 #>  75: 74.84172 61.88597 -5.184870e-01 -0.52672810 -0.73308795  0  1  0  1  1 #>  76: 91.60804 63.32283  1.343653e+00  2.06376423 -1.89839605  0  1  0  1  0 #>  77: 87.40961 59.72468  8.748702e-02  0.42372826  0.44587930  0  0  0  0  1 #>  78: 65.89167 60.84810  5.376727e-01  1.00855573  0.45626086  0  0  0  0  1 #>  79: 58.56517 65.99554  1.492186e+00  1.36114180 -1.52619721  0  0  0  1  0 #>  80: 71.10492 64.14804  8.767927e-01 -0.10595486 -0.08058262  0  0  1  0  1 #>  81: 77.02966 66.49966  4.958852e-01  0.04150070 -0.34001061  0  0  0  0  0 #>  82: 71.90150 53.59561 -2.473539e-01  1.11989772  0.05368080  0  0  0  0  1 #>  83: 71.35316 55.32200 -7.287776e-01  0.23916287 -0.69163485  0  1  0  0  1 #>  84: 55.30238 61.83689  8.741936e-01 -1.03908394 -0.30349490  0  0  0  0  1 #>  85: 22.60817 59.94846 -7.606030e-01 -0.49175571 -1.19501405  0  0  1  0  0 #>  86: 58.87421 57.04893  4.029195e-01  0.38418962  1.01973592  0  0  0  1  0 #>  87: 46.09025 64.62609 -5.317420e-01 -0.14747227 -0.47844422  0  0  0  1  0 #>  88: 78.52232 59.53003  1.193348e-05 -0.65047518 -0.65949205  1  1  0  1  0 #>  89: 62.74970 64.89474  8.181784e-01  0.05630389  0.67887965  0  0  1  0  0 #>  90: 72.57549 55.50661  2.691192e-01 -0.24660122 -0.10535533  1  0  0  0  1 #>  91: 70.05943 61.18653 -3.880011e-01  1.23622156 -0.45371767  0  1  0  0  1 #>  92: 39.53909 56.46051 -3.247585e-01 -0.17832690  1.34143863  0  0  0  1  0 #>  93: 69.97910 53.47501  1.680009e+00  1.23646958  0.98595720  0  0  1  0  0 #>  94: 70.89334 64.13688 -2.880736e+00 -1.08216683 -1.19546478  0  0  0  1  1 #>  95: 64.40614 62.91072  6.221381e-01 -0.49419020 -0.57485857  1  0  0  0  1 #>  96: 45.97832 53.21347 -2.203552e+00 -1.71111303  0.98199136  1  0  0  0  0 #>  97: 78.72715 61.59434 -2.726918e-01  0.04005805 -1.65738323  0  0  0  1  0 #>  98: 34.65440 58.68629 -9.221195e-01 -0.56114348 -1.11964693  0  0  0  1  1 #>  99: 82.23566 54.07995 -3.062827e-01 -2.55736206 -1.17082441  0  1  1  0  0 #> 100: 76.36865 60.93626  2.536559e+00 -0.69677881 -1.13905161  0  0  0  0  1 #>            X6       X7            X8          X9         X10 X1 X2 X3 X4 X5 #>       eventtime  censtime       time event #>   1:  6.7778319 10.855483  6.7778319     1 #>   2:  9.9851341 11.645024  9.9851341     1 #>   3:  0.8401512  7.704695  0.8401512     1 #>   4:  8.5391295 16.957550  8.5391295     1 #>   5: 14.9499500  8.706974  8.7069741     0 #>   6:  2.6489767  8.521409  2.6489767     1 #>   7:  1.3483311  4.558061  1.3483311     1 #>   8:  0.5893505  9.966877  0.5893505     1 #>   9:  2.4964235  7.772476  2.4964235     1 #>  10: 18.8061049 13.305700 13.3057001     0 #>  11: 12.0984084  6.855722  6.8557222     0 #>  12: 21.3980774  3.540841  3.5408414     0 #>  13:  7.8763135 11.276980  7.8763135     1 #>  14:  4.8244485  9.592070  4.8244485     1 #>  15:  4.3768039  5.206590  4.3768039     1 #>  16:  9.3937423  6.339864  6.3398641     0 #>  17:  8.5220276 12.596186  8.5220276     1 #>  18:  1.4842932 10.141747  1.4842932     1 #>  19: 10.6713543 10.114892 10.1148916     0 #>  20:  1.7064612  6.088043  1.7064612     1 #>  21:  2.8615077  7.899199  2.8615077     1 #>  22:  1.9236250  5.842592  1.9236250     1 #>  23:  5.5264960  7.869236  5.5264960     1 #>  24: 12.0467048  5.376368  5.3763684     0 #>  25:  4.3452714  9.312674  4.3452714     1 #>  26:  3.9798130 13.280201  3.9798130     1 #>  27:  9.7418576  5.108553  5.1085530     0 #>  28:  1.6712251  3.544233  1.6712251     1 #>  29: 14.2462641  7.742614  7.7426139     0 #>  30: 29.8433725 11.318694 11.3186940     0 #>  31: 14.9946246  8.466481  8.4664812     0 #>  32:  1.2118202  2.723590  1.2118202     1 #>  33: 18.4143115 10.264338 10.2643379     0 #>  34: 26.0671465  2.166248  2.1662481     0 #>  35:  6.0249198  6.028674  6.0249198     1 #>  36:  0.6641801  3.422689  0.6641801     1 #>  37: 22.5921361 13.086399 13.0863995     0 #>  38: 40.7684690  6.804431  6.8044311     0 #>  39: 10.9267374  1.024241  1.0242411     0 #>  40:  0.4892511 14.275858  0.4892511     1 #>  41:  4.3338206 10.519805  4.3338206     1 #>  42: 11.2127745  3.806395  3.8063949     0 #>  43:  4.5942554  5.015606  4.5942554     1 #>  44:  4.9708097  4.354121  4.3541213     0 #>  45: 16.6936971  7.108448  7.1084479     0 #>  46:  6.3725349  8.431128  6.3725349     1 #>  47:  5.0931095  4.979978  4.9799783     0 #>  48:  4.7723257  3.507726  3.5077262     0 #>  49:  3.9452410 12.536322  3.9452410     1 #>  50:  9.9472450 10.865670  9.9472450     1 #>  51:  6.5412516 10.521684  6.5412516     1 #>  52:  1.2047660 12.712452  1.2047660     1 #>  53:  3.2931742 12.021729  3.2931742     1 #>  54:  2.8338257 11.363962  2.8338257     1 #>  55: 36.7224759  7.248422  7.2484217     0 #>  56:  8.9401593 11.716753  8.9401593     1 #>  57: 36.2736286 14.462426 14.4624255     0 #>  58:  1.4994490 12.124707  1.4994490     1 #>  59:  0.8575735  7.175479  0.8575735     1 #>  60:  3.8093308 12.465804  3.8093308     1 #>  61:  1.0798844  8.766498  1.0798844     1 #>  62:  1.2428148  6.597368  1.2428148     1 #>  63:  0.4860709  2.005622  0.4860709     1 #>  64: 22.4887895  6.252786  6.2527863     0 #>  65:  0.7896928  8.996379  0.7896928     1 #>  66: 22.7244665 10.138315 10.1383154     0 #>  67:  4.7921419  8.864827  4.7921419     1 #>  68: 14.6746626  8.993059  8.9930592     0 #>  69: 18.5979601 11.857990 11.8579898     0 #>  70:  1.6670672  6.039686  1.6670672     1 #>  71: 24.7839327  9.413590  9.4135900     0 #>  72:  5.7111205 10.562092  5.7111205     1 #>  73:  2.2063292  7.467459  2.2063292     1 #>  74:  6.8294418  1.831877  1.8318769     0 #>  75:  2.4217336  6.425135  2.4217336     1 #>  76:  4.6512264  6.859208  4.6512264     1 #>  77:  3.5804775  3.933475  3.5804775     1 #>  78:  9.7949584  5.051511  5.0515106     0 #>  79:  9.6808401  4.260157  4.2601571     0 #>  80:  5.4480162 15.463842  5.4480162     1 #>  81:  1.6643375  8.817941  1.6643375     1 #>  82:  6.2972809  7.154224  6.2972809     1 #>  83:  0.9294319  2.892817  0.9294319     1 #>  84:  7.6141555  1.316250  1.3162500     0 #>  85: 16.2001667 18.098005 16.2001667     1 #>  86: 11.4249161  7.404659  7.4046588     0 #>  87: 20.8327994  5.569390  5.5693901     0 #>  88:  0.4273145 11.795497  0.4273145     1 #>  89:  3.3500529 10.961390  3.3500529     1 #>  90:  0.5275823  5.567523  0.5275823     1 #>  91:  4.1258922  3.125110  3.1251101     0 #>  92:  5.5389253 12.496082  5.5389253     1 #>  93:  1.8459367 10.133296  1.8459367     1 #>  94:  9.9258411  8.957090  8.9570896     0 #>  95:  1.2407218  3.134412  1.2407218     1 #>  96:  4.6466306  9.711062  4.6466306     1 #>  97:  1.9163111  8.116795  1.9163111     1 #>  98: 14.5709719 14.413642 14.4136417     0 #>  99:  1.0470911 18.712860  1.0470911     1 #> 100:  2.2608531  5.089427  2.2608531     1 #>       eventtime  censtime       time event # then fit a Cox model library(rms) cphmodel <- cph(Surv(time,event)~X1+X2,data=d,surv=TRUE,x=TRUE,y=TRUE) # or via survival library(survival) coxphmodel <- coxph(Surv(time,event)~X1+X2,data=d,x=TRUE,y=TRUE)  # Extract predicted survival probabilities  # at selected time-points: ttt <- quantile(d$time) # for selected predictor values: ndat <- data.frame(X1=c(0.25,0.25,-0.05,0.05),X2=c(0,1,0,1)) # as follows predictRisk(cphmodel,newdata=ndat,times=ttt) #>             [,1]      [,2]      [,3]      [,4]      [,5] #> [1,] 0.010423552 0.2498546 0.4661259 0.6749391 0.9490180 #> [2,] 0.011569784 0.2733328 0.5019288 0.7129324 0.9633185 #> [3,] 0.007190205 0.1796201 0.3509290 0.5387894 0.8712277 #> [4,] 0.009034264 0.2204172 0.4193263 0.6221600 0.9240581 predictRisk(coxphmodel,newdata=ndat,times=ttt) #>             [,1]      [,2]      [,3]      [,4]      [,5] #> [1,] 0.010423555 0.2498546 0.4661259 0.6749389 0.9490178 #> [2,] 0.011569787 0.2733328 0.5019287 0.7129322 0.9633183 #> [3,] 0.007190219 0.1796204 0.3509294 0.5387898 0.8712279 #> [4,] 0.009034276 0.2204174 0.4193266 0.6221602 0.9240581  # stratified cox model sfit <- coxph(Surv(time,event)~strata(X1)+X2,data=d,x=TRUE,y=TRUE) predictRisk(sfit,newdata=d[1:3,],times=c(1,3,5,10)) #>            [,1]     [,2]      [,3]     [,4] #> [1,] 0.07654315 0.281073 0.4322176 0.689776 #> [2,] 0.07654315 0.281073 0.4322176 0.689776 #> [3,] 0.07654315 0.281073 0.4322176 0.689776  ## simulate learning and validation data learndat <- sampleData(100,outcome=\"survival\") valdat <- sampleData(100,outcome=\"survival\") ## use the learning data to fit a Cox model library(survival) fitCox <- coxph(Surv(time,event)~X1+X2,data=learndat,x=TRUE,y=TRUE) ## suppose we want to predict the survival probabilities for all subjects ## in the validation data at the following time points: ## 0, 12, 24, 36, 48, 60 psurv <- predictRisk(fitCox,newdata=valdat,times=seq(0,60,12)) ## This is a matrix with event probabilities (1-survival) ## one column for each of the 5 time points ## one row for each validation set individual  # Do the same for a randomSurvivalForest model # library(randomForestSRC) # rsfmodel <- rfsrc(Surv(time,event)~X1+X2,data=learndat) # prsfsurv=predictRisk(rsfmodel,newdata=valdat,times=seq(0,60,12)) # plot(psurv,prsfsurv)  ## Cox with ridge option f1 <- coxph(Surv(time,event)~X1+X2,data=learndat,x=TRUE,y=TRUE) f2 <- coxph(Surv(time,event)~ridge(X1)+ridge(X2),data=learndat,x=TRUE,y=TRUE) if (FALSE) { plot(predictRisk(f1,newdata=valdat,times=10),      riskRegression:::predictRisk.coxph(f2,newdata=valdat,times=10),      xlim=c(0,1),      ylim=c(0,1),      xlab=\"Unpenalized predicted survival chance at 10\",      ylab=\"Ridge predicted survival chance at 10\") }  ## competing risks  library(survival) library(riskRegression) library(prodlim) train <- prodlim::SimCompRisk(100) test <- prodlim::SimCompRisk(10) cox.fit  <- CSC(Hist(time,cause)~X1+X2,data=train) predictRisk(cox.fit,newdata=test,times=seq(1:10),cause=1) #>              [,1]        [,2]       [,3]       [,4]       [,5]       [,6] #>  [1,] 0.003336186 0.006815801 0.01619852 0.02672988 0.04254840 0.06207469 #>  [2,] 0.031154093 0.062123978 0.14073384 0.21892189 0.31623402 0.40920676 #>  [3,] 0.002135486 0.004370331 0.01041397 0.01724860 0.02764812 0.04069547 #>  [4,] 0.015269678 0.031098095 0.07285185 0.11851646 0.18515067 0.26350414 #>  [5,] 0.071858689 0.141485382 0.30494285 0.45213411 0.61501518 0.74365714 #>  [6,] 0.008438974 0.017143504 0.04034630 0.06571777 0.10222401 0.14483683 #>  [7,] 0.019114164 0.038834445 0.09045024 0.14615640 0.22589234 0.31715015 #>  [8,] 0.012909266 0.026116995 0.06098177 0.09834693 0.15043127 0.20869101 #>  [9,] 0.088712245 0.169974894 0.35189416 0.49656435 0.62685981 0.70423405 #> [10,] 0.014431815 0.029407277 0.06897824 0.11238172 0.17598556 0.25122048 #>             [,7]       [,8]       [,9]     [,10] #>  [1,] 0.10014146 0.11107754 0.11107754 0.1566170 #>  [2,] 0.52199267 0.54231411 0.54231411 0.5854577 #>  [3,] 0.06697324 0.07473752 0.07473752 0.1084884 #>  [4,] 0.40501038 0.44254884 0.44254884 0.5868296 #>  [5,] 0.85808309 0.87165494 0.87165494 0.8886527 #>  [6,] 0.21937006 0.23879428 0.23879428 0.3087464 #>  [7,] 0.47403469 0.51371708 0.51371708 0.6569501 #>  [8,] 0.30273776 0.32546337 0.32546337 0.3987820 #>  [9,] 0.74636289 0.74893384 0.74893384 0.7499682 #> [10,] 0.38857610 0.42539186 0.42539186 0.5688372  ## with strata cox.fit2  <- CSC(list(Hist(time,cause)~strata(X1)+X2,Hist(time,cause)~X1+X2),data=train) predictRisk(cox.fit2,newdata=test,times=seq(1:10),cause=1) #>              [,1]        [,2]        [,3]       [,4]       [,5]       [,6] #>  [1,] 0.003408683 0.006817084 0.014309898 0.01918373 0.03858482 0.07252045 #>  [2,] 0.031858033 0.062417019 0.125586702 0.16409076 0.29136919 0.45125305 #>  [3,] 0.002183560 0.004372607 0.009202652 0.01235594 0.02508376 0.04776776 #>  [4,] 0.014921141 0.031035493 0.076679322 0.13563418 0.19232139 0.24677922 #>  [5,] 0.070581243 0.141808469 0.320150086 0.50265176 0.63413772 0.72648490 #>  [6,] 0.008612007 0.017146262 0.035664275 0.04755050 0.09280959 0.16678930 #>  [7,] 0.018683356 0.038764611 0.095183187 0.16690843 0.23453254 0.29813092 #>  [8,] 0.013172600 0.026136611 0.053982039 0.07166659 0.13690221 0.23793972 #>  [9,] 0.091973643 0.173528151 0.323325921 0.40329682 0.59785720 0.71952743 #> [10,] 0.014101554 0.029346853 0.072605636 0.12867447 0.18281979 0.23507918 #>             [,7]       [,8]       [,9]      [,10] #>  [1,] 0.11733823 0.11733823 0.11733823 0.11733823 #>  [2,] 0.56711144 0.56711144 0.56711144 0.56711144 #>  [3,] 0.07887777 0.07887777 0.07887777 0.07887777 #>  [4,] 0.38320640 0.44483827 0.44483827 0.60016503 #>  [5,] 0.85495833 0.87963912 0.87963912 0.89157834 #>  [6,] 0.25269590 0.25269590 0.25269590 0.25269590 #>  [7,] 0.45111926 0.51696557 0.51696557 0.66986176 #>  [8,] 0.34430205 0.34430205 0.34430205 0.34430205 #>  [9,] 0.74198812 0.74198812 0.74198812 0.74198812 #> [10,] 0.36717403 0.42747770 0.42747770 0.58216010"},{"path":"/reference/print.CauseSpecificCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Print of a Cause-Specific Cox regression model — print.CauseSpecificCox","title":"Print of a Cause-Specific Cox regression model — print.CauseSpecificCox","text":"Print Cause-Specific Cox regression model","code":""},{"path":"/reference/print.CauseSpecificCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print of a Cause-Specific Cox regression model — print.CauseSpecificCox","text":"","code":"# S3 method for CauseSpecificCox print(x, ...)"},{"path":"/reference/print.CauseSpecificCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print of a Cause-Specific Cox regression model — print.CauseSpecificCox","text":"x Object obtained CSC ... Passed print","code":""},{"path":"/reference/print.FGR.html","id":null,"dir":"Reference","previous_headings":"","what":"Print of a Fine-Gray regression model — print.FGR","title":"Print of a Fine-Gray regression model — print.FGR","text":"Print Fine-Gray regression model","code":""},{"path":"/reference/print.FGR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print of a Fine-Gray regression model — print.FGR","text":"","code":"# S3 method for FGR print(x, ...)"},{"path":"/reference/print.FGR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print of a Fine-Gray regression model — print.FGR","text":"x Object fitted function FGR ... passed cmprsk::summary.crr","code":""},{"path":"/reference/print.IPA.html","id":null,"dir":"Reference","previous_headings":"","what":"Print IPA object — print.IPA","title":"Print IPA object — print.IPA","text":"Print method IPA","code":""},{"path":"/reference/print.IPA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print IPA object — print.IPA","text":"","code":"# S3 method for IPA print(x, digits = 2, ...)"},{"path":"/reference/print.IPA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print IPA object — print.IPA","text":"x Object obtained IPA digits Number digits ... passed print","code":""},{"path":"/reference/print.IPA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print IPA object — print.IPA","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/print.Score.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Score object — print.Score","title":"Print Score object — print.Score","text":"Print method risk prediction scores","code":""},{"path":"/reference/print.Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Score object — print.Score","text":"","code":"# S3 method for Score print(x, digits, ...)"},{"path":"/reference/print.Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Score object — print.Score","text":"x Object obtained Score.list digits Number digits ... passed print","code":""},{"path":"/reference/print.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Average Treatment Effects — print.ate","title":"Print Average Treatment Effects — print.ate","text":"Print average treatment effects.","code":""},{"path":"/reference/print.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Average Treatment Effects — print.ate","text":"","code":"# S3 method for ate print(x, estimator = x$estimator, ...)"},{"path":"/reference/print.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Average Treatment Effects — print.ate","text":"x object obtained function ate estimator [character] type estimator relative risks output. ... internal use","code":""},{"path":[]},{"path":"/reference/print.influenceTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Output of the DIfference Between Two Estimates — print.influenceTest","title":"Output of the DIfference Between Two Estimates — print.influenceTest","text":"Output difference two estimates.","code":""},{"path":"/reference/print.influenceTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output of the DIfference Between Two Estimates — print.influenceTest","text":"","code":"# S3 method for influenceTest print(x, digits = 3, ...)"},{"path":"/reference/print.influenceTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output of the DIfference Between Two Estimates — print.influenceTest","text":"x object obtained function influenceTest. digits [integer, >0] indicating number decimal places. ... Passed print.","code":""},{"path":"/reference/print.influenceTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Output of the DIfference Between Two Estimates — print.influenceTest","text":"display confidence intervals/bands, confint method needs applied object.","code":""},{"path":[]},{"path":"/reference/print.predictCSC.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Predictions From a Cause-specific Cox Proportional Hazard Regression — print.predictCSC","title":"Print Predictions From a Cause-specific Cox Proportional Hazard Regression — print.predictCSC","text":"Print predictions Cause-specific Cox proportional hazard regression.","code":""},{"path":"/reference/print.predictCSC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Predictions From a Cause-specific Cox Proportional Hazard Regression — print.predictCSC","text":"","code":"# S3 method for predictCSC print(x, digits = 3, ...)"},{"path":"/reference/print.predictCSC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Predictions From a Cause-specific Cox Proportional Hazard Regression — print.predictCSC","text":"x object obtained function predictCox. digits [integer, >0] indicating number decimal places. ... Passed print.","code":""},{"path":"/reference/print.predictCSC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Predictions From a Cause-specific Cox Proportional Hazard Regression — print.predictCSC","text":"display confidence intervals/bands, confint method needs applied object.","code":""},{"path":[]},{"path":"/reference/print.predictCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Predictions From a Cox Model — print.predictCox","title":"Print Predictions From a Cox Model — print.predictCox","text":"Print predictions Cox model.","code":""},{"path":"/reference/print.predictCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Predictions From a Cox Model — print.predictCox","text":"","code":"# S3 method for predictCox print(x, digits = 3, ...)"},{"path":"/reference/print.predictCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Predictions From a Cox Model — print.predictCox","text":"x object obtained function predictCox. digits [integer, >0] indicating number decimal places. ... Passed print.","code":""},{"path":"/reference/print.predictCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Predictions From a Cox Model — print.predictCox","text":"display confidence intervals/bands, confint method needs applied object.","code":""},{"path":[]},{"path":"/reference/print.riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for riskRegression models — print.riskRegression","title":"Print function for riskRegression models — print.riskRegression","text":"Print function riskRegression models","code":""},{"path":"/reference/print.riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for riskRegression models — print.riskRegression","text":"","code":"# S3 method for riskRegression print(x, times, digits = 3, eps = 10^-4, verbose = TRUE, conf.int = 0.95, ...)"},{"path":"/reference/print.riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for riskRegression models — print.riskRegression","text":"x Object obtained ARR, LRR riskRegression times Time points show time-dependent coefficients digits Number digits numbers p-values eps p-values smaller number shown verbose Level verbosity conf.int level confidence. default 0.95 ... used","code":""},{"path":"/reference/print.subjectWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Print subject weights — print.subjectWeights","title":"Print subject weights — print.subjectWeights","text":"Print subject weights","code":""},{"path":"/reference/print.subjectWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print subject weights — print.subjectWeights","text":"","code":"# S3 method for subjectWeights print(x, digits = 3, ...)"},{"path":"/reference/print.subjectWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print subject weights — print.subjectWeights","text":"x Subject weights digits Digits ... used","code":""},{"path":"/reference/reconstructData.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconstruct the original dataset — reconstructData","title":"Reconstruct the original dataset — reconstructData","text":"Reconstruct original dataset elements stored coxph object","code":""},{"path":"/reference/reconstructData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconstruct the original dataset — reconstructData","text":"","code":"reconstructData(object)"},{"path":"/reference/reconstructData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconstruct the original dataset — reconstructData","text":"object coxph object.","code":""},{"path":"/reference/reconstructData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reconstruct the original dataset — reconstructData","text":"Brice Ozenne broz@sund.ku.dk Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/riskLevelPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Level plots for risk prediction models — riskLevelPlot","title":"Level plots for risk prediction models — riskLevelPlot","text":"Level plots predicted risks","code":""},{"path":"/reference/riskLevelPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Level plots for risk prediction models — riskLevelPlot","text":"","code":"riskLevelPlot(   object,   formula,   data = parent.frame(),   horizon = NULL,   cause = 1,   ... )"},{"path":"/reference/riskLevelPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Level plots for risk prediction models — riskLevelPlot","text":"object risk prediction model object formula formula data data horizon time point cause cause interst ... passed lattice::levelplot","code":""},{"path":"/reference/riskLevelPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Level plots for risk prediction models — riskLevelPlot","text":"Level plots predicted risks","code":""},{"path":"/reference/riskLevelPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Level plots for risk prediction models — riskLevelPlot","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/riskLevelPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Level plots for risk prediction models — riskLevelPlot","text":"","code":"# ---------- logistic regression -------------------- expit <- function(x){exp(x)/(1+exp(x))} partyData <- function(N){   Age <- runif(N,.5,15)   Parasites <- rnorm(N,mean=3.5-0.03*Age)   Fever <- factor(rbinom(N,1,expit(-3.5-.3*Age+.55*Parasites+0.15*Age*Parasites)))   data.frame(Fever,Age,Parasites) } d <- partyData(100) f <- glm(Fever~Age+Parasites,data=d,family=\"binomial\") riskLevelPlot(f,Fever~Age+Parasites,d)  if (requireNamespace(\"randomForest\",quietly=TRUE)){ rf <- randomForest::randomForest(Fever~Age+Parasites,data=d) riskLevelPlot(f,Fever~Age+Parasites,d) riskLevelPlot(rf,Fever~Age+Parasites,d) }   # ---------- survival analysis --------------------  # --simulate an artificial data frame # with survival response and three predictors  library(survival) library(prodlim) set.seed(140515) sdat <- sampleData(43,outcome=\"survival\") # -- fit a Cox regression model  survForm = Surv(time,event) ~ X8 + X9 cox <- coxph(survForm, data = sdat,x=TRUE)  # --choose a time horizon for the predictions and plot the risks timeHorizon <- floor(median(sdat$time)) riskLevelPlot(cox, survForm, data = sdat, horizon = timeHorizon)   # ---------- competing risks --------------------  # -- simulate an artificial data frame # with competing cause response and three predictors library(cmprsk) library(riskRegression) set.seed(140515) crdat <- sampleData(49)  # -- fit a cause-specific Cox regression model crForm <- Hist(time,event)~X8+X9 csCox  <- CSC(crForm, data=crdat)  # -- choose a time horizon and plot the risk for a given cause timeHorizon <- floor(median(crdat$time)) riskLevelPlot(csCox, crForm, data = crdat, horizon = timeHorizon, cause = 1)"},{"path":"/reference/riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"wrapper function comp.risk timereg package. main difference one marks variables formula time-dependent effect whereas comp.risk one marks variables time constant (proportional) effect.","code":""},{"path":"/reference/riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"","code":"riskRegression(   formula,   data,   times,   link = \"relative\",   cause,   conf.int = TRUE,   cens.model,   cens.formula,   max.iter = 50,   conservative = TRUE,   ... )"},{"path":"/reference/riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"formula Formula left hand side specifies event history event.history right hand side linear predictor.  See examples. data data fitting model includes variables included formula. times Vector times. time point times estimate baseline risk timevarying coefficients. link \"relative\" absolute risk regression model.  \"logistic\" logistic risk regression model. \"prop\" Fine-Gray regression model. cause cause interest. conf.int TRUE return iid decomposition, can used construct confidence bands predictions. cens.model Specified model (conditional) censoring distribution used deriving weights (IFPW). Defaults \"KM\" (Kaplan-Meier method ignoring covariates) alternatively may \"Cox\" (Cox regression). cens.formula Right hand side formula used fitting censoring model.  specified right hand side formula used. max.iter Maximal number iterations. conservative TRUE use variance formula ignores contribution estimate inverse probability censoring weights ... arguments passed comp.risk","code":""},{"path":"/reference/riskRegression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"Thomas Gerds, Thomas H Scheike, Per K Andersen. Absolute risk regression competing risks: interpretation, link functions, prediction. Statistics medicine, 31(29):3921--3930, 2012. Scheike, Zhang Gerds (2008), Predicting cumulative incidence probability direct binomial regression, Biometrika, 95, 205-220. Scheike Zhang (2007), Flexible competing risks regression modelling goodness fit, LIDA, 14, 464-483. Martinussen Scheike (2006), Dynamic regression models survival data, Springer.","code":""},{"path":"/reference/riskRegression.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"Thomas . Gerds tag@biostat.ku.dk, Thomas H. Scheike ts@biostat.ku.dk","code":""},{"path":"/reference/riskRegression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Risk Regression\nFits a regression model for the risk of an event -- allowing for competing\nrisks. — riskRegression","text":"","code":"library(prodlim) data(Melanoma,package=\"riskRegression\") ## tumor thickness on the log-scale Melanoma$logthick <- log(Melanoma$thick)  # Single binary factor  ## absolute risk regression library(survival) library(prodlim) fit.arr <- ARR(Hist(time,status)~sex,data=Melanoma,cause=1) print(fit.arr) #> Competing risks regression model  #>  #> IPCW weights: marginal Kaplan-Meier for the censoring distribution. #> Link: 'log' yielding absolute risk ratios #> No covariates with time-varying coefficient specified. #>  #> Time constant regression coefficients: #>  Variable Levels Coef Lower Upper  Pvalue #>       sex   Male 1.87  1.17  3.01 0.00927 #>  #>  #> Note: The coefficients (Coef) are absolute risk ratios  # show predicted cumulative incidences plot(fit.arr,col=3:4,newdata=data.frame(sex=c(\"Female\",\"Male\")))   ## compare with non-parametric Aalen-Johansen estimate library(prodlim) fit.aj <- prodlim(Hist(time,status)~sex,data=Melanoma) plot(fit.aj,conf.int=FALSE) plot(fit.arr,add=TRUE,col=3:4,newdata=data.frame(sex=c(\"Female\",\"Male\")))   ## with time-dependent effect fit.tarr <- ARR(Hist(time,status)~strata(sex),data=Melanoma,cause=1) plot(fit.tarr,newdata=data.frame(sex=c(\"Female\",\"Male\")))   ## logistic risk regression fit.lrr <- LRR(Hist(time,status)~sex,data=Melanoma,cause=1) summary(fit.lrr) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> the Kaplan-Meier estimate for the censoring distribution. #>  #> Link function: 'logistic' yielding odds ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) #> 230  \"1.013\"     #> 770  \"1.064\"     #> 1100 \"1.122\"     #> 1700 \"1.198\"     #> 3300 \"1.431\"     #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Covariates with time-constant effects: #>  #>  sexMale (numeric) #>  #> Time constant regression coefficients: #>  #>   Factor  Coef exp(Coef) StandardError     z         CI_95   Pvalue #>  sexMale 0.832     2.298         0.319 2.605 [1.229;4.298] 0.009184 #>  #>  #> Note: The values exp(Coef) are odds ratios    # Single continuous factor  ## tumor thickness on the log-scale Melanoma$logthick <- log(Melanoma$thick)  ## absolute risk regression  fit2.arr <- ARR(Hist(time,status)~logthick,data=Melanoma,cause=1) print(fit2.arr) #> Competing risks regression model  #>  #> IPCW weights: marginal Kaplan-Meier for the censoring distribution. #> Link: 'log' yielding absolute risk ratios #> No covariates with time-varying coefficient specified. #>  #> Time constant regression coefficients: #>  Variable Levels Coef Lower Upper Pvalue #>  logthick        1.87  1.49  2.35 <1e-04 #>  #>  #> Note: The coefficients (Coef) are absolute risk ratios  # show predicted cumulative incidences plot(fit2.arr,col=1:5,newdata=data.frame(logthick=quantile(Melanoma$logthick)))   ## comparison with nearest neighbor non-parametric Aalen-Johansen estimate library(prodlim) fit2.aj <- prodlim(Hist(time,status)~logthick,data=Melanoma) plot(fit2.aj,conf.int=FALSE,newdata=data.frame(logthick=quantile(Melanoma$logthick))) plot(fit2.arr,add=TRUE,col=1:5,lty=3,newdata=data.frame(logthick=quantile(Melanoma$logthick)))   ## logistic risk regression fit2.lrr <- LRR(Hist(time,status)~logthick,data=Melanoma,cause=1) summary(fit2.lrr) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> the Kaplan-Meier estimate for the censoring distribution. #>  #> Link function: 'logistic' yielding odds ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) #> 230  \"1.007\"     #> 770  \"1.040\"     #> 1100 \"1.074\"     #> 1700 \"1.120\"     #> 3300 \"1.283\"     #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Covariates with time-constant effects: #>  #>  logthick (numeric) #>  #> Time constant regression coefficients: #>  #>    Factor  Coef exp(Coef) StandardError     z         CI_95  Pvalue #>  logthick 1.003     2.726         0.214 4.677 [1.790;4.149] < 1e-04 #>  #>  #> Note: The values exp(Coef) are odds ratios   ## change model for censoring weights library(rms) fit2a.lrr <- LRR(Hist(time,status)~logthick,                  data=Melanoma,                  cause=1,                  cens.model=\"cox\",                  cens.formula=~sex+epicel+ulcer+age+logthick) summary(fit2a.lrr) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> a Cox model for the censoring distribution. #>  #> Link function: 'logistic' yielding odds ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) #> 230  \"1.007\"     #> 770  \"1.040\"     #> 1100 \"1.074\"     #> 1700 \"1.120\"     #> 3300 \"1.283\"     #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Covariates with time-constant effects: #>  #>  logthick (numeric) #>  #> Time constant regression coefficients: #>  #>    Factor  Coef exp(Coef) StandardError     z         CI_95  Pvalue #>  logthick 1.003     2.726         0.214 4.677 [1.790;4.149] < 1e-04 #>  #>  #> Note: The values exp(Coef) are odds ratios   ##  compare prediction performance Score(list(ARR=fit2.arr,AJ=fit2.aj,LRR=fit2.lrr),formula=Hist(time,status)~1,data=Melanoma) #>  #> Metric AUC: #>  #> Results by model: #>  #>    model times  AUC lower upper #> 1:   ARR  2006 60.0  55.5  64.5 #> 2:    AJ  2006 72.6  64.4  80.8 #> 3:   LRR  2006 73.8  65.7  82.0 #>  #> Results of model comparisons: #>  #>    times model reference delta.AUC lower upper     p #> 1:  2006    AJ       ARR      12.6   5.1  20.1 9e-04 #> 2:  2006   LRR       ARR      13.8   6.4  21.2 3e-04 #> 3:  2006   LRR        AJ       1.2  -0.5   2.9 2e-01 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The higher AUC the better. #>  #> Metric Brier: #>  #> Results by model: #>  #>         model times Brier lower upper #> 1: Null model  2006  17.7  14.5  20.9 #> 2:        ARR  2006  68.9  62.7  75.1 #> 3:         AJ  2006  15.9  13.0  18.7 #> 4:        LRR  2006  34.8  30.8  38.8 #>  #> Results of model comparisons: #>  #>    times model  reference delta.Brier lower upper            p #> 1:  2006   ARR Null model        51.2  42.1  60.2 1.453263e-28 #> 2:  2006    AJ Null model        -1.9  -3.8   0.0 5.626213e-02 #> 3:  2006   LRR Null model        17.1  10.8  23.4 9.691641e-08 #> 4:  2006    AJ        ARR       -53.1 -61.3 -44.8 1.940307e-36 #> 5:  2006   LRR        ARR       -34.1 -38.2 -29.9 1.253980e-58 #> 6:  2006   LRR         AJ        19.0  13.9  24.1 2.963694e-13 #>  #> NOTE: Values are multiplied by 100 and given in %. #> NOTE: The lower Brier the better.   # multiple regression library(riskRegression) library(prodlim) # absolute risk model multi.arr <- ARR(Hist(time,status)~logthick+sex+age+ulcer,data=Melanoma,cause=1)  # stratified model allowing different baseline risk for the two gender multi.arr <- ARR(Hist(time,status)~thick+strata(sex)+age+ulcer,data=Melanoma,cause=1)  # stratify by a continuous variable: strata(age) multi.arr <- ARR(Hist(time,status)~tp(thick,power=0)+strata(age)+sex+ulcer,                  data=Melanoma,                  cause=1)  fit.arr2a <- ARR(Hist(time,status)~tp(thick,power=1),data=Melanoma,cause=1) summary(fit.arr2a) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> the Kaplan-Meier estimate for the censoring distribution. #>  #> Link function: 'relative' yielding absolute risk ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) #> 230  \"1.015\"     #> 770  \"1.082\"     #> 1100 \"1.145\"     #> 1700 \"1.195\"     #> 3300 \"1.156\"     #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Covariates with time-constant effects: #>  #>  thick (numeric) #>  #> Time constant regression coefficients: #>  #>  Factor     Coef exp(Coef) StandardError        z         CI_95  Pvalue #>   thick 4.44e-05  1.00e+00      7.33e-06 6.05e+00 [1.000;1.000] < 1e-04 #>  #>  #> Note: The values exp(Coef) are absolute risk ratios  #>  #>  #> Note:The coeffient(s) for the following variable(s) #> thick are interpreted as per factor unit multiplied by time^power. fit.arr2b <- ARR(Hist(time,status)~timevar(thick),data=Melanoma,cause=1) summary(fit.arr2b) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> the Kaplan-Meier estimate for the censoring distribution. #>  #> Link function: 'relative' yielding absolute risk ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  thick (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) thick   #> 230  \"0.993\"     \"1.008\" #> 770  \"0.984\"     \"1.033\" #> 1100 \"1.022\"     \"1.042\" #> 1700 \"1.066\"     \"1.050\" #> 3300 \"1.241\"     \"1.043\" #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Time constant regression coefficients: #>  #> No covariates with time-constant coefficients specified.  ## logistic risk model fit.lrr <- LRR(Hist(time,status)~thick,data=Melanoma,cause=1) summary(fit.lrr) #>  #> riskRegression: Competing risks regression model  #>  #> IPCW estimation. The weights are based on #> the Kaplan-Meier estimate for the censoring distribution. #>  #> Link function: 'logistic' yielding odds ratios, see help(riskRegression). #>  #> Covariates with time-varying effects: #>  #>  Intercept (numeric) #>  #> The effects of these variables depend on time.The column 'Intercept' is the baseline risk where all the covariates have value zero #>  #>      (Intercept) #> 230  \"1.007\"     #> 770  \"1.050\"     #> 1100 \"1.098\"     #> 1700 \"1.158\"     #> 3300 \"1.347\"     #>  #> Shown are selected time points, use #>  #> plot.riskRegression #>  #> to investigate the full shape. #>  #>  #> Covariates with time-constant effects: #>  #>  thick (numeric) #>  #> Time constant regression coefficients: #>  #>  Factor   Coef exp(Coef) StandardError      z         CI_95  Pvalue #>   thick 0.1942    1.2143        0.0477 4.0690 [1.106;1.333] < 1e-04 #>  #>  #> Note: The values exp(Coef) are odds ratios       ## nearest neighbor non-parametric Aalen-Johansen estimate library(prodlim) fit.aj <- prodlim(Hist(time,status)~thick,data=Melanoma) plot(fit.aj,conf.int=FALSE)   # prediction performance x <- Score(list(fit.arr2a,fit.arr2b,fit.lrr),              data=Melanoma,              formula=Hist(time,status)~1,              cause=1,              split.method=\"none\")"},{"path":"/reference/riskRegression.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Global options for riskRegression — riskRegression.options","title":"Global options for riskRegression — riskRegression.options","text":"Output set global options riskRegression package.","code":""},{"path":"/reference/riskRegression.options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global options for riskRegression — riskRegression.options","text":"","code":"riskRegression.options(...)"},{"path":"/reference/riskRegression.options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global options for riskRegression — riskRegression.options","text":"... now limited method.predictRisk mehtod.predictRiskIID.","code":""},{"path":"/reference/riskRegression.options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Global options for riskRegression — riskRegression.options","text":"used ate function.","code":""},{"path":"/reference/riskRegression.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global options for riskRegression — riskRegression.options","text":"","code":"options <- riskRegression.options()  ## add new method.predictRiskIID riskRegression.options(method.predictRiskIID = c(options$method.predictRiskIID,\"xx\"))  riskRegression.options() #> $method.predictRisk #>  [1] \"predictRisk.ARR\"              \"predictRisk.BinaryTree\"       #>  [3] \"predictRisk.CauseSpecificCox\" \"predictRisk.Cforest\"          #>  [5] \"predictRisk.cox.aalen\"        \"predictRisk.coxph\"            #>  [7] \"predictRisk.coxph.penal\"      \"predictRisk.coxphTD\"          #>  [9] \"predictRisk.cph\"              \"predictRisk.CSCTD\"            #> [11] \"predictRisk.Ctree\"            \"predictRisk.default\"          #> [13] \"predictRisk.double\"           \"predictRisk.factor\"           #> [15] \"predictRisk.FGR\"              \"predictRisk.flexsurvreg\"      #> [17] \"predictRisk.formula\"          \"predictRisk.gbm\"              #> [19] \"predictRisk.glm\"              \"predictRisk.hal9001\"          #> [21] \"predictRisk.integer\"          \"predictRisk.lrm\"              #> [23] \"predictRisk.matrix\"           \"predictRisk.multinom\"         #> [25] \"predictRisk.numeric\"          \"predictRisk.penfitS3\"         #> [27] \"predictRisk.prodlim\"          \"predictRisk.psm\"              #> [29] \"predictRisk.randomForest\"     \"predictRisk.ranger\"           #> [31] \"predictRisk.rfsrc\"            \"predictRisk.riskRegression\"   #> [33] \"predictRisk.rpart\"            \"predictRisk.selectCox\"        #> [35] \"predictRisk.singleEventCB\"    \"predictRisk.SmcFcs\"           #> [37] \"predictRisk.SuperPredictor\"   \"predictRisk.survfit\"          #> [39] \"predictRisk.wglm\"             \"predictRisk.aalen\"            #>  #> $method.predictRiskIID #> [1] \"predictRiskIID.CauseSpecificCox\" \"predictRiskIID.coxph\"            #> [3] \"predictRiskIID.cph\"              \"predictRiskIID.default\"          #> [5] \"predictRiskIID.glm\"              \"predictRiskIID.phreg\"            #> [7] \"predictRiskIID.wglm\"             \"predictRiskIID.multinom\"         #> [9] \"xx\"                              #>"},{"path":"/reference/rowCenter_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply - by row — rowCenter_cpp","title":"Apply - by row — rowCenter_cpp","text":"Fast computation sweep(X, MARGIN = 2, FUN = \"-\", STATS = center)","code":""},{"path":"/reference/rowCenter_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply - by row — rowCenter_cpp","text":"","code":"rowCenter_cpp(X, center)"},{"path":"/reference/rowCenter_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply - by row — rowCenter_cpp","text":"X matrix. center numeric vector length equal number rows x","code":""},{"path":"/reference/rowCenter_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply - by row — rowCenter_cpp","text":"matrix size X.","code":""},{"path":"/reference/rowCenter_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply - by row — rowCenter_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/rowCenter_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply - by row — rowCenter_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 2, FUN = \"-\", STATS = 1:5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0   -1   -2   -3   -4 #> [2,]    0   -1   -2   -3   -4 #> [3,]    0   -1   -2   -3   -4 #> [4,]    0   -1   -2   -3   -4 #> [5,]    0   -1   -2   -3   -4 #> [6,]    0   -1   -2   -3   -4 rowCenter_cpp(x, 1:5 ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0   -1   -2   -3   -4 #> [2,]    0   -1   -2   -3   -4 #> [3,]    0   -1   -2   -3   -4 #> [4,]    0   -1   -2   -3   -4 #> [5,]    0   -1   -2   -3   -4 #> [6,]    0   -1   -2   -3   -4  rowCenter_cpp(x, colMeans(x) ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    0    0    0    0 #> [2,]    0    0    0    0    0 #> [3,]    0    0    0    0    0 #> [4,]    0    0    0    0    0 #> [5,]    0    0    0    0    0 #> [6,]    0    0    0    0    0"},{"path":"/reference/rowCumProd.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply cumprod in each row — rowCumProd","title":"Apply cumprod in each row — rowCumProd","text":"Fast computation t(apply(x,1,cumprod))","code":""},{"path":"/reference/rowCumProd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply cumprod in each row — rowCumProd","text":"","code":"rowCumProd(x)"},{"path":"/reference/rowCumProd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply cumprod in each row — rowCumProd","text":"x matrix.","code":""},{"path":"/reference/rowCumProd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply cumprod in each row — rowCumProd","text":"matrix size x.","code":""},{"path":"/reference/rowCumProd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply cumprod in each row — rowCumProd","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/rowCumProd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply cumprod in each row — rowCumProd","text":"","code":"x <- matrix(1:8,ncol=2) rowCumProd(x) #>      [,1] [,2] #> [1,]    1    5 #> [2,]    2   12 #> [3,]    3   21 #> [4,]    4   32"},{"path":"/reference/rowCumSum.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply cumsum in each row — rowCumSum","title":"Apply cumsum in each row — rowCumSum","text":"Fast computation t(apply(x,1,cumsum))","code":""},{"path":"/reference/rowCumSum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply cumsum in each row — rowCumSum","text":"","code":"rowCumSum(x)"},{"path":"/reference/rowCumSum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply cumsum in each row — rowCumSum","text":"x matrix.","code":""},{"path":"/reference/rowCumSum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply cumsum in each row — rowCumSum","text":"matrix size x.","code":""},{"path":"/reference/rowCumSum.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply cumsum in each row — rowCumSum","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/rowCumSum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply cumsum in each row — rowCumSum","text":"","code":"x <- matrix(1:8,ncol=2) rowCumSum(x) #>      [,1] [,2] #> [1,]    1    6 #> [2,]    2    8 #> [3,]    3   10 #> [4,]    4   12"},{"path":"/reference/rowMultiply_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply * by row — rowMultiply_cpp","title":"Apply * by row — rowMultiply_cpp","text":"Fast computation sweep(X, MARGIN = 2, FUN = \"*\", STATS = scale)","code":""},{"path":"/reference/rowMultiply_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply * by row — rowMultiply_cpp","text":"","code":"rowMultiply_cpp(X, scale)"},{"path":"/reference/rowMultiply_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply * by row — rowMultiply_cpp","text":"X matrix. scale numeric vector length equal number rows x","code":""},{"path":"/reference/rowMultiply_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply * by row — rowMultiply_cpp","text":"matrix size X.","code":""},{"path":"/reference/rowMultiply_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply * by row — rowMultiply_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/rowMultiply_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply * by row — rowMultiply_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 2, FUN = \"*\", STATS = 1:5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    2    3    4    5 #> [2,]    1    2    3    4    5 #> [3,]    1    2    3    4    5 #> [4,]    1    2    3    4    5 #> [5,]    1    2    3    4    5 #> [6,]    1    2    3    4    5 rowMultiply_cpp(x, 1:5 ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    2    3    4    5 #> [2,]    1    2    3    4    5 #> [3,]    1    2    3    4    5 #> [4,]    1    2    3    4    5 #> [5,]    1    2    3    4    5 #> [6,]    1    2    3    4    5  rowMultiply_cpp(x, 1/colMeans(x) ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    1    1    1    1 #> [2,]    1    1    1    1    1 #> [3,]    1    1    1    1    1 #> [4,]    1    1    1    1    1 #> [5,]    1    1    1    1    1 #> [6,]    1    1    1    1    1"},{"path":"/reference/rowPaste.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse Rows of Characters. — rowPaste","title":"Collapse Rows of Characters. — rowPaste","text":"Collapse rows characters. Fast alternative apply(x,1,paste0,collapse=\"\")","code":""},{"path":"/reference/rowPaste.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse Rows of Characters. — rowPaste","text":"","code":"rowPaste(object)"},{"path":"/reference/rowPaste.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse Rows of Characters. — rowPaste","text":"object matrix/data.frame/list containing characters.","code":""},{"path":"/reference/rowPaste.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse Rows of Characters. — rowPaste","text":"","code":"if (FALSE) { M <- matrix(letters,nrow = 26, ncol = 2) rowPaste(M) }"},{"path":"/reference/rowScale_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply / by row — rowScale_cpp","title":"Apply / by row — rowScale_cpp","text":"Fast computation sweep(X, MARGIN = 2, FUN = \"/\", STATS = scale)","code":""},{"path":"/reference/rowScale_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply / by row — rowScale_cpp","text":"","code":"rowScale_cpp(X, scale)"},{"path":"/reference/rowScale_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply / by row — rowScale_cpp","text":"X matrix. scale numeric vector length equal number rows x","code":""},{"path":"/reference/rowScale_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply / by row — rowScale_cpp","text":"matrix size X.","code":""},{"path":"/reference/rowScale_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply / by row — rowScale_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/rowScale_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply / by row — rowScale_cpp","text":"","code":"x <- matrix(1,6,5) sweep(x, MARGIN = 2, FUN = \"/\", STATS = 1:5) #>      [,1] [,2]      [,3] [,4] [,5] #> [1,]    1  0.5 0.3333333 0.25  0.2 #> [2,]    1  0.5 0.3333333 0.25  0.2 #> [3,]    1  0.5 0.3333333 0.25  0.2 #> [4,]    1  0.5 0.3333333 0.25  0.2 #> [5,]    1  0.5 0.3333333 0.25  0.2 #> [6,]    1  0.5 0.3333333 0.25  0.2 rowScale_cpp(x, 1:5 ) #>      [,1] [,2]      [,3] [,4] [,5] #> [1,]    1  0.5 0.3333333 0.25  0.2 #> [2,]    1  0.5 0.3333333 0.25  0.2 #> [3,]    1  0.5 0.3333333 0.25  0.2 #> [4,]    1  0.5 0.3333333 0.25  0.2 #> [5,]    1  0.5 0.3333333 0.25  0.2 #> [6,]    1  0.5 0.3333333 0.25  0.2  rowScale_cpp(x, colMeans(x) ) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    1    1    1    1 #> [2,]    1    1    1    1    1 #> [3,]    1    1    1    1    1 #> [4,]    1    1    1    1    1 #> [5,]    1    1    1    1    1 #> [6,]    1    1    1    1    1"},{"path":"/reference/rowSumsCrossprod.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply crossprod and rowSums — rowSumsCrossprod","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"Fast computation crossprod(rowSums(X),Y)","code":""},{"path":"/reference/rowSumsCrossprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"","code":"rowSumsCrossprod(X, Y, transposeY)"},{"path":"/reference/rowSumsCrossprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"X matrix dimensions n*k. Hence result rowSums(X) length n. Y matrix dimenions n*m. Can matrix dimension m*n transposeY TRUE. transposeY Logical. TRUE transpose Y matrix multiplication.","code":""},{"path":"/reference/rowSumsCrossprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"vector length m.","code":""},{"path":"/reference/rowSumsCrossprod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"Thomas Alexander Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/rowSumsCrossprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply crossprod and rowSums — rowSumsCrossprod","text":"","code":"x <- matrix(1:10,nrow=5) y <- matrix(1:20,ncol=4) rowSumsCrossprod(x,y,0) #>      [,1] [,2] [,3] [,4] #> [1,]  185  460  735 1010  x <- matrix(1:10,nrow=5) y <- matrix(1:20,ncol=5) rowSumsCrossprod(x,y,1) #>      [,1] [,2] [,3] [,4] #> [1,]  575  630  685  740"},{"path":"/reference/sampleData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data with binary or time-to-event outcome — sampleData","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"Simulate data binary outcome 10 covariates.","code":""},{"path":"/reference/sampleData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"","code":"sampleData(n,outcome=\"competing.risks\", formula= ~ f(X1,2)+f(X2,-0.033)+f(X3,0.4)+f(X6,.1)+f(X7,-.1)+f(X8,.5)+f(X9,-1),           intercept=0) sampleDataTD(n,n.intervals=5,outcome=\"competing.risks\", formula= ~ f(X1,2)+f(X2,-0.033)+f(X3,0.4)+f(X6,.1)+f(X7,-.1)+f(X8,.5)+f(X9,-1))"},{"path":"/reference/sampleData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"n Sample size outcome Character vector. Response variables generated according keywords: \"binary\" = binary response, \"survival\" = survival response, \"competing.risks\" = competing risks response formula Specify regression coefficients intercept binary outcome intercept logistic regression. n.intervals sampleDataTD : maximum number episodes covariates updated.","code":""},{"path":"/reference/sampleData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"Simulated data data.table n rows following columns: Y (binary outcome), time (non-binary outcome), event (non-binary outcome), X1-X5 (binary predictors), X6-X10 (continous predictors)","code":""},{"path":"/reference/sampleData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"actual lava::regression parameters see function definition.","code":""},{"path":[]},{"path":"/reference/sampleData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/sampleData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data with binary or time-to-event outcome — sampleData","text":"","code":"sampleData(10,outcome=\"binary\") #>           X6       X7          X8         X9        X10 X1 X2 X3 X4 X5 Y #>  1: 46.82367 67.24533  0.76601117  1.3039815 -1.5953831  0  0  1  0  0 0 #>  2: 77.69055 61.02286 -1.25070514 -0.2387592 -0.3046539  1  0  0  1  0 1 #>  3: 47.43607 68.04548 -1.93934626  0.6812340  0.4854172  0  0  1  0  1 0 #>  4: 45.74745 69.19576 -2.08930856  1.5028794 -1.2190607  0  0  1  1  0 0 #>  5: 47.23630 67.74454  0.41779689  0.4520591  1.3879925  0  1  1  1  1 0 #>  6: 83.33275 63.70914  0.44404509 -0.1358663 -1.4756768  0  0  1  0  0 1 #>  7: 39.19116 63.04737 -0.14412019  0.7608121 -0.2618844  0  1  0  0  1 0 #>  8: 67.81334 64.13697  0.09318769 -0.7907372  0.1239023  0  1  0  1  1 1 #>  9: 66.32582 57.58020  0.71205220  1.5738184 -1.3145448  0  1  0  0  1 0 #> 10: 65.49821 58.47139 -1.44213677  1.8802128 -0.0988130  0  0  1  1  1 0 sampleData(10,outcome=\"survival\") #>            X6       X7         X8         X9        X10 X1 X2 X3 X4 X5 #>  1: 105.34595 58.19687 -2.3673196  1.1758264 -0.2662620  0  0  0  1  1 #>  2:  90.71622 50.04183  0.7468906  0.1840539  0.9415957  0  1  0  0  1 #>  3:  59.69159 60.70045 -1.3214394  0.8982531  0.6179547  0  0  0  0  1 #>  4:  26.55609 55.80982 -0.1839103 -0.4361993  0.2406645  0  0  0  0  0 #>  5:  44.86785 64.13566  0.3702102  0.9412698 -0.2811275  0  0  1  1  1 #>  6:  70.93943 59.31365  0.4427237 -1.4587915 -0.1273632  0  0  1  1  0 #>  7:  44.41888 60.26168  0.3243719  1.6640414  1.4109850  0  1  0  0  0 #>  8:  69.23317 59.13929 -0.2946856 -0.1398363  2.1002374  0  1  0  0  0 #>  9:  78.25618 62.90142 -1.0414508  0.7459810 -0.1347690  0  0  0  0  1 #> 10:  62.46170 67.39584 -1.8278110  0.2303515 -1.7317539  0  0  1  0  0 #>      eventtime  censtime       time event #>  1:  2.1584938 12.291536  2.1584938     1 #>  2:  0.7952726  7.687468  0.7952726     1 #>  3:  9.6945964 13.932777  9.6945964     1 #>  4: 48.0137416  7.058650  7.0586503     0 #>  5: 55.3383918 11.390308 11.3903079     0 #>  6:  2.2579616 15.292583  2.2579616     1 #>  7: 23.5150791  9.408254  9.4082539     0 #>  8:  2.3798579  7.207902  2.3798579     1 #>  9: 12.2951520  2.611471  2.6114709     0 #> 10: 12.1308164 16.270998 12.1308164     1 sampleData(10,outcome=\"competing.risks\") #>           X6       X7          X8          X9        X10 X1 X2 X3 X4 X5 #>  1: 70.95693 69.90523 -0.11716037 -1.60872843 -0.8276721  0  0  0  0  1 #>  2: 48.44728 60.88304 -0.92216042  0.75254134 -0.6963852  0  0  0  1  1 #>  3: 45.47900 60.71565  0.30189182 -0.93065381  1.9186075  0  1  0  0  1 #>  4: 64.37623 63.43177  1.35253949 -0.41297456 -0.7568721  1  0  0  0  1 #>  5: 76.89589 54.65964  0.93818152 -0.58867640  1.4836873  0  1  0  1  0 #>  6: 36.21012 58.08425  0.27056390 -0.72435849 -0.1764810  0  1  0  1  0 #>  7: 55.36911 63.40905  1.27362824 -0.35314014  1.5612745  0  0  0  0  1 #>  8: 52.17097 65.28943 -1.16935075 -0.72582011 -1.4857048  0  0  0  0  0 #>  9: 68.56586 61.42335  0.08619538 -0.02632572 -0.5342470  0  0  0  0  0 #> 10: 59.30486 57.85724 -0.58657058 -0.15254579 -0.2432629  0  0  1  0  0 #>     eventtime1 eventtime2  censtime       time event #>  1:  5.0641127  15.504000  6.941363  5.0641127     1 #>  2: 61.5754692  12.371662 13.492984 12.3716622     2 #>  3: 18.1930468  12.201308 14.666782 12.2013077     2 #>  4:  0.8187567   6.553765  9.042609  0.8187567     1 #>  5:  1.8570417   9.563060  4.970838  1.8570417     1 #>  6: 14.1247074   4.960097 10.476599  4.9600967     2 #>  7:  6.8519327   9.906128  8.926625  6.8519327     1 #>  8:  4.2771898   6.811277  8.223740  4.2771898     1 #>  9:  3.6496208   5.146281  3.941413  3.6496208     1 #> 10:  9.0028432   4.160078  9.114821  4.1600785     2"},{"path":"/reference/score.wglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Score for IPCW Logistic Regressions — score.wglm","title":"Score for IPCW Logistic Regressions — score.wglm","text":"Compute first derivative log-likelihood IPCW logistic regressions.","code":""},{"path":"/reference/score.wglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Score for IPCW Logistic Regressions — score.wglm","text":"","code":"# S3 method for wglm score(x, indiv = FALSE, times = NULL, simplifies = TRUE, ...)"},{"path":"/reference/score.wglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Score for IPCW Logistic Regressions — score.wglm","text":"x wglm object. indiv [logical] individual score output? Otherwise total score (.e. summed individuals output). times [numeric vector] time points score output. simplifies [logical] ouput converted matrix one timepoint requested. Otherwise always return list. ... used.","code":""},{"path":"/reference/selectCox.html","id":null,"dir":"Reference","previous_headings":"","what":"Backward variable selection in the Cox regression model — selectCox","title":"Backward variable selection in the Cox regression model — selectCox","text":"wrapper function first selects variables Cox regression model using fastbw rms package returns fitted Cox regression model selected variables.","code":""},{"path":"/reference/selectCox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Backward variable selection in the Cox regression model — selectCox","text":"","code":"selectCox(formula, data, rule = \"aic\")"},{"path":"/reference/selectCox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Backward variable selection in the Cox regression model — selectCox","text":"formula formula object Surv object left-hand side variables right-hand side. data Name data frame containing needed variables. rule method selecting variables. See fastbw details.","code":""},{"path":"/reference/selectCox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Backward variable selection in the Cox regression model — selectCox","text":"function first calls cph fastbw finally cph .","code":""},{"path":"/reference/selectCox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Backward variable selection in the Cox regression model — selectCox","text":"Ulla B. Mogensen, Hemant Ishwaran, Thomas . Gerds (2012). Evaluating Random Forests Survival Analysis Using Prediction Error Curves. Journal Statistical Software, 50(11), 1-23. URL http://www.jstatsoft.org/v50/i11/.","code":""},{"path":"/reference/selectCox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Backward variable selection in the Cox regression model — selectCox","text":"","code":"library(pec) #>  #> Attaching package: ‘pec’ #> The following objects are masked from ‘package:riskRegression’: #>  #>     ipcw, selectCox library(prodlim) data(GBSG2) library(survival) f <- selectCox(Surv(time,cens)~horTh+age+menostat+tsize+tgrade+pnodes+progrec+estrec ,          data=GBSG2)"},{"path":"/reference/selectJump.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the influence function at selected times — selectJump","title":"Evaluate the influence function at selected times — selectJump","text":"Evaluate influence function selected times","code":""},{"path":"/reference/selectJump.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the influence function at selected times — selectJump","text":"","code":"selectJump(IF, times, type)"},{"path":"/reference/selectJump.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the influence function at selected times — selectJump","text":"influence function returned iidCox times times influence function assessed type can \"hazard\" /\"cumhazard\".","code":""},{"path":"/reference/selectJump.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the influence function at selected times — selectJump","text":"object dimensions ","code":""},{"path":"/reference/selectJump.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate the influence function at selected times — selectJump","text":"Brice Ozenne broz@sund.ku.dk","code":""},{"path":"/reference/simActiveSurveillance.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"Simulate data hypothetical active surveillance prostate cancer study","code":""},{"path":"/reference/simActiveSurveillance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"","code":"simActiveSurveillance(n)"},{"path":"/reference/simActiveSurveillance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"n sample size","code":""},{"path":"/reference/simActiveSurveillance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"data table size n","code":""},{"path":"/reference/simActiveSurveillance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"based functionality library(lava).","code":""},{"path":"/reference/simActiveSurveillance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/simActiveSurveillance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data of a hypothetical active surveillance prostate cancer study — simActiveSurveillance","text":"","code":"set.seed(71) simActiveSurveillance(3) #>         age   lpsaden     ppb5     lmax ct1 diaggs erg.status     time event #> 1: 68.04504 -3.504668 2.024705 1.077346 cT1    3/3        neg 4.047567     0 #> 2: 68.45207 -3.696001 5.321986 4.231017 cT1    3/3        pos 1.603210     1 #> 3: 70.81464 -3.082855 3.428400 2.042447 cT1    GNA        neg 5.566821     0"},{"path":"/reference/simMelanoma.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data alike the Melanoma data — simMelanoma","title":"Simulate data alike the Melanoma data — simMelanoma","text":"Simulate data alike Melanoma data","code":""},{"path":"/reference/simMelanoma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data alike the Melanoma data — simMelanoma","text":"","code":"simMelanoma(n)"},{"path":"/reference/simMelanoma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data alike the Melanoma data — simMelanoma","text":"n sample size","code":""},{"path":"/reference/simMelanoma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data alike the Melanoma data — simMelanoma","text":"data table size n","code":""},{"path":"/reference/simMelanoma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate data alike the Melanoma data — simMelanoma","text":"based functionality library(lava).","code":""},{"path":"/reference/simMelanoma.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate data alike the Melanoma data — simMelanoma","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/simMelanoma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data alike the Melanoma data — simMelanoma","text":"","code":"set.seed(71) simMelanoma(3) #>          ulcer      epicel  sex      age  logthick     thick       time status #> 1: not present     present Male 67.63431 -1.384208 0.2505222 3076.04823      0 #> 2:     present not present Male 57.92951  1.446500 4.2482183 2179.31190      1 #> 3:     present     present Male 60.48275  2.287579 9.8510608   25.85244      1 #>    ici #> 1:   0 #> 2:   0 #> 3:   3"},{"path":"/reference/sliceMultiply_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply * by slice — sliceMultiply_cpp","title":"Apply * by slice — sliceMultiply_cpp","text":"Fast computation sweep(X, MARGIN = 1:2, FUN = \"*\", STATS = scale)","code":""},{"path":"/reference/sliceMultiply_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply * by slice — sliceMultiply_cpp","text":"","code":"sliceMultiply_cpp(X, M)  sliceMultiplyPointer_cpp(X, M)"},{"path":"/reference/sliceMultiply_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply * by slice — sliceMultiply_cpp","text":"X array. M matrix number row columns X.","code":""},{"path":"/reference/sliceMultiply_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply * by slice — sliceMultiply_cpp","text":"array size X.","code":""},{"path":"/reference/sliceMultiply_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply * by slice — sliceMultiply_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/sliceMultiply_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply * by slice — sliceMultiply_cpp","text":"","code":"x <- array(1, dim = c(2,6,5)) M <- matrix(1:12,2,6) sweep(x, MARGIN = 1:2, FUN = \"*\", STATS = M) #> , , 1 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 2 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 3 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 4 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 5 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  sliceMultiply_cpp(x, M)  #> , , 1 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 2 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 3 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 4 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>  #> , , 5 #>  #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    7    9   11 #> [2,]    2    4    6    8   10   12 #>"},{"path":"/reference/sliceScale_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply / by slice — sliceScale_cpp","title":"Apply / by slice — sliceScale_cpp","text":"Fast computation sweep(X, MARGIN = 1:2, FUN = \"/\", STATS = scale)","code":""},{"path":"/reference/sliceScale_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply / by slice — sliceScale_cpp","text":"","code":"sliceScale_cpp(X, M)  sliceScalePointer_cpp(X, M)"},{"path":"/reference/sliceScale_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply / by slice — sliceScale_cpp","text":"X array. M matrix number row columns X.","code":""},{"path":"/reference/sliceScale_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply / by slice — sliceScale_cpp","text":"array size X.","code":""},{"path":"/reference/sliceScale_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply / by slice — sliceScale_cpp","text":"Brice Ozenne <broz@sund.ku.dk>","code":""},{"path":"/reference/sliceScale_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply / by slice — sliceScale_cpp","text":"","code":"x <- array(1, dim = c(2,6,5)) M <- matrix(1:12,2,6) sweep(x, MARGIN = 1:2, FUN = \"/\", STATS = M) #> , , 1 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 2 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 3 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 4 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 5 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  sliceScale_cpp(x, M)  #> , , 1 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 2 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 3 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 4 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>  #> , , 5 #>  #>      [,1]      [,2]      [,3]      [,4]      [,5]       [,6] #> [1,]  1.0 0.3333333 0.2000000 0.1428571 0.1111111 0.09090909 #> [2,]  0.5 0.2500000 0.1666667 0.1250000 0.1000000 0.08333333 #>"},{"path":"/reference/splitStrataVar.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconstruct each of the strata variables — splitStrataVar","title":"Reconstruct each of the strata variables — splitStrataVar","text":"Reconstruct strata variables strata variable stored coxph object.","code":""},{"path":"/reference/splitStrataVar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconstruct each of the strata variables — splitStrataVar","text":"","code":"splitStrataVar(object)"},{"path":"/reference/splitStrataVar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconstruct each of the strata variables — splitStrataVar","text":"object coxph object.","code":""},{"path":"/reference/splitStrataVar.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reconstruct each of the strata variables — splitStrataVar","text":"Brice Ozenne broz@sund.ku.dk Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/subjectWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of censoring probabilities at subject specific times — subjectWeights","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"function used internally contruct pseudo values inverse probability censoring weights.","code":""},{"path":"/reference/subjectWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"","code":"subjectWeights(   formula,   data,   method = c(\"cox\", \"marginal\", \"km\", \"nonpar\", \"forest\", \"none\"),   args,   lag = 1 )"},{"path":"/reference/subjectWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"formula survival formula like, Surv(time,status)~1 Hist(time,status)~1 status=0 means censored. status variable internally reversed estimation censoring rather survival probabilities. available models, see argument model, use predictors right hand side formula. data data used fitting censoring model method Censoring model used estimation (conditional) censoring distribution. args Arguments passed fitter method. lag equal 1 obtain G(T_i-|X_i), equal 0 estimate conditional censoring distribution subject.times, .e. (G(T_i|X_i)).","code":""},{"path":"/reference/subjectWeights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"times times weights estimated weights Estimated weights individual time values subject.times lag time lag. fit fitted censoring model method method modelling censoring distribution call call","code":""},{"path":"/reference/subjectWeights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"Inverse probability censoring weights usually refer probabilities censored certain time points. probabilities also values conditional survival function censoring time given covariates. function subjectWeights estimates conditional survival function censoring times derives weights. IMPORTANT: data set ordered, order(time,-status) order get weights right order choices method.","code":""},{"path":"/reference/subjectWeights.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"Thomas . Gerds tag@biostat.ku.dk","code":""},{"path":"/reference/subjectWeights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of censoring probabilities at subject specific times — subjectWeights","text":"","code":"library(prodlim) library(survival) dat=SimSurv(300)  dat <- dat[order(dat$time,-dat$status),]  # using the marginal Kaplan-Meier for the censoring times  WKM=subjectWeights(Hist(time,status)~X2,data=dat,method=\"marginal\") plot(WKM$fit)  WKM$fit #>  #> Call: prodlim::prodlim(formula = formula, data = data, reverse = TRUE) #>  #> Kaplan-Meier estimator for the censoring time survival function #>  #> No covariates #>  #> Right-censored response of a survival model #>  #> No.Observations: 300  #>  #> Pattern: #>                 Freq #>  event          172  #>  right.censored 128  WKM$weights #>   [1] 1.00000000 1.00000000 1.00000000 1.00000000 0.99663300 0.99663300 #>   [7] 0.99663300 0.99663300 0.99663300 0.99321987 0.99321987 0.98979497 #>  [13] 0.98979497 0.98635819 0.98292140 0.97948461 0.97604782 0.97604782 #>  [19] 0.97604782 0.97604782 0.97604782 0.97604782 0.97604782 0.97604782 #>  [25] 0.97604782 0.97604782 0.97604782 0.97604782 0.97247255 0.96889729 #>  [31] 0.96889729 0.96889729 0.96889729 0.96889729 0.96889729 0.96525482 #>  [37] 0.96161235 0.96161235 0.95795603 0.95795603 0.95795603 0.95427158 #>  [43] 0.95058713 0.95058713 0.95058713 0.95058713 0.95058713 0.95058713 #>  [49] 0.95058713 0.95058713 0.95058713 0.95058713 0.95058713 0.95058713 #>  [55] 0.94673860 0.94673860 0.94673860 0.94673860 0.94673860 0.94673860 #>  [61] 0.94673860 0.94673860 0.94277735 0.94277735 0.93879939 0.93879939 #>  [67] 0.93480450 0.93480450 0.93480450 0.93077517 0.93077517 0.92672832 #>  [73] 0.92268147 0.92268147 0.92268147 0.92268147 0.92268147 0.92268147 #>  [79] 0.92268147 0.92268147 0.91850644 0.91850644 0.91850644 0.91850644 #>  [85] 0.91850644 0.91850644 0.91850644 0.91421436 0.91421436 0.91421436 #>  [91] 0.91421436 0.90986095 0.90550755 0.90550755 0.90550755 0.90550755 #>  [97] 0.90550755 0.90106879 0.90106879 0.90106879 0.90106879 0.89656345 #> [103] 0.89656345 0.89656345 0.89656345 0.89656345 0.89196568 0.89196568 #> [109] 0.88734410 0.88734410 0.88734410 0.88734410 0.88734410 0.88734410 #> [115] 0.88259895 0.88259895 0.88259895 0.87780221 0.87780221 0.87780221 #> [121] 0.87780221 0.87780221 0.87780221 0.87287074 0.87287074 0.86791125 #> [127] 0.86295175 0.85799226 0.85303277 0.85303277 0.85303277 0.85303277 #> [133] 0.85303277 0.85303277 0.84792479 0.84281681 0.84281681 0.84281681 #> [139] 0.84281681 0.84281681 0.84281681 0.84281681 0.83751607 0.83751607 #> [145] 0.83218157 0.83218157 0.83218157 0.83218157 0.82674248 0.82674248 #> [151] 0.82126736 0.81579225 0.81579225 0.81028014 0.81028014 0.80473027 #> [157] 0.80473027 0.80473027 0.80473027 0.80473027 0.80473027 0.80473027 #> [163] 0.80473027 0.80473027 0.79885633 0.79885633 0.79885633 0.79885633 #> [169] 0.79284989 0.78684345 0.78684345 0.78079081 0.77473817 0.76868553 #> [175] 0.76263288 0.75658024 0.75052760 0.74447496 0.74447496 0.73837271 #> [181] 0.73227045 0.72616820 0.72006594 0.71396369 0.71396369 0.70780883 #> [187] 0.70165397 0.70165397 0.70165397 0.70165397 0.69533276 0.68901156 #> [193] 0.68901156 0.68901156 0.68257220 0.68257220 0.67607151 0.67607151 #> [199] 0.66950771 0.66950771 0.66287892 0.66287892 0.65618317 0.64948743 #> [205] 0.64279168 0.64279168 0.64279168 0.64279168 0.64279168 0.63580481 #> [211] 0.62881795 0.62881795 0.62175258 0.61468721 0.60762184 0.60762184 #> [217] 0.60047334 0.59332485 0.58617636 0.57902787 0.57902787 0.57902787 #> [223] 0.57902787 0.57160443 0.56418100 0.55675757 0.54933413 0.54191070 #> [229] 0.53448726 0.53448726 0.52695927 0.51943128 0.51943128 0.51179259 #> [235] 0.50415389 0.50415389 0.49639768 0.48864147 0.48088525 0.47312904 #> [241] 0.46537282 0.46537282 0.45748515 0.45748515 0.44945909 0.44143304 #> [247] 0.43340698 0.43340698 0.43340698 0.42507223 0.41673748 0.41673748 #> [253] 0.40823264 0.40823264 0.40823264 0.40823264 0.39916080 0.39008896 #> [259] 0.39008896 0.39008896 0.38057460 0.38057460 0.38057460 0.37055948 #> [265] 0.36054436 0.35052924 0.35052924 0.35052924 0.35052924 0.33957520 #> [271] 0.32862116 0.32862116 0.31728940 0.31728940 0.31728940 0.31728940 #> [277] 0.30459782 0.30459782 0.29135444 0.27811105 0.26486767 0.25162429 #> [283] 0.25162429 0.23764516 0.23764516 0.22279234 0.22279234 0.22279234 #> [289] 0.20565446 0.20565446 0.18695860 0.16826274 0.16826274 0.14722990 #> [295] 0.12619706 0.10516421 0.10516421 0.07887316 0.05258211 0.02629105  # using the Cox model for the censoring times given X2  WCox=subjectWeights(Surv(time,status)~X2,data=dat,method=\"cox\") WCox #>  #> Estimated inverse of the probability of censoring weights (subjectWeights) #>  #> Method for estimation:  Cox regression  #> Handler function:  function (formula = formula(data), data = environment(formula), weights, subset, na.action = na.delete, method = c(\"efron\", \"breslow\", \"exact\", \"model.frame\", \"model.matrix\"), singular.ok = FALSE, robust = FALSE, model = FALSE, x = FALSE, y = FALSE, se.fit = FALSE, linear.predictors = TRUE, residuals = TRUE, nonames = FALSE, eps = 1e-04, init, iter.max = 10, tol = 1e-09, surv = FALSE, time.inc, type = NULL, vartype = NULL, debug = FALSE, ...)  #> { #>     method <- match.arg(method) #>     call <- match.call() #>     if (!inherits(formula, \"formula\")) { #>         if (inherits(formula, \"Surv\")) { #>             xx <- function(x) formula(x) #>             formula <- xx(paste(deparse(substitute(formula)), 1, sep = \"~\")) #>         } #>         else stop(\"Invalid formula\") #>     } #>     callenv <- parent.frame() #>     weights <- if (!missing(weights))  #>         eval(substitute(weights), data, callenv) #>     subset <- if (!missing(subset))  #>         eval(substitute(subset), data, callenv) #>     data <- modelData(data, formula, weights = weights, subset = subset, na.action = na.action, dotexpand = FALSE, callenv = callenv) #>     nstrata <- 0 #>     Strata <- NULL #>     odb <- .Options$debug #>     if (length(odb) && is.logical(odb) && odb)  #>         debug <- TRUE #>     if (length(z <- attr(terms(formula, allowDotAsName = TRUE), \"term.labels\")) > 0 && any(z != \".\")) { #>         X <- Design(data, formula, specials = c(\"strat\", \"strata\")) #>         atrx <- attributes(X) #>         atr <- atrx$Design #>         nact <- atrx$na.action #>         sformula <- atrx$sformula #>         mmcolnames <- atr$mmcolnames #>         if (method == \"model.frame\")  #>             return(X) #>         Terms <- terms(sformula, specials = c(\"strat\", \"strata\"), data = data) #>         asm <- atr$assume.code #>         name <- atr$name #>         specials <- attr(Terms, \"specials\") #>         if (length(specials$strata))  #>             stop(\"cph supports strat(), not strata()\") #>         stra <- specials$strat #>         cluster <- attr(X, \"cluster\") #>         if (length(cluster)) { #>             if (missing(robust))  #>                 robust <- TRUE #>             attr(X, \"cluster\") <- NULL #>         } #>         Terms.ns <- Terms #>         if (length(stra)) { #>             temp <- untangle.specials(Terms.ns, \"strat\", 1) #>             Terms.ns <- Terms.ns[-temp$terms] #>             Strata <- list() #>             strataname <- attr(Terms, \"term.labels\")[stra - 1] #>             j <- 0 #>             for (i in (1:length(asm))[asm == 8]) { #>                 nstrata <- nstrata + 1 #>                 xi <- X[[i + 1]] #>                 levels(xi) <- paste(name[i], \"=\", levels(xi), sep = \"\") #>                 Strata[[nstrata]] <- xi #>             } #>             Strata <- interaction(as.data.frame(Strata), drop = TRUE) #>         } #>         xpres <- length(asm) && any(asm != 8) #>         Y <- model.extract(X, \"response\") #>         if (!inherits(Y, \"Surv\"))  #>             stop(\"response variable should be a Surv object\") #>         n <- nrow(Y) #>         weights <- model.extract(X, \"weights\") #>         offset <- attr(X, \"offset\") #>         if (!xpres) { #>             X <- matrix(nrow = 0, ncol = 0) #>             assign <- NULL #>         } #>         else { #>             X <- model.matrix(sformula, X) #>             alt <- attr(mmcolnames, \"alt\") #>             if (debug) { #>                 print(cbind(`colnames(X)` = colnames(X)[-1], mmcolnames = mmcolnames, `Design colnames` = atr$colnames, alt = alt)) #>             } #>             if (!all(mmcolnames %in% colnames(X)) && length(alt))  #>                 mmcolnames <- alt #>             X <- X[, mmcolnames, drop = FALSE] #>             assign <- attr(X, \"assign\") #>             assign[[1]] <- NULL #>         } #>         nullmod <- FALSE #>     } #>     else { #>         X <- NULL #>         Y <- data[[1]] #>         sformula <- formula #>         mmcolnames <- \"\" #>         weights <- if (\"(weights)\" %in% names(data))  #>             data[[\"(weights)\"]] #>         atr <- atrx <- NULL #>         Terms <- terms(formula, allowDotAsName = TRUE) #>         if (!inherits(Y, \"Surv\"))  #>             stop(\"response variable should be a Surv object\") #>         Y <- Y[!is.na(Y)] #>         assign <- NULL #>         xpres <- FALSE #>         nullmod <- TRUE #>         nact <- NULL #>     } #>     ny <- ncol(Y) #>     maxtime <- max(Y[, ny - 1]) #>     rnam <- if (!nonames)  #>         dimnames(Y)[[1]] #>     if (xpres)  #>         dimnames(X) <- list(rnam, atr$colnames) #>     if (method == \"model.matrix\")  #>         return(X) #>     time.units <- units(Y) #>     if (!length(time.units) || time.units == \"\")  #>         time.units <- \"Day\" #>     if (missing(time.inc)) { #>         time.inc <- switch(time.units, Day = 30, Month = 1, Year = 1, maxtime/10) #>         if (time.inc >= maxtime | maxtime/time.inc > 25)  #>             time.inc <- max(pretty(c(0, maxtime)))/10 #>     } #>     ytype <- attr(Y, \"type\") #>     if (nullmod)  #>         f <- NULL #>     else { #>         fitter <- if (method == \"breslow\" || method == \"efron\") { #>             if (ytype == \"right\")  #>                 coxph.fit #>             else agreg.fit #>         } #>         else if (method == \"exact\") { #>             if (ytype == \"right\")  #>                 getFromNamespace(\"coxexact.fit\", \"survival\") #>             else agexact.fit #>         } #>         else stop(paste(\"Unknown method\", method)) #>         if (missing(init))  #>             init <- NULL #>         f <- fitter(X, Y, strata = Strata, offset = offset, weights = weights, init = init, method = method, rownames = rnam, control = coxph.control(eps = eps, toler.chol = tol, toler.inf = 1, iter.max = iter.max)) #>     } #>     if (is.character(f)) { #>         cat(\"Failure in cph:\\n\", f, \"\\n\") #>         return(structure(list(fail = TRUE), class = \"cph\")) #>     } #>     else { #>         if (length(f$coefficients) && any(is.na(f$coefficients))) { #>             vars <- names(f$coefficients)[is.na(f$coefficients)] #>             msg <- paste(\"X matrix deemed to be singular; variable\", paste(vars, collapse = \" \")) #>             if (singular.ok)  #>                 warning(msg) #>             else { #>                 cat(msg, \"\\n\") #>                 return(structure(list(fail = TRUE), class = \"cph\")) #>             } #>         } #>     } #>     f$terms <- Terms #>     f$sformula <- sformula #>     f$mmcolnames <- mmcolnames #>     if (robust) { #>         f$naive.var <- f$var #>         if (!length(cluster))  #>             cluster <- FALSE #>         fit2 <- c(f, list(x = X, y = Y, weights = weights, method = method)) #>         if (length(stra))  #>             fit2$strata <- Strata #>         r <- getS3method(\"residuals\", \"coxph\")(fit2, type = \"dfbeta\", collapse = cluster, weighted = TRUE) #>         f$var <- t(r) %*% r #>     } #>     nvar <- length(f$coefficients) #>     ev <- factor(Y[, ny], levels = 0:1, labels = c(\"No Event\", \"Event\")) #>     n.table <- { #>         if (!length(Strata))  #>             table(ev, dnn = \"Status\") #>         else table(Strata, ev, dnn = c(\"Stratum\", \"Status\")) #>     } #>     f$n <- n.table #>     nevent <- sum(Y[, ny]) #>     if (xpres) { #>         logtest <- -2 * (f$loglik[1] - f$loglik[2]) #>         R2.max <- 1 - exp(2 * f$loglik[1]/n) #>         R2 <- (1 - exp(-logtest/n))/R2.max #>         P <- 1 - pchisq(logtest, nvar) #>         gindex <- GiniMd(f$linear.predictors) #>         dxy <- dxy.cens(f$linear.predictors, Y, type = \"hazard\")[\"Dxy\"] #>         stats <- c(n, nevent, logtest, nvar, P, f$score, 1 - pchisq(f$score, nvar), R2, dxy, gindex, exp(gindex)) #>         names(stats) <- c(\"Obs\", \"Events\", \"Model L.R.\", \"d.f.\", \"P\", \"Score\", \"Score P\", \"R2\", \"Dxy\", \"g\", \"gr\") #>     } #>     else { #>         stats <- c(n, nevent) #>         names(stats) <- c(\"Obs\", \"Events\") #>     } #>     f$method <- NULL #>     if (xpres)  #>         dimnames(f$var) <- list(atr$colnames, atr$colnames) #>     f <- c(f, list(call = call, Design = atr, assign = DesignAssign(atr, 0, atrx$terms), na.action = nact, fail = FALSE, non.slopes = 0, stats = stats, method = method, maxtime = maxtime, time.inc = time.inc, units = time.units)) #>     if (xpres) { #>         f$center <- sum(f$means * f$coefficients) #>         f$scale.pred <- c(\"log Relative Hazard\", \"Hazard Ratio\") #>         attr(f$linear.predictors, \"strata\") <- Strata #>         names(f$linear.predictors) <- rnam #>         if (se.fit) { #>             XX <- X - rep(f$means, rep.int(n, nvar)) #>             se.fit <- drop(((XX %*% f$var) * XX) %*% rep(1, ncol(XX)))^0.5 #>             names(se.fit) <- rnam #>             f$se.fit <- se.fit #>         } #>     } #>     if (model)  #>         f$model <- data #>     if (is.character(surv) || surv) { #>         if (length(Strata)) { #>             iStrata <- as.character(Strata) #>             slev <- levels(Strata) #>             nstr <- length(slev) #>         } #>         else nstr <- 1 #>         srv <- NULL #>         tim <- NULL #>         s.e. <- NULL #>         timepts <- seq(0, maxtime, by = time.inc) #>         s.sum <- array(double(1), c(length(timepts), nstr, 3), list(format(timepts), paste(\"Stratum\", 1:nstr), c(\"Survival\", \"n.risk\", \"std.err\"))) #>         g <- list(n = sum(f$n), coefficients = f$coefficients, linear.predictors = f$linear.predictors, method = f$method, type = type, means = f$means, var = f$var, x = X, y = Y, strata = Strata, offset = offset, weights = weights, terms = Terms, call = call) #>         g <- survfit.cph(g, se.fit = is.character(surv) || surv, type = type, vartype = vartype, conf.type = \"log\") #>         strt <- if (nstr > 1)  #>             rep(names(g$strata), g$strata) #>         for (k in 1:nstr) { #>             j <- if (nstr == 1)  #>                 TRUE #>             else strt == slev[k] #>             yy <- Y[if (nstr == 1)  #>                 TRUE #>             else iStrata == slev[k], ny - 1] #>             maxt <- max(yy) #>             tt <- c(0, g$time[j]) #>             su <- c(1, g$surv[j]) #>             se <- c(NA, g$std.err[j]) #>             if (maxt > tt[length(tt)]) { #>                 tt <- c(tt, maxt) #>                 su <- c(su, su[length(su)]) #>                 se <- c(se, NA) #>             } #>             kk <- 0 #>             for (tp in timepts) { #>                 kk <- kk + 1 #>                 t.choice <- max((1:length(tt))[tt <= tp + 1e-06]) #>                 if (tp > max(tt) + 1e-06 & su[length(su)] > 0) { #>                   Su <- NA #>                   Se <- NA #>                 } #>                 else { #>                   Su <- su[t.choice] #>                   Se <- se[t.choice] #>                 } #>                 n.risk <- sum(yy >= tp) #>                 s.sum[kk, k, 1:3] <- c(Su, n.risk, Se) #>             } #>             if (!is.character(surv)) { #>                 if (nstr == 1) { #>                   tim <- tt #>                   srv <- su #>                   s.e. <- se #>                 } #>                 else { #>                   tim <- c(tim, list(tt)) #>                   srv <- c(srv, list(su)) #>                   s.e. <- c(s.e., list(se)) #>                 } #>             } #>         } #>         if (is.character(surv))  #>             f$surv.summary <- s.sum #>         else { #>             if (nstr > 1) { #>                 names(srv) <- names(tim) <- names(s.e.) <- levels(Strata) #>             } #>             f <- c(f, list(time = tim, surv = srv, std.err = s.e., surv.summary = s.sum)) #>         } #>     } #>     f$strata <- Strata #>     if (x)  #>         f$x <- X #>     if (y)  #>         f$y <- Y #>     f$weights <- weights #>     f$offset <- offset #>     if (!linear.predictors)  #>         f$linear.predictors <- NULL #>     if (!residuals)  #>         f$residuals <- NULL #>     class(f) <- c(\"cph\", \"rms\", \"coxph\") #>     f #> }()  #>  #> Summary of the weights  G(T_i-|X_i) : #>  #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0392  0.5643  0.8254  0.7273  0.9247  1.0000  plot(WCox$weights,WKM$weights)   # using the stratified Kaplan-Meier for the censoring times given X2  WKM2 <- subjectWeights(Surv(time,status)~X2,data=dat,method=\"nonpar\") plot(WKM2$fit,add=FALSE)"},{"path":"/reference/subsetIndex.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Specific Elements From An Object — subsetIndex","title":"Extract Specific Elements From An Object — subsetIndex","text":"Extract specific elements object.","code":""},{"path":"/reference/subsetIndex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Specific Elements From An Object — subsetIndex","text":"","code":"subsetIndex(object, index, default, ...)  # S3 method for default subsetIndex(object, index, default, ...)  # S3 method for matrix subsetIndex(object, index, default, col = TRUE, ...)"},{"path":"/reference/subsetIndex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Specific Elements From An Object — subsetIndex","text":"object vector matrix. index index elements extracted. 0 indicates column set default value. NA indicates column set NA. default default value. ... used generic method. col object matrix, TRUE lead extract columns FALSE rows.","code":""},{"path":"/reference/subsetIndex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Specific Elements From An Object — subsetIndex","text":"","code":"M <- matrix(rnorm(50),5,10) subsetIndex(M, index = c(0,0,1), default = 0) #>      [,1] [,2]         [,3] #> [1,]    0    0 -0.721900766 #> [2,]    0    0  0.006108878 #> [3,]    0    0 -0.581568838 #> [4,]    0    0  2.070620238 #> [5,]    0    0  0.385736150 subsetIndex(M, index = c(0,2,3,NA), default = 0) #>      [,1]       [,2]         [,3] [,4] #> [1,]    0  0.3531510 -0.006797234   NA #> [2,]    0 -0.4182667 -0.709035959   NA #> [3,]    0  1.9425657 -1.896683608   NA #> [4,]    0 -2.1185980 -0.265387786   NA #> [5,]    0 -0.3325030 -0.463719324   NA subsetIndex(M, index = c(0,NA,2,3,NA), default = 0) #>      [,1] [,2]       [,3]         [,4] [,5] #> [1,]    0   NA  0.3531510 -0.006797234   NA #> [2,]    0   NA -0.4182667 -0.709035959   NA #> [3,]    0   NA  1.9425657 -1.896683608   NA #> [4,]    0   NA -2.1185980 -0.265387786   NA #> [5,]    0   NA -0.3325030 -0.463719324   NA  C <- 1:10 subsetIndex(C, index = c(0,0,1,5,NA), default = 0) #> [1]  0  0  1  5 NA"},{"path":"/reference/summary.FGR.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of a Fine-Gray regression model — summary.FGR","title":"Summary of a Fine-Gray regression model — summary.FGR","text":"Summary Fine-Gray regression model","code":""},{"path":"/reference/summary.FGR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of a Fine-Gray regression model — summary.FGR","text":"","code":"# S3 method for FGR summary(object, ...)"},{"path":"/reference/summary.FGR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of a Fine-Gray regression model — summary.FGR","text":"object Object fitted function FGR ... passed cmprsk::summary.crr","code":""},{"path":"/reference/summary.Score.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of prediction performance metrics — summary.Score","title":"Summary of prediction performance metrics — summary.Score","text":"Summarizing Score object","code":""},{"path":"/reference/summary.Score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of prediction performance metrics — summary.Score","text":"","code":"# S3 method for Score summary(   object,   times,   what = c(\"score\", \"contrasts\"),   models,   digits = 1,   pvalue.digits = 4,   ... )"},{"path":"/reference/summary.Score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of prediction performance metrics — summary.Score","text":"object Object obtained Score. times Select time points Either \"score\", \"contrasts\" , .e., c(\"score\",\"contrasts\") models Select models summarize. Need subset object$models digits rounding everything p-values pvalue.digits rounding p-values ... used","code":""},{"path":"/reference/summary.Score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of prediction performance metrics — summary.Score","text":"List tables","code":""},{"path":"/reference/summary.Score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of prediction performance metrics — summary.Score","text":"AUC Brier score put tables","code":""},{"path":[]},{"path":"/reference/summary.Score.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary of prediction performance metrics — summary.Score","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/summary.ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Average Treatment Effects — summary.ate","title":"Summary Average Treatment Effects — summary.ate","text":"Summary average treatment effects.","code":""},{"path":"/reference/summary.ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Average Treatment Effects — summary.ate","text":"","code":"# S3 method for ate summary(   object,   estimator = object$estimator[1],   short = FALSE,   type = c(\"meanRisk\", \"diffRisk\"),   se = FALSE,   quantile = FALSE,   estimate.boot = TRUE,   digits = 3,   ... )"},{"path":"/reference/summary.ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Average Treatment Effects — summary.ate","text":"object object obtained function ate estimator [character] type estimator relative estimates displayed. short [logical] TRUE, displays estimated risks. type [character vector] displayed. Can \"meanRisk\" display risks specific treatment group, \"diffRisk\" display difference risks treatment groups, \"ratioRisk\" display ratio risks treatment groups,. se [logical] standard error risks displayed? quantile [logical] quantile confidence bands displayed? estimate.boot [logical] average estimate bootstrap samples displayed? digits [integer, >0] Number digits. ... passed confint","code":""},{"path":"/reference/summary.ate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Average Treatment Effects — summary.ate","text":"display confidence intervals/bands p.value, confint method needs applied object.","code":""},{"path":[]},{"path":"/reference/summary.riskRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of a risk regression model — summary.riskRegression","title":"Summary of a risk regression model — summary.riskRegression","text":"Summary risk regression model","code":""},{"path":"/reference/summary.riskRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of a risk regression model — summary.riskRegression","text":"","code":"# S3 method for riskRegression summary(   object,   times,   digits = 3,   pvalue.digits = 4,   eps = 10^-4,   verbose = TRUE,   ... )"},{"path":"/reference/summary.riskRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of a risk regression model — summary.riskRegression","text":"object Object obtained ARR, LRR riskRegression times Time points show time-dependent coefficients digits Number digits numbers p-values pvalue.digits Number digits p-values eps p-values smaller number shown verbose Level verbosity ... used","code":""},{"path":"/reference/terms.phreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract terms for phreg objects — terms.phreg","title":"Extract terms for phreg objects — terms.phreg","text":"Extract terms phreg objects","code":""},{"path":"/reference/terms.phreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract terms for phreg objects — terms.phreg","text":"","code":"# S3 method for phreg terms(x, ...)"},{"path":"/reference/terms.phreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract terms for phreg objects — terms.phreg","text":"x phreg object. ... used.","code":""},{"path":"/reference/transformCIBP.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","title":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","text":"Compute confidence intervals/bands p-values transformation","code":""},{"path":"/reference/transformCIBP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","text":"","code":"transformCIBP(   estimate,   se,   iid,   null,   conf.level,   alternative,   ci,   type,   min.value,   max.value,   band,   method.band,   n.sim,   seed,   p.value,   df = NULL )"},{"path":"/reference/transformCIBP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","text":"estimate [numeric matrix] estimate value transformation. se [numeric matrix] standard error transformation. iid [numeric array] iid decomposition transformation. null [numeric] value estimate (transformation) null hypothesis. conf.level [numeric, 0-1] Level confidence. alternative [character] character string specifying alternative hypothesis, must one \"two.sided\" (default), \"greater\" \"less\". ci [logical] confidence intervals computed. type [character] transforamtion. Can \"log\", \"loglog\", \"cloglog\", \"atanh\" (Fisher transform), \"atanh2\" (modified Fisher transform [0-1] variable). min.value [numeric] NULL lower bound confidence interval min, set min. max.value [numeric] NULL lower bound confidence interval max, set max. band [integer 0,1,2] non-0, confidence bands computed contrasts (band=1) contrasts (band=2). method.band [character] method used adjust multiple comparisons. Can element p.adjust.methods (e.g. \"holm\"), \"maxT-integration\", \"maxT-simulation\". n.sim [integer, >0] number simulations used compute quantiles confidence bands. seed [integer, >0] seed number set performing simulations confidence bands. p.value [logical] p-values adjusted p-values computed. active ci=TRUE band>0. df [integer, >0] optional. Degrees freedom used student distribution test statistic. specified, use normal distribution instead.","code":""},{"path":"/reference/transformCIBP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","text":"iid decomposition must dimensions [n.obs,time,n.prediction] estimate se must dimensions [n.prediction,time]. Single step max adjustment multiple comparisons, .e. accounting correlation test statistics ordering tests, can performed setting arguemnt method.band \"maxT-integration\" \"maxT-simulation\". former uses numerical integration (pmvnorm qmvnorm perform adjustment latter using simulation. assume test statistics jointly normally distributed.","code":""},{"path":"/reference/transformCIBP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Confidence Intervals/Bands and P-values After a Transformation — transformCIBP","text":"","code":"set.seed(10) n <- 100 X <- rnorm(n)  res2sided <- transformCIBP(estimate = mean(X), se = cbind(sd(X)/sqrt(n)), null = 0,               type = \"none\", ci = TRUE, conf.level = 0.95, alternative = \"two.sided\",               min.value = NULL, max.value = NULL, band = FALSE,               p.value = TRUE, seed = 10, df = n-1)  resLess <- transformCIBP(estimate = mean(X), se = cbind(sd(X)/sqrt(n)), null = 0,               type = \"none\", ci = TRUE, conf.level = 0.95, alternative = \"less\",               min.value = NULL, max.value = NULL, band = FALSE,               p.value = TRUE, seed = 10, df = n-1)  resGreater <- transformCIBP(estimate = mean(X), se = cbind(sd(X)/sqrt(n)), null = 0,               type = \"none\", ci = TRUE, conf.level = 0.95, alternative = \"greater\",               min.value = NULL, max.value = NULL, band = FALSE,               p.value = TRUE, seed = 10, df = n-1)   ## comparison with t-test GS <- t.test(X, alternative = \"two.sided\") res2sided$p.value - GS$p.value #>               [,1] #> [1,] -5.551115e-17 unlist(res2sided[c(\"lower\",\"upper\")]) - GS$conf.int #>         lower         upper  #>  0.000000e+00 -1.387779e-17  #> attr(,\"conf.level\") #> [1] 0.95  GS <- t.test(X, alternative = \"less\") resLess$p.value - GS$p.value #>      [,1] #> [1,]    0 unlist(resLess[c(\"lower\",\"upper\")]) - GS$conf.int #>         lower         upper  #>           NaN -6.938894e-18  #> attr(,\"conf.level\") #> [1] 0.95  GS <- t.test(X, alternative = \"greater\") resGreater$p.value - GS$p.value #>      [,1] #> [1,]    0 unlist(resGreater[c(\"lower\",\"upper\")]) - GS$conf.int #> lower upper  #>     0   NaN  #> attr(,\"conf.level\") #> [1] 0.95"},{"path":"/reference/wglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic Regression Using IPCW — wglm","title":"Logistic Regression Using IPCW — wglm","text":"Logistic regression multiple timepoints right-censoring handle using inverse probability censoring weighting.","code":""},{"path":"/reference/wglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic Regression Using IPCW — wglm","text":"","code":"wglm(   regressor.event,   formula.censor,   times,   data,   cause = NA,   fitter = \"coxph\",   product.limit = FALSE )"},{"path":"/reference/wglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic Regression Using IPCW — wglm","text":"regressor.event [formula] formula empty left hand side covariates logistic regression right hand side. formula.censor [formula] formula used fit censoring model. times [numeric vector] time points model probability experiencing event. data [data.frame] dataset containing time event occured, type event, regressors used fit censoring logistic models. cause [character numeric] cause interest. Defaults first cause. fitter [character] routine fit Cox regression models. product.limit [logical] TRUE survival computed using product limit estimator.","code":""},{"path":"/reference/wglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logistic Regression Using IPCW — wglm","text":"object class \"wglm\".","code":""},{"path":"/reference/wglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic Regression Using IPCW — wglm","text":"First, Cox model fitted (argument formula.censor) censoring probabilities computed relative timepoint (argument times) obtain censoring weights. , timepoint, logistic regression fitted appropriate censoring weights outcome indicator experience event interest (argument cause) timepoint.","code":""},{"path":"/reference/wglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic Regression Using IPCW — wglm","text":"","code":"library(survival)  set.seed(10) n <- 250 tau <- 1:5 d <- sampleData(n, outcome = \"competing.risks\") dFull <- d[event!=0] ## remove censoring dSurv <- d[event!=2] ## remove competing risk  #### no censoring #### e.wglm <- wglm(regressor.event = ~ X1, formula.censor = Surv(time,event==0) ~ 1,                times = tau, data = dFull, product.limit = TRUE) e.wglm ## same as a logistic regression #>      logistic regression for cause 1:  #> ---------------------------------------------------------------------------------- #>   - time: 1 #>  #> Call:  glm(XX_event.1_XX ~ X1, family = binomial(link = \"logit\")) #>  #> Coefficients: #> (Intercept)          X11   #>      -2.430        1.226   #>  #> Degrees of Freedom: 185 Total (i.e. Null);  184 Residual #> Null Deviance:\t    113.7  #> Residual Deviance: 111.3 \tAIC: 115.3 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 2 #>  #> Call:  glm(XX_event.2_XX ~ X1, family = binomial(link = \"logit\")) #>  #> Coefficients: #> (Intercept)          X11   #>      -1.372        0.561   #>  #> Degrees of Freedom: 185 Total (i.e. Null);  184 Residual #> Null Deviance:\t    191  #> Residual Deviance: 190.3 \tAIC: 194.3 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 3 #>  #> Call:  glm(XX_event.3_XX ~ X1, family = binomial(link = \"logit\")) #>  #> Coefficients: #> (Intercept)          X11   #>     -0.8445       0.6904   #>  #> Degrees of Freedom: 185 Total (i.e. Null);  184 Residual #> Null Deviance:\t    230.8  #> Residual Deviance: 229.5 \tAIC: 233.5 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 4 #>  #> Call:  glm(XX_event.4_XX ~ X1, family = binomial(link = \"logit\")) #>  #> Coefficients: #> (Intercept)          X11   #>     -0.4832       0.6373   #>  #> Degrees of Freedom: 185 Total (i.e. Null);  184 Residual #> Null Deviance:\t    249.2  #> Residual Deviance: 248 \tAIC: 252 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 5 #>  #> Call:  glm(XX_event.5_XX ~ X1, family = binomial(link = \"logit\")) #>  #> Coefficients: #> (Intercept)          X11   #>     -0.1506       0.9615   #>  #> Degrees of Freedom: 185 Total (i.e. Null);  184 Residual #> Null Deviance:\t    257.5  #> Residual Deviance: 254.9 \tAIC: 258.9 #> ----------------------------------------------------------------------------------  summary(ate(e.wglm, data = dFull, times = tau, treatment = \"X1\", verbose = FALSE)) #>      Average treatment effect for cause 1  #>  #>  - Treatment            : X1 (2 levels: \"0\" \"1\") #>  - Event                : event (cause: 1, competing risk(s): 2) #>  - Time  [min;max]      : time [0.136;13.9] #>  - Eval. time          :   1   2  3  4  5 #>       number at risk 0   151 126 98 74 52 #>       number at risk 1    10   9  7  4  2 #>  #>  Estimation procedure  #>  - Estimator  : G-formula #>  - Uncertainty: Gaussian approximation  #>                 where the variance is estimated via the influence function  #>  #>  Testing procedure #>  - Null hypothesis     : given two treatments (A,B) and a specific timepoint, equal risks  #>  - Confidence level    : 0.95 #>  #>  Results:  #>  - Difference in standardized risk (B-A) between time zero and 'time'  #>                 reported on the scale [-1;1] (difference between two probabilities) #>  (difference in average risks when treating all subjects with the experimental treatment (B), #>                                 vs. treating all subjects with the reference treatment (A)) #>  #>  time X1=A risk(X1=A) X1=B risk(X1=B) difference           ci p.value #>     1    0     0.0809    1      0.231      0.150 [-0.08;0.38]  0.2067 #>     2    0     0.2023    1      0.308      0.105 [-0.15;0.36]  0.4233 #>     3    0     0.3006    1      0.462      0.161 [-0.12;0.44]  0.2590 #>     4    0     0.3815    1      0.538      0.157 [-0.12;0.44]  0.2727 #>     5    0     0.4624    1      0.692      0.230 [-0.03;0.49]  0.0851 #>  #>  difference      : estimated difference in standardized risks  #>  ci              : pointwise confidence intervals  #>  p.value         : (unadjusted) p-value   #### right-censoring #### ## no covariante in the censoring model (independent censoring) eC.wglm <- wglm(regressor.event = ~ X1, formula.censor = Surv(time,event==0) ~ 1,                times = tau, data = dSurv, product.limit = TRUE) eC.wglm #>      IPCW logistic regression :  #> ---------------------------------------------------------------------------------- #>   - time: 1 #>  #> Call:  glm(XX_event.1_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.1_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>       -2.36         1.26   #>  #> Degrees of Freedom: 173 Total (i.e. Null);  172 Residual #> Null Deviance:\t    111.9  #> Residual Deviance: 109.3 \tAIC: 112.8 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 2 #>  #> Call:  glm(XX_event.2_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.2_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>      -1.277        0.560   #>  #> Degrees of Freedom: 169 Total (i.e. Null);  168 Residual #> Null Deviance:\t    186.9  #> Residual Deviance: 186.2 \tAIC: 186.4 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 3 #>  #> Call:  glm(XX_event.3_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.3_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>     -0.7090       0.6523   #>  #> Degrees of Freedom: 163 Total (i.e. Null);  162 Residual #> Null Deviance:\t    224.6  #> Residual Deviance: 223.4 \tAIC: 216 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 4 #>  #> Call:  glm(XX_event.4_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.4_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>     -0.2975       0.6894   #>  #> Degrees of Freedom: 152 Total (i.e. Null);  151 Residual #> Null Deviance:\t    239.9  #> Residual Deviance: 238.6 \tAIC: 215.5 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 5 #>  #> Call:  glm(XX_event.5_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.5_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>      0.1487       1.8171   #>  #> Degrees of Freedom: 143 Total (i.e. Null);  142 Residual #> Null Deviance:\t    240.1  #> Residual Deviance: 234.4 \tAIC: 193.2 #> ----------------------------------------------------------------------------------  ## with covariates in the censoring model eC2.wglm <- wglm(regressor.event = ~ X1 + X8,                 formula.censor = Surv(time,event==0) ~ X1*X8,                  times = tau, data = dSurv) eC2.wglm #>      IPCW logistic regression :  #> ---------------------------------------------------------------------------------- #>   - time: 1 #>  #> Call:  glm(XX_event.1_XX ~ X1 + X8, family = binomial(link = \"logit\"),  #>     weights = \"XX_IPCW.1_XX\") #>  #> Coefficients: #> (Intercept)          X11           X8   #>      -3.101        1.243        1.077   #>  #> Degrees of Freedom: 173 Total (i.e. Null);  171 Residual #> Null Deviance:\t    111.8  #> Residual Deviance: 92.42 \tAIC: 98.07 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 2 #>  #> Call:  glm(XX_event.2_XX ~ X1 + X8, family = binomial(link = \"logit\"),  #>     weights = \"XX_IPCW.2_XX\") #>  #> Coefficients: #> (Intercept)          X11           X8   #>     -1.5679       0.4646       0.6977   #>  #> Degrees of Freedom: 169 Total (i.e. Null);  167 Residual #> Null Deviance:\t    186.8  #> Residual Deviance: 170.3 \tAIC: 173.1 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 3 #>  #> Call:  glm(XX_event.3_XX ~ X1 + X8, family = binomial(link = \"logit\"),  #>     weights = \"XX_IPCW.3_XX\") #>  #> Coefficients: #> (Intercept)          X11           X8   #>     -0.9496       0.5895       0.7033   #>  #> Degrees of Freedom: 163 Total (i.e. Null);  161 Residual #> Null Deviance:\t    224.3  #> Residual Deviance: 203.1 \tAIC: 199.4 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 4 #>  #> Call:  glm(XX_event.4_XX ~ X1 + X8, family = binomial(link = \"logit\"),  #>     weights = \"XX_IPCW.4_XX\") #>  #> Coefficients: #> (Intercept)          X11           X8   #>     -0.4363       0.6414       0.5335   #>  #> Degrees of Freedom: 152 Total (i.e. Null);  150 Residual #> Null Deviance:\t    239.8  #> Residual Deviance: 224.7 \tAIC: 206.8 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 5 #>  #> Call:  glm(XX_event.5_XX ~ X1 + X8, family = binomial(link = \"logit\"),  #>     weights = \"XX_IPCW.5_XX\") #>  #> Coefficients: #> (Intercept)          X11           X8   #>     0.06096      1.67334      0.45678   #>  #> Degrees of Freedom: 143 Total (i.e. Null);  141 Residual #> Null Deviance:\t    239.7  #> Residual Deviance: 224 \tAIC: 199.9 #> ----------------------------------------------------------------------------------  #### Competing risks #### ## here Kaplan-Meier as censoring model eCR.wglm <- wglm(regressor.event = ~ X1,                  formula.censor = Surv(time,event==0) ~ strata(X1),                  times = tau, data = d, cause = 1, product.limit = TRUE) eCR.wglm #>      IPCW logistic regression for cause 1:  #> ---------------------------------------------------------------------------------- #>   - time: 1 #>  #> Call:  glm(XX_event.1_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.1_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>      -2.756        1.370   #>  #> Degrees of Freedom: 248 Total (i.e. Null);  247 Residual #> Null Deviance:\t    124.4  #> Residual Deviance: 121.4 \tAIC: 125 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 2 #>  #> Call:  glm(XX_event.2_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.2_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>      -1.732        0.720   #>  #> Degrees of Freedom: 244 Total (i.e. Null);  243 Residual #> Null Deviance:\t    217.6  #> Residual Deviance: 216.4 \tAIC: 217.6 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 3 #>  #> Call:  glm(XX_event.3_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.3_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>     -1.2312       0.8257   #>  #> Degrees of Freedom: 238 Total (i.e. Null);  237 Residual #> Null Deviance:\t    273.5  #> Residual Deviance: 271.3 \tAIC: 267 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 4 #>  #> Call:  glm(XX_event.4_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.4_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>     -0.8904       0.7569   #>  #> Degrees of Freedom: 227 Total (i.e. Null);  226 Residual #> Null Deviance:\t    306.1  #> Residual Deviance: 304.2 \tAIC: 288.2 #> ---------------------------------------------------------------------------------- #> ---------------------------------------------------------------------------------- #>   - time: 5 #>  #> Call:  glm(XX_event.5_XX ~ X1, family = binomial(link = \"logit\"), weights = \"XX_IPCW.5_XX\") #>  #> Coefficients: #> (Intercept)          X11   #>     -0.5634       1.1743   #>  #> Degrees of Freedom: 218 Total (i.e. Null);  217 Residual #> Null Deviance:\t    332  #> Residual Deviance: 327.3 \tAIC: 301 #> ----------------------------------------------------------------------------------"}]
